{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import datetime\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.path.exists('/workspace/data_2'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data_2/'\n",
    "else:\n",
    "    data_path = '../data/'\n",
    "    \n",
    "# if torch.cuda.is_available() == False:\n",
    "#     RuntimeError(\"GPU detected: False\")\n",
    "#     print(\"GPU detected: False\")\n",
    "# else:\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(\"The GPU is detected.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_pickle(data_path + 'dataset_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df=pd.read_pickle(data_path + 'labelled_sets_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((dataset_df[['matchup_1','winner']].value_counts().to_string()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the columns using a loop for ease of reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(dataset_df.columns):\n",
    "    print(i, col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of features and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset_df.columns[36:46].append(dataset_df.columns[47:53])\n",
    "features = features.append(dataset_df.columns[55:])\n",
    "target = 'winner'\n",
    "\n",
    "df = dataset_df.dropna(subset=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Train XGBoostClassifier and look at the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and target to numpy arrays\n",
    "X = df[features].values.astype(float)\n",
    "y = df['winner'].values.astype(int)\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for weight, gain, and cover\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "\n",
    "# Map importance to feature names and create a comprehensive DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': [features[int(k[1:])] for k in importance_weight.keys()],  # Map f0, f1, ... to feature names\n",
    "    'Weight': [importance_weight.get(f, 0) for f in importance_weight.keys()],\n",
    "    'Gain': [importance_gain.get(f, 0) for f in importance_weight.keys()],\n",
    "    'Cover': [importance_cover.get(f, 0) for f in importance_weight.keys()]\n",
    "}).sort_values(by='Weight', ascending=False)  # Sort by Weight (or choose another metric)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(importance_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight:** Number of times a feature is used in a split across all trees. High weight means the feature is frequently used in decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_df.sort_values(by='Weight', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gain:** The average improvement in accuracy brought by a feature when it is used in trees. High gain means the feature has a strong impact on predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_df.sort_values(by='Gain', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cover:** The average number of samples affected by splits involving the feature.\n",
    "High cover means the feature is applied to a large number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(importance_df.sort_values(by='Cover', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = ['matchup_1'] # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    df.sample(10_000),\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=target,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "    # diag_kind='kde',  # Kernel density estimate on diagonals\n",
    "    # markers=['o', 's', 'D']  # Different markers for the hue variable\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Pair Plot\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = ['matchup_1'] # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] != 1500.0)]\n",
    "\n",
    "n_samples = 1_000\n",
    "winner_sample = plotting_df[plotting_df['winner']==1.0].sample(int((n_samples/2)))\n",
    "loser_sample = plotting_df[plotting_df['winner']==0.0].sample(int((n_samples/2)))\n",
    "sample_df  = pd.concat([winner_sample,loser_sample])\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=target,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "    # diag_kind='kde',  # Kernel density estimate on diagonals\n",
    "    # markers=['o', 's', 'D']  # Different markers for the hue variable\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Both players appeared in the dataset before\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = 'matchup_1' # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "# plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] != 1500.0)]\n",
    "\n",
    "print(\"Rows for (matchup_1 == 1) & (winner == 1):\",\n",
    "      df[(df['matchup_1'] == 1) & (df['winner'] == 1)].shape[0])\n",
    "print(\"Rows for (matchup_1 == 0) & (winner == 0):\",\n",
    "      df[(df['matchup_1'] == 0) & (df['winner'] == 0)].shape[0])\n",
    "\n",
    "\n",
    "i = 500\n",
    "winner_sample = df[(df['matchup_1']==1) & (df['winner']==1)].sample(n=i)\n",
    "loser_sample = df[(df['matchup_1']==0) & (df['winner']==0)].sample(n=i)\n",
    "sample_df  = pd.concat([winner_sample,loser_sample])\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=extra_variable,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Player most recent set agrees with the outcome of this set\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = 'matchup_1' # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "# plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] != 1500.0)]\n",
    "\n",
    "print(\"Rows for (matchup_1 == 1) & (winner == 1):\",\n",
    "      df[(df['matchup_1'] == 0) & (df['winner'] == 1)].shape[0])\n",
    "print(\"Rows for (matchup_1 == 0) & (winner == 0):\",\n",
    "      df[(df['matchup_1'] == 1) & (df['winner'] == 0)].shape[0])\n",
    "\n",
    "\n",
    "i = 500\n",
    "winner_sample = df[(df['matchup_1']==0) & (df['winner']==1)].sample(n=i)\n",
    "loser_sample = df[(df['matchup_1']==1) & (df['winner']==0)].sample(n=i)\n",
    "sample_df  = pd.concat([winner_sample,loser_sample])\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=extra_variable,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Player's most recent set disagrees with the outcome of this set\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = 'matchup_1' # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "# plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] != 1500.0)]\n",
    "\n",
    "# print(\"Rows for (matchup_1 == 1) & (winner == 1):\",\n",
    "#       df[(df[['matchup_1','matchup_2']] == [1,1]) & (df['winner'] == 1)].shape[0])\n",
    "# print(\"Rows for (matchup_1 == 0) & (winner == 0):\",\n",
    "#       df[(df[['matchup_1','matchup_2']] == [0,0]) & (df['winner'] == 0)].shape[0])\n",
    "\n",
    "\n",
    "# Filter and sample rows for winner\n",
    "winner_sample = df[\n",
    "    (df['matchup_1'] == 1) & (df['matchup_2'] == 1) & (df['winner'] == 1)\n",
    "].sample(n=min(i, len(df[(df['matchup_1'] == 1) & (df['matchup_2'] == 0) & (df['winner'] == 1)])))\n",
    "\n",
    "# Filter and sample rows for loser\n",
    "loser_sample = df[\n",
    "    (df['matchup_1'] == 0) & (df['matchup_2'] == 0) & (df['winner'] == 0)\n",
    "].sample(n=min(i, len(df[(df['matchup_1'] == 0) & (df['matchup_2'] == 1) & (df['winner'] == 0)])))\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=extra_variable,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"The most recent set agrees while the second most recent set dissagrees with the outcome of the set\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = 'matchup_1' # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter and sample rows for winner\n",
    "winner_sample = df[\n",
    "    (df['matchup_1'] == 0) & (df['matchup_2'] == 1) & (df['winner'] == 1)\n",
    "].sample(n=min(i, len(df[(df['matchup_1'] == 0) & (df['matchup_2'] == 1) & (df['winner'] == 1)])))\n",
    "\n",
    "# Filter and sample rows for loser\n",
    "loser_sample = df[\n",
    "    (df['matchup_1'] == 1) & (df['matchup_2'] == 0) & (df['winner'] == 0)\n",
    "].sample(n=min(i, len(df[(df['matchup_1'] == 1) & (df['matchup_2'] == 0) & (df['winner'] == 0)])))\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=extra_variable,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"The most recent set disagrees while the second most recent set agrees with the outcome of the set\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = ['matchup_1'] # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] == 1500.0)]\n",
    "\n",
    "i = 500\n",
    "winner_sample = plotting_df[plotting_df['winner']==1.0].sample(i )\n",
    "loser_sample = plotting_df[plotting_df['winner']==0.0].sample(i )\n",
    "sample_df  = pd.concat([winner_sample,loser_sample])\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=target,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "    # diag_kind='kde',  # Kernel density estimate on diagonals\n",
    "    # markers=['o', 's', 'D']  # Different markers for the hue variable\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Both players appeared in the dataset before\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = ['p1_default_elo',  'p1/m1_alt3_elo', 'p1/m1/m1_alt2_elo', 'p1_default_rd', 'p1/m1_alt3_rd',  'p1/m1/m1_alt2_rd']\n",
    "y_vars = ['p2_default_elo',  'p2/m1_alt3_elo', 'p2/m1/m1_alt2_elo', 'p2_default_rd','p2/m1_alt3_rd',  'p2/m1/m1_alt2_rd']\n",
    "extra_variable = 'matchup_1' # Can be either 1.0, 0.0, or 0.5\n",
    "target = 'winner' # Can be 1 or 0\n",
    "\n",
    "# Filter rows\n",
    "# plotting_df = df[(df['p1_default_elo'] != 1500.0) & (df['p2_default_elo'] != 1500.0)]\n",
    "plotting_df = plotting_df[plotting_df['winner']==1.0]\n",
    "\n",
    "n_samples = 1_000\n",
    "winner_sample = plotting_df[plotting_df['matchup_1']==1.0].sample(int((n_samples/2)))\n",
    "loser_sample = plotting_df[plotting_df['matchup_1']==0.0].sample(int((n_samples/2)))\n",
    "sample_df  = pd.concat([winner_sample,loser_sample])\n",
    "\n",
    "# Create the pair plot\n",
    "sns.pairplot(\n",
    "    sample_df,\n",
    "    x_vars = x_vars,\n",
    "    y_vars = y_vars,\n",
    "    hue=extra_variable,  # Use matchup_1 to color the plots\n",
    "    kind = 'kde',\n",
    "\n",
    ")\n",
    "\n",
    "# Add a title\n",
    "plt.suptitle(\"Both players appeared in the dataset before\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shade the regions above and have new outlined regions being matchup_1 = 1.0. See how that shifts the regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look default elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_elo_df = df[['winner', 'p1_default_elo', 'p2_default_elo', 'p1_default_rd', 'p2_default_rd', 'p1_default_updates', 'p2_default_updates', 'matchup_1']].copy()\n",
    "default_elo_df['elo_difference'] = df['p1_default_elo'] - df['p2_default_elo']\n",
    "default_elo_df = default_elo_df[default_elo_df['elo_difference'] != 0]\n",
    "default_elo_df['min_rd'] = np.minimum(df['p1_default_rd'], df['p2_default_rd'])\n",
    "default_elo_df['max_rd'] = np.maximum(df['p1_default_rd'], df['p2_default_rd'])\n",
    "\n",
    "\n",
    "p2_won = default_elo_df['winner']==0.0\n",
    "default_elo_df['winning_difference'] = default_elo_df['elo_difference']\n",
    "default_elo_df.loc[p2_won,'winning_difference'] = default_elo_df.loc[p2_won,'winning_difference'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_elo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the distribution of winning_difference\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(\n",
    "    data=default_elo_df,\n",
    "    x='winning_difference',\n",
    "    fill=True,\n",
    "    color='blue',\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title('Distribution of Winning Difference')\n",
    "plt.xlabel('Winning Difference')\n",
    "plt.ylabel('Density')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define bins for Elo difference\n",
    "elo_bin_size = 100\n",
    "default_elo_df['elo_bin'] = pd.cut(\n",
    "    default_elo_df['elo_difference'], \n",
    "    bins=np.arange(default_elo_df['elo_difference'].min(), \n",
    "                   default_elo_df['elo_difference'].max() + elo_bin_size, \n",
    "                   elo_bin_size)\n",
    ")\n",
    "\n",
    "# Calculate probabilities for each bin\n",
    "binned_probabilities = (\n",
    "    default_elo_df.groupby('elo_bin')['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add bin midpoints for better x-axis representation\n",
    "binned_probabilities['elo_bin_midpoint'] = binned_probabilities['elo_bin'].apply(\n",
    "    lambda x: (x.left + x.right) / 2\n",
    ")\n",
    "\n",
    "# Plot the smoothed probabilities\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=binned_probabilities,\n",
    "    x='elo_bin_midpoint',\n",
    "    y='winner',\n",
    "    label='P(Winner = 1.0 | Elo Bin)',\n",
    "    color='blue'\n",
    ")\n",
    "plt.axhline(0.5, color='red', linestyle='--', label='Baseline (50%)')\n",
    "plt.title('Probability of Winning by Binned Elo Difference')\n",
    "plt.xlabel('Elo Difference (Higher - Lower)')\n",
    "plt.ylabel('Probability Winner = 1.0')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_bin_size = 25\n",
    "max_elo_bin_value = 500\n",
    "\n",
    "# Shift the bin boundaries by subtracting half the bin size\n",
    "default_elo_df['binned_elo_difference'] = (\n",
    "    np.sign(default_elo_df['elo_difference']) * \n",
    "    np.minimum(\n",
    "        np.ceil((np.abs(default_elo_df['elo_difference']) - elo_bin_size / 2) / elo_bin_size), \n",
    "        max_elo_bin_value / elo_bin_size\n",
    "    ) * elo_bin_size\n",
    ").astype(np.int16)\n",
    "\n",
    "rd_bin_size = 100\n",
    "max_rd_bin_value = 300\n",
    "\n",
    "\n",
    "default_elo_df['p1_binned_rd'] = (\n",
    "    np.ceil(default_elo_df['p1_default_rd'] / rd_bin_size) * rd_bin_size\n",
    ").astype(np.int16)\n",
    "\n",
    "\n",
    "default_elo_df['p2_binned_rd'] = (\n",
    "    np.ceil(default_elo_df['p2_default_rd'] / rd_bin_size) * rd_bin_size\n",
    ").astype(np.int16)\n",
    "\n",
    "default_elo_df['min_rd'] = np.minimum(default_elo_df['p1_binned_rd'], default_elo_df['p2_binned_rd'])\n",
    "default_elo_df['max_rd'] = np.maximum(default_elo_df['p1_binned_rd'], default_elo_df['p2_binned_rd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_elo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate overall probability\n",
    "overall_probabilities = (\n",
    "    default_elo_df.groupby('binned_elo_difference')['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "overall_probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Calculate probabilities for p1_binned_rd\n",
    "p1_probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'p1_binned_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "p1_probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Calculate probabilities for p2_binned_rd\n",
    "p2_probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'p2_binned_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "p2_probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Plot for p1_binned_rd\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=overall_probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    label='Overall',\n",
    "    color='black',\n",
    "    linewidth=2\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=p1_probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    hue='p1_binned_rd',\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Effect of p1_binned_rd on Probability of Winner Being 1.0')\n",
    "plt.xlabel('Binned Elo Difference')\n",
    "plt.ylabel('Probability Winner = 1.0')\n",
    "plt.legend(title='p1_binned_rd')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot for p2_binned_rd\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=overall_probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    label='Overall',\n",
    "    color='black',\n",
    "    linewidth=2\n",
    ")\n",
    "sns.lineplot(\n",
    "    data=p2_probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    hue='p2_binned_rd',\n",
    "    palette='plasma'\n",
    ")\n",
    "plt.title('Effect of p2_binned_rd on Probability of Winner Being 1.0')\n",
    "plt.xlabel('Binned Elo Difference')\n",
    "plt.ylabel('Probability Winner = 1.0')\n",
    "plt.legend(title='p2_binned_rd')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the probability of the winner being 1.0 grouped by binned_elo_difference and binned_min_rd\n",
    "probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'binned_min_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename for clarity\n",
    "probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Create a Seaborn plot\n",
    "g = sns.FacetGrid(\n",
    "    probabilities,\n",
    "    col=\"binned_min_rd\",\n",
    "    col_wrap=3,  # Adjust the number of columns for the grid\n",
    "    sharey=True,\n",
    "    height=4,\n",
    "    aspect=1.5\n",
    ")\n",
    "g.map(sns.lineplot, 'binned_elo_difference', 'probability_winner_1', marker='o')\n",
    "\n",
    "# Add titles and labels\n",
    "g.set_axis_labels('Binned Elo Difference', 'Probability Winner = 1.0')\n",
    "g.set_titles('Min RD = {col_name}')\n",
    "g.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the probability of the winner being 1.0 grouped by binned_elo_difference and binned_min_rd\n",
    "probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'binned_max_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename for clarity\n",
    "probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Create a Seaborn plot\n",
    "g = sns.FacetGrid(\n",
    "    probabilities,\n",
    "    col=\"binned_max_rd\",\n",
    "    col_wrap=3,  # Adjust the number of columns for the grid\n",
    "    sharey=True,\n",
    "    height=4,\n",
    "    aspect=1.5\n",
    ")\n",
    "g.map(sns.lineplot, 'binned_elo_difference', 'probability_winner_1', marker='o')\n",
    "\n",
    "# Add titles and labels\n",
    "g.set_axis_labels('Binned Elo Difference', 'Probability Winner = 1.0')\n",
    "g.set_titles('Max RD = {col_name}')\n",
    "g.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the probabilities for both Min RD and Max RD\n",
    "min_rd_probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'binned_min_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "min_rd_probabilities['RD Type'] = 'Min RD'  # Add a column to distinguish Min RD\n",
    "\n",
    "max_rd_probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'binned_max_rd'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "max_rd_probabilities['RD Type'] = 'Max RD'  # Add a column to distinguish Max RD\n",
    "\n",
    "# Rename for clarity\n",
    "min_rd_probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "max_rd_probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_probabilities = pd.concat([min_rd_probabilities, max_rd_probabilities], ignore_index=True)\n",
    "\n",
    "# Create a Seaborn FacetGrid plot with RD Type as hue\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=combined_probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    hue='RD Type',\n",
    "    style='RD Type',\n",
    "    markers=True,\n",
    "    dashes=False\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Probability of Winner Being 1.0 by Binned Elo Difference (Min RD vs Max RD)')\n",
    "plt.xlabel('Binned Elo Difference')\n",
    "plt.ylabel('Probability Winner = 1.0')\n",
    "plt.legend(title='RD Type')\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the `matchup_1` column exists in your DataFrame; adjust this as needed\n",
    "# For demonstration, replace \"matchup_1\" with the actual column name or create one if missing\n",
    "\n",
    "# Calculate the probabilities for each combination of binned_elo_difference and matchup_1\n",
    "probabilities = (\n",
    "    default_elo_df.groupby(['binned_elo_difference', 'matchup_1'])['winner']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename for clarity\n",
    "probabilities.rename(columns={'winner': 'probability_winner_1'}, inplace=True)\n",
    "\n",
    "# Plot the results with seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(\n",
    "    data=probabilities,\n",
    "    x='binned_elo_difference',\n",
    "    y='probability_winner_1',\n",
    "    hue='matchup_1',\n",
    "    marker='o',\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Probability of Winner Being 1.0 by Binned Elo Difference and Matchup')\n",
    "plt.xlabel('Binned Elo Difference')\n",
    "plt.ylabel('Probability Winner = 1.0')\n",
    "plt.legend(title='Matchup 1')\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
