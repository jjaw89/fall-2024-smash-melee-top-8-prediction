{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Majors\n",
    "In this notebook we will label the major tournaments based on ``https://liquipedia.net/smash/Major_Tournaments/Melee``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import re\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "if os.path.exists('/workspace/data_2'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data_2/'\n",
    "else:\n",
    "    data_path = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Load some data we extracted in ``jaspar_label_0_extract_data.ipynb``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = pd.read_pickle(data_path + 'tournament_info_df.pkl')\n",
    "print(tournament_info_df.shape)\n",
    "tournament_info_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copied the information from Liquipedia into a speadsheet and saved it as a CSV which we load as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_df = pd.read_csv('melee_majors.csv')\n",
    "\n",
    "# Ignore the most recent tournaments that are missing from our dataset.\n",
    "majors_df = majors_df.iloc[6:]\n",
    "\n",
    "print(f\"There are {majors_df.shape[0]} major tournaments to label.\")\n",
    "majors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up the Tournament Names\n",
    "We can see from the head of ``majors_df`` that names of the tournaments in ``majors_df['Tournaments']`` have duplicate phrases. We need to clean the tournament names remove duplicates phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_list = list(majors_df['Tournament'])\n",
    "\n",
    "# Function to remove duplicate phrases\n",
    "def remove_duplicate_phrases(name):\n",
    "    # Split the name into words\n",
    "    words = name.split()\n",
    "    # Use a sliding window to find duplicates\n",
    "    for i in range(1, len(words)):\n",
    "        if words[:i] == words[i:2*i]:\n",
    "            return ' '.join(words[i:])\n",
    "    return name\n",
    "\n",
    "# Clean the tournament names\n",
    "cleaned_tournament_list = [remove_duplicate_phrases(name) for name in tournament_list]\n",
    "\n",
    "print(\"Cleaned Tournament Names:\")\n",
    "for original, cleaned in zip(tournament_list, cleaned_tournament_list):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean tournament names\n",
    "def clean_tournament_name(name):\n",
    "    # Remove special characters, convert to lowercase, remove extra spaces\n",
    "    # if ':' in name:\n",
    "    #     name = name.split(\":\")[0]\n",
    "    # if '-' in name:\n",
    "    #     name = name.split(\"-\")[0]\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s]', '', name)\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "# Clean the major tournament names\n",
    "major_tournaments_cleaned = [clean_tournament_name(t) for t in cleaned_tournament_list]\n",
    "\n",
    "# Clean the 'cleaned_name' column in your DataFrame\n",
    "tournament_info_df['cleaned_name_cleaned'] = tournament_info_df['cleaned_name'].apply(clean_tournament_name)\n",
    "\n",
    "# Create the 'major' column\n",
    "tournament_info_df['major'] = tournament_info_df['cleaned_name_cleaned'].isin(major_tournaments_cleaned)\n",
    "\n",
    "# Verify the results\n",
    "majors_in_df = tournament_info_df[tournament_info_df['major']]\n",
    "print(f\"We found of {majors_in_df.shape[0]} majors and are missing (at least) {majors_df.shape[0]-majors_in_df.shape[0]}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove not majors\n",
    "Going through the list on the website and comparing to the majors we found, remove the ones that were miss labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_actually_majors = [\n",
    "36389,  #battle-of-bc-6-7__lowtier-bracket-melee\n",
    "16526, #ludwig-smash-invitational__melee-singles-lcq\n",
    "]\n",
    "\n",
    "tournament_info_df.loc[not_actually_majors, 'major'] = False\n",
    "\n",
    "print(f\"We managed to find {tournament_info_df[tournament_info_df['major']==True].shape[0]} out of {majors_df.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_majors = [major for major in major_tournaments_cleaned if not tournament_info_df['cleaned_name_cleaned'].isin([major]).any()]\n",
    "\n",
    "print(f\"We are missing {len(missing_majors)} majors.\\n\")\n",
    "for major in missing_majors:\n",
    "    print(major)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for missing majors\n",
    "We missed some tournaments because the tournament names found on Liquipeadia do not match the ones in ``tournament_info_df``. We now go through the list of misisng majors one by one and search for them in ``tournament_info_df``. Each tournament in ``majors_df`` has the date, the city, and the number of entrants. Some of those values match what is in ``tournament_info_df`` and some do not. Our strategy is to filter ``tournament_info_df`` down to as small as possible for each missing major and find the major by inspection. We demonstrate for ``tipped off 15``. We collect the missing majors index values as we find them in ``tournament_info_df`` in ``missing_majors``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = tournament_info_df.copy()\n",
    "\n",
    "# look up the informaion about the missing tournament (I used the website rather than the majors_df)\n",
    "print(majors_df.loc[6])\n",
    "\n",
    "# Filter tournaments based on date.\n",
    "year = 2024\n",
    "temp_df = temp_df[temp_df['start']>=datetime(year,6,15)]\n",
    "temp_df = temp_df[temp_df['start']<datetime(year,6,16)]\n",
    "\n",
    "# Filter the tournament based on location.\n",
    "temp_df = tournament_info_df[tournament_info_df['city']=='Marietta']\n",
    "\n",
    "# Filter tournaments based on entrants.\n",
    "temp_df = temp_df[temp_df['entrants']==513]   \n",
    "\n",
    "print(f\"We have filtered down to {temp_df.shape[0]} tournament(s).\")\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_majors=[\n",
    "39443, #Tipped off 15\n",
    "38456, #Get on my level X\n",
    "28389, #riptide 2023\n",
    "26646, #Get on my level 2023\n",
    "26137, # ludwig 2023 main event\n",
    "24918, #Tipped off 14,\n",
    "22595, # back in blood major upset\n",
    "17129,# smash summit 14\n",
    "15764, # lost tech city 2022\n",
    "12948, # double down 2022\n",
    "12779, # get on my level 2022\n",
    "11293, # smash summit 13\n",
    "7532, #smash_world tour\n",
    "6377, #SWT 2021 NA east regional finals\n",
    "5168, #riptide 2021\n",
    "1233, #Galint Melee Open: Spring Edition\n",
    "2, #Slippi Champions League Week 1\n",
    "3,#Slippi Champions League Week 2\n",
    "4,#Slippi Champions League Week 3\n",
    "5,#Slippi Champions League Week 4\n",
    "667, #Get on my line 2020\n",
    "167, #GameTyrant Expo 2018\n",
    "30, #EVO 2018\t\n",
    "41, #Enthusiast Gaming Live Expo 2018\n",
    "51, #GameTyrant Expo 2017\n",
    "# genesis fuse doubles circuit finals\n",
    "58, #EVO 2017\n",
    "#Shine 2016\n",
    "26, #EVO 2016\n",
    "141, # Supe Smash con\n",
    "25, #EVO 2015\n",
    "# WTFox\n",
    "165, #FC Smash 15XR: Return\n",
    "14 #paragon 2015\n",
    "]\n",
    "\n",
    "tournament_info_df.loc[missing_majors, 'major'] = True\n",
    "\n",
    "print(f\"We managed now have {tournament_info_df[tournament_info_df['major']==True].shape[0]} out of {majors_df.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_tournament_info_df = tournament_info_df[tournament_info_df['major']==True]\n",
    "major_tournament_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_tournament_info_df.to_pickle(data_path + 'major_tournament_info_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
