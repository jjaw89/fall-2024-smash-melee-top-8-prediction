{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "#import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from glicko2 import Player\n",
    "import multiprocessing\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "if os.path.exists('/workspace/data_2'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data_2/'\n",
    "else:\n",
    "    data_path = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the single-set model saved from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 single-set performance metrics\n",
      "\n",
      "On all sets:\n",
      "Log loss:  0.444\n",
      "Accuracy:  79.5\n",
      "\n",
      "Restricting to top 8 sets only:\n",
      "Log loss:  0.514\n",
      "Accuracy:  75.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "dataset_df = pd.read_pickle(data_path + 'dataset_full.pkl')\n",
    "dataset_df.sort_index(inplace=True) # For convenience, mostly. Not really necessary, we use .loc[] anyways\n",
    "\n",
    "# Note that there is no real reason to keep separately computing the individual probabilities of winning each individual set.\n",
    "# Let's just compute them all at once here.\n",
    "\n",
    "single_set_model = None\n",
    "with open(data_path + 'single_set_model.pkl', 'rb') as f:\n",
    "    single_set_model = pickle.load(f)\n",
    "\n",
    "# Make sure these match up with what features the model was trained on.\n",
    "features_all_everything = ['p1_default_elo', 'p2_default_elo', 'p1_default_rd', 'p2_default_rd',\n",
    "       'p1_default_updates', 'p2_default_updates', 'matchup_1', 'matchup_2',\n",
    "       'matchup_3', 'matchup_4', 'matchup_5', 'matchup_6', 'matchup_7',\n",
    "       'matchup_8', 'matchup_9', 'matchup_10', 'p1_m1_usage', 'p2_m1_usage',\n",
    "       'p1/m1/m1_alt2_elo', 'p1/m1/m1_alt2_rd', 'p1/m1/m1_alt2_updates',\n",
    "       'p2/m1/m1_alt2_elo', 'p2/m1/m1_alt2_rd', 'p2/m1/m1_alt2_updates',\n",
    "       'p1/m1_alt3_elo', 'p1/m1_alt3_rd', 'p1/m1_alt3_updates',\n",
    "       'p2/m1_alt3_elo', 'p2/m1_alt3_rd', 'p2/m1_alt3_updates']\n",
    "\n",
    "dataset_df['p1_win_prob'] = single_set_model.predict_proba(dataset_df[features_all_everything])[:,1]\n",
    "\n",
    "# As a sanity check, let's verify the accuracy and log loss on 2024 data\n",
    "# Total accuracy and log loss (including lots of data that the model was trained on)\n",
    "date_filter = (dataset_df['start'] >= datetime.datetime(2024,1,1)) & (dataset_df['end'] <= datetime.datetime(2024,12,31))\n",
    "print(\"2024 single-set performance metrics\")\n",
    "print()\n",
    "print(\"On all sets:\")\n",
    "print(\"Log loss: \", round(log_loss(dataset_df[date_filter]['winner'], dataset_df[date_filter]['p1_win_prob']), 3))\n",
    "print(\"Accuracy: \", round(100.0 * accuracy_score(dataset_df[date_filter]['winner'], dataset_df[date_filter]['p1_win_prob'] >= 0.5), 1))\n",
    "print()\n",
    "print(\"Restricting to top 8 sets only:\")\n",
    "print(\"Log loss: \", round(log_loss(dataset_df[date_filter & dataset_df['top_8']]['winner'], dataset_df[date_filter & dataset_df['top_8']]['p1_win_prob']), 3))\n",
    "print(\"Accuracy: \", round(100.0 * accuracy_score(dataset_df[date_filter & dataset_df['top_8']]['winner'], dataset_df[date_filter & dataset_df['top_8']]['p1_win_prob'] >= 0.5), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean up the tournament dataframe\n",
    "\n",
    "In particular, this dataframe contains info on all top 8 players, along with the paths that they took to get to where they are in the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_id</th>\n",
       "      <th>LN_A_p1</th>\n",
       "      <th>LN_A_p2</th>\n",
       "      <th>LN_B_p1</th>\n",
       "      <th>LN_B_p2</th>\n",
       "      <th>WSF_A_p1</th>\n",
       "      <th>WSF_A_p2</th>\n",
       "      <th>WSF_B_p1</th>\n",
       "      <th>WSF_B_p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>374889</td>\n",
       "      <td>212438</td>\n",
       "      <td>262548</td>\n",
       "      <td>378028</td>\n",
       "      <td>1727716</td>\n",
       "      <td>1971084</td>\n",
       "      <td>374889</td>\n",
       "      <td>29873</td>\n",
       "      <td>21515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>2931588</td>\n",
       "      <td>1652036</td>\n",
       "      <td>2720652</td>\n",
       "      <td>2512785</td>\n",
       "      <td>3188220</td>\n",
       "      <td>2931588</td>\n",
       "      <td>1470721</td>\n",
       "      <td>3188222</td>\n",
       "      <td>2551763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>701767</td>\n",
       "      <td>2670568</td>\n",
       "      <td>1693244</td>\n",
       "      <td>2159124</td>\n",
       "      <td>2382715</td>\n",
       "      <td>2998349</td>\n",
       "      <td>579172</td>\n",
       "      <td>2207927</td>\n",
       "      <td>701767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>26574</td>\n",
       "      <td>1482652</td>\n",
       "      <td>264041</td>\n",
       "      <td>2326935</td>\n",
       "      <td>650242</td>\n",
       "      <td>3024047</td>\n",
       "      <td>26574</td>\n",
       "      <td>674084</td>\n",
       "      <td>557126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>631158</td>\n",
       "      <td>2559523</td>\n",
       "      <td>1240442</td>\n",
       "      <td>1077370</td>\n",
       "      <td>3013285</td>\n",
       "      <td>631158</td>\n",
       "      <td>1007980</td>\n",
       "      <td>3188449</td>\n",
       "      <td>2557927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>2788878</td>\n",
       "      <td>3596098</td>\n",
       "      <td>3540721</td>\n",
       "      <td>4110509</td>\n",
       "      <td>287537</td>\n",
       "      <td>2410418</td>\n",
       "      <td>2788878</td>\n",
       "      <td>2956817</td>\n",
       "      <td>3815971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>180292</td>\n",
       "      <td>2298994</td>\n",
       "      <td>519020</td>\n",
       "      <td>36152</td>\n",
       "      <td>4916</td>\n",
       "      <td>36285</td>\n",
       "      <td>180292</td>\n",
       "      <td>37001</td>\n",
       "      <td>25701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>19641</td>\n",
       "      <td>405463</td>\n",
       "      <td>1445708</td>\n",
       "      <td>246491</td>\n",
       "      <td>769516</td>\n",
       "      <td>19641</td>\n",
       "      <td>2249893</td>\n",
       "      <td>3822249</td>\n",
       "      <td>148391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>267849</td>\n",
       "      <td>533918</td>\n",
       "      <td>56918</td>\n",
       "      <td>55591</td>\n",
       "      <td>342875</td>\n",
       "      <td>893866</td>\n",
       "      <td>267849</td>\n",
       "      <td>216979</td>\n",
       "      <td>512704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>609081</td>\n",
       "      <td>34804</td>\n",
       "      <td>25647</td>\n",
       "      <td>7564</td>\n",
       "      <td>1602510</td>\n",
       "      <td>698885</td>\n",
       "      <td>136697</td>\n",
       "      <td>10565</td>\n",
       "      <td>609081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      winner_id  LN_A_p1  LN_A_p2  LN_B_p1  LN_B_p2 WSF_A_p1 WSF_A_p2  \\\n",
       "18944    374889   212438   262548   378028  1727716  1971084   374889   \n",
       "18951   2931588  1652036  2720652  2512785  3188220  2931588  1470721   \n",
       "18948    701767  2670568  1693244  2159124  2382715  2998349   579172   \n",
       "18955     26574  1482652   264041  2326935   650242  3024047    26574   \n",
       "18950    631158  2559523  1240442  1077370  3013285   631158  1007980   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "39657   2788878  3596098  3540721  4110509   287537  2410418  2788878   \n",
       "39672    180292  2298994   519020    36152     4916    36285   180292   \n",
       "39598     19641   405463  1445708   246491   769516    19641  2249893   \n",
       "39031    267849   533918    56918    55591   342875   893866   267849   \n",
       "31228    609081    34804    25647     7564  1602510   698885   136697   \n",
       "\n",
       "      WSF_B_p1 WSF_B_p2  \n",
       "18944    29873    21515  \n",
       "18951  3188222  2551763  \n",
       "18948  2207927   701767  \n",
       "18955   674084   557126  \n",
       "18950  3188449  2557927  \n",
       "...        ...      ...  \n",
       "39657  2956817  3815971  \n",
       "39672    37001    25701  \n",
       "39598  3822249   148391  \n",
       "39031   216979   512704  \n",
       "31228    10565   609081  \n",
       "\n",
       "[15293 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_df = pd.read_pickle(data_path + 'top_8_tournament_previous_sets_and_results_with_winners_df')\n",
    "\n",
    "# Filter down to tournaments which actually have valid top 8 data, and previous data on getting there.\n",
    "tournament_df = tournament_df.loc[tournament_df[['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2',\n",
    "                                                 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2',\n",
    "                                                 'LN_A_p1_non_top_8_sets', 'LN_A_p2_non_top_8_sets',\n",
    "                                                 'LN_B_p1_non_top_8_sets', 'LN_B_p2_non_top_8_sets',\n",
    "                                                 'WSF_A_p1_non_top_8_sets', 'WSF_A_p2_non_top_8_sets',\n",
    "                                                 'WSF_B_p1_non_top_8_sets', 'WSF_B_p2_non_top_8_sets']].dropna().index]\n",
    "\n",
    "\n",
    "# Very rarely (not sure where the problem is) you get something not actually in the single-set dataframe\n",
    "# It is not actually that common though, so let's just delete those instances.\n",
    "def references_valid_sets(prev_sets):\n",
    "    for x in prev_sets:\n",
    "        if x[0] not in dataset_df.index:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "filter = tournament_df[['LN_A_p1_non_top_8_sets', 'LN_A_p2_non_top_8_sets',\n",
    "                        'LN_B_p1_non_top_8_sets', 'LN_B_p2_non_top_8_sets',\n",
    "                        'WSF_A_p1_non_top_8_sets', 'WSF_A_p2_non_top_8_sets',\n",
    "                        'WSF_B_p1_non_top_8_sets', 'WSF_B_p2_non_top_8_sets']].map(references_valid_sets).all(axis=1)\n",
    "\n",
    "tournament_df = tournament_df[filter]\n",
    "\n",
    "# Likewise, some of these sets don't seem to have a valid winner\n",
    "tournament_df = tournament_df[~tournament_df['winner_id'].isna()]\n",
    "\n",
    "# A bit more cleanup, for sanity\n",
    "min_date = datetime.datetime(2015,1,1)\n",
    "max_date = datetime.datetime(2024,12,31)\n",
    "\n",
    "tournament_df = tournament_df[(tournament_df['start'] >= min_date) &\n",
    "                              (tournament_df['end'] >= min_date) &\n",
    "                              (tournament_df['start'] <= max_date) &\n",
    "                              (tournament_df['end'] <= max_date)]\n",
    "\n",
    "# We will only be dealing with data from 2023 onwards, because the single-set predictor that we will be using\n",
    "# was trained on data up to the end of 2022, and we don't want it leaking data.\n",
    "# This will also speed up computations by not performing them on data we don't care about.\n",
    "tournament_df = tournament_df[tournament_df['start'] >= datetime.datetime(2023,1,1)]\n",
    "\n",
    "tournament_df.sort_values(by=['end', 'start'], inplace=True)\n",
    "\n",
    "tournament_df[['winner_id', 'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more feature engineering\n",
    "\n",
    "Here, we compute a \"score\" that shows how well a player is doing relative to their skill level and the skill level of their opponents in this tournament. If they are beating players well beyond their normal skill level, their score goes up. If they lose, it goes down.\n",
    "\n",
    "More specifically, we compute the probability that they win, and add the negative log of that probability if they indeed win. Losses are similar, but based on the probability that they lose, and subtracted instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1531552, True), (1531561, True), (1531566, False), (1531590, True)]\n",
      "\n",
      "         p1_default_elo  p2_default_elo  winner  p1_win_prob\n",
      "1531552          1500.0          1500.0     1.0     0.503824\n",
      "1531561          1500.0          1500.0     1.0     0.503824\n",
      "1531566          1500.0          1500.0     1.0     0.503824\n",
      "1531590          1500.0          1500.0     1.0     0.503824\n",
      "\n",
      "Previous set score:  1.3710570335388184\n"
     ]
    }
   ],
   "source": [
    "# Compute a score based on how likely it was that they actually made it to the top.\n",
    "# A sort of sum of negative log probabilities, where wins are positive and losses are negative\n",
    "def prev_set_score(prev_sets):\n",
    "    result = 0\n",
    "\n",
    "    for x in prev_sets:\n",
    "        data = dataset_df.loc[x[0], ['winner', 'p1_win_prob']]\n",
    "        outcome = x[1]\n",
    "\n",
    "        # We don't know if this player is p1 or p2 in this list, but this can determine it without looking at player id\n",
    "        # Compare if (player we are interested in wins) vs (did p1 win)\n",
    "        if outcome == (data['winner'] == 1.0): # The player is p1\n",
    "            if outcome: # player wins, as p1\n",
    "                result += (-np.log(data['p1_win_prob']))\n",
    "            else:       # player loses, as p1\n",
    "                result -= (-np.log(1-data['p1_win_prob']))\n",
    "        else:                                  # The player is p2\n",
    "            if outcome: # player wins, as p2\n",
    "                result += (-np.log(1-data['p1_win_prob']))\n",
    "            else:       # player loses, as p2\n",
    "                result -= (-np.log(data['p1_win_prob']))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example data (note that there is a consistent ELO throughout this entire dataset)\n",
    "prev_sets = tournament_df.iloc[10000]['LN_A_p1_non_top_8_sets']\n",
    "print(prev_sets)\n",
    "print()\n",
    "print(dataset_df.loc[[x[0] for x in prev_sets], ['p1_default_elo', 'p2_default_elo', 'winner', 'p1_win_prob']])\n",
    "print()\n",
    "print(\"Previous set score: \", prev_set_score(tournament_df.iloc[10000]['LN_A_p1_non_top_8_sets']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we will keep track of all of the necessary data for each player in the top 8 by keeping track of what their starting position was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LN_A_p1_non_top_8_sets</th>\n",
       "      <th>LN_A_p2_non_top_8_sets</th>\n",
       "      <th>LN_B_p1_non_top_8_sets</th>\n",
       "      <th>LN_B_p2_non_top_8_sets</th>\n",
       "      <th>WSF_A_p1_non_top_8_sets</th>\n",
       "      <th>WSF_A_p2_non_top_8_sets</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets</th>\n",
       "      <th>LN_A_p1_non_top_8_sets_len</th>\n",
       "      <th>LN_A_p2_non_top_8_sets_len</th>\n",
       "      <th>...</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets_len</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets_len</th>\n",
       "      <th>LN_A_p1_non_top_8_sets_score</th>\n",
       "      <th>LN_A_p2_non_top_8_sets_score</th>\n",
       "      <th>LN_B_p1_non_top_8_sets_score</th>\n",
       "      <th>LN_B_p2_non_top_8_sets_score</th>\n",
       "      <th>WSF_A_p1_non_top_8_sets_score</th>\n",
       "      <th>WSF_A_p2_non_top_8_sets_score</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets_score</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>[(1028338, True), (1028347, True), (1028351, F...</td>\n",
       "      <td>[(1028335, True), (1028345, True), (1028350, F...</td>\n",
       "      <td>[(1028337, True), (1028346, False), (1028361, ...</td>\n",
       "      <td>[(1028330, True), (1028341, True), (1028348, F...</td>\n",
       "      <td>[(1028342, True), (1028349, True)]</td>\n",
       "      <td>[(1028340, True), (1028348, True)]</td>\n",
       "      <td>[(1028344, True), (1028350, True)]</td>\n",
       "      <td>[(1028346, True), (1028351, True)]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>2.056586</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>[(1028523, False), (1028528, True)]</td>\n",
       "      <td>[(1028522, False)]</td>\n",
       "      <td>[(1028521, False)]</td>\n",
       "      <td>[(1028519, True), (1028520, False)]</td>\n",
       "      <td>[(1028520, True)]</td>\n",
       "      <td>[(1028521, True)]</td>\n",
       "      <td>[(1028522, True)]</td>\n",
       "      <td>[(1028523, True)]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.685529</td>\n",
       "      <td>-0.685529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>[(1028465, True), (1028469, False), (1028478, ...</td>\n",
       "      <td>[(1028463, True), (1028468, False), (1028479, ...</td>\n",
       "      <td>[(1028459, True), (1028466, False), (1028477, ...</td>\n",
       "      <td>[(1028461, True), (1028467, False), (1028476, ...</td>\n",
       "      <td>[(1028460, True), (1028467, True)]</td>\n",
       "      <td>[(1028458, True), (1028466, True)]</td>\n",
       "      <td>[(1028464, True), (1028469, True)]</td>\n",
       "      <td>[(1028462, True), (1028468, True)]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.421395</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>1.106924</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>1.371057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>[(1028610, True), (1028614, False), (1028622, ...</td>\n",
       "      <td>[(1028608, True), (1028613, False), (1028623, ...</td>\n",
       "      <td>[(1028606, True), (1028612, False), (1028624, ...</td>\n",
       "      <td>[(1028605, True), (1028611, False), (1028625, ...</td>\n",
       "      <td>[(1028607, True), (1028612, True)]</td>\n",
       "      <td>[(1028611, True)]</td>\n",
       "      <td>[(1028609, True), (1028614, True)]</td>\n",
       "      <td>[(1028613, True)]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>1.371057</td>\n",
       "      <td>0.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>[(1028500, True), (1028504, False)]</td>\n",
       "      <td>[(1028501, True), (1028505, False), (1028510, ...</td>\n",
       "      <td>[(1028500, False), (1028511, True)]</td>\n",
       "      <td>[(1028501, False), (1028512, True)]</td>\n",
       "      <td>[(1028502, True)]</td>\n",
       "      <td>[(1028503, True)]</td>\n",
       "      <td>[(1028504, True)]</td>\n",
       "      <td>[(1028505, True)]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "      <td>0.685529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LN_A_p1_non_top_8_sets  \\\n",
       "18944  [(1028338, True), (1028347, True), (1028351, F...   \n",
       "18951                [(1028523, False), (1028528, True)]   \n",
       "18948  [(1028465, True), (1028469, False), (1028478, ...   \n",
       "18955  [(1028610, True), (1028614, False), (1028622, ...   \n",
       "18950                [(1028500, True), (1028504, False)]   \n",
       "\n",
       "                                  LN_A_p2_non_top_8_sets  \\\n",
       "18944  [(1028335, True), (1028345, True), (1028350, F...   \n",
       "18951                                 [(1028522, False)]   \n",
       "18948  [(1028463, True), (1028468, False), (1028479, ...   \n",
       "18955  [(1028608, True), (1028613, False), (1028623, ...   \n",
       "18950  [(1028501, True), (1028505, False), (1028510, ...   \n",
       "\n",
       "                                  LN_B_p1_non_top_8_sets  \\\n",
       "18944  [(1028337, True), (1028346, False), (1028361, ...   \n",
       "18951                                 [(1028521, False)]   \n",
       "18948  [(1028459, True), (1028466, False), (1028477, ...   \n",
       "18955  [(1028606, True), (1028612, False), (1028624, ...   \n",
       "18950                [(1028500, False), (1028511, True)]   \n",
       "\n",
       "                                  LN_B_p2_non_top_8_sets  \\\n",
       "18944  [(1028330, True), (1028341, True), (1028348, F...   \n",
       "18951                [(1028519, True), (1028520, False)]   \n",
       "18948  [(1028461, True), (1028467, False), (1028476, ...   \n",
       "18955  [(1028605, True), (1028611, False), (1028625, ...   \n",
       "18950                [(1028501, False), (1028512, True)]   \n",
       "\n",
       "                  WSF_A_p1_non_top_8_sets             WSF_A_p2_non_top_8_sets  \\\n",
       "18944  [(1028342, True), (1028349, True)]  [(1028340, True), (1028348, True)]   \n",
       "18951                   [(1028520, True)]                   [(1028521, True)]   \n",
       "18948  [(1028460, True), (1028467, True)]  [(1028458, True), (1028466, True)]   \n",
       "18955  [(1028607, True), (1028612, True)]                   [(1028611, True)]   \n",
       "18950                   [(1028502, True)]                   [(1028503, True)]   \n",
       "\n",
       "                  WSF_B_p1_non_top_8_sets             WSF_B_p2_non_top_8_sets  \\\n",
       "18944  [(1028344, True), (1028350, True)]  [(1028346, True), (1028351, True)]   \n",
       "18951                   [(1028522, True)]                   [(1028523, True)]   \n",
       "18948  [(1028464, True), (1028469, True)]  [(1028462, True), (1028468, True)]   \n",
       "18955  [(1028609, True), (1028614, True)]                   [(1028613, True)]   \n",
       "18950                   [(1028504, True)]                   [(1028505, True)]   \n",
       "\n",
       "       LN_A_p1_non_top_8_sets_len  LN_A_p2_non_top_8_sets_len  ...  \\\n",
       "18944                           4                           4  ...   \n",
       "18951                           2                           1  ...   \n",
       "18948                           3                           3  ...   \n",
       "18955                           3                           3  ...   \n",
       "18950                           2                           3  ...   \n",
       "\n",
       "       WSF_B_p1_non_top_8_sets_len  WSF_B_p2_non_top_8_sets_len  \\\n",
       "18944                            2                            2   \n",
       "18951                            1                            1   \n",
       "18948                            2                            2   \n",
       "18955                            2                            1   \n",
       "18950                            1                            1   \n",
       "\n",
       "       LN_A_p1_non_top_8_sets_score  LN_A_p2_non_top_8_sets_score  \\\n",
       "18944                      1.371057                      1.371057   \n",
       "18951                      0.000000                     -0.685529   \n",
       "18948                      0.685529                      0.421395   \n",
       "18955                      0.685529                      0.685529   \n",
       "18950                      0.000000                      0.685529   \n",
       "\n",
       "       LN_B_p1_non_top_8_sets_score  LN_B_p2_non_top_8_sets_score  \\\n",
       "18944                      2.056586                      1.371057   \n",
       "18951                     -0.685529                      0.000000   \n",
       "18948                      0.685529                      0.949662   \n",
       "18955                      0.685529                      0.685529   \n",
       "18950                      0.000000                      0.000000   \n",
       "\n",
       "       WSF_A_p1_non_top_8_sets_score  WSF_A_p2_non_top_8_sets_score  \\\n",
       "18944                       1.371057                       1.371057   \n",
       "18951                       0.685529                       0.685529   \n",
       "18948                       1.106924                       1.371057   \n",
       "18955                       1.371057                       0.685529   \n",
       "18950                       0.685529                       0.685529   \n",
       "\n",
       "       WSF_B_p1_non_top_8_sets_score  WSF_B_p2_non_top_8_sets_score  \n",
       "18944                       1.371057                       1.371057  \n",
       "18951                       0.685529                       0.685529  \n",
       "18948                       1.371057                       1.371057  \n",
       "18955                       1.371057                       0.685529  \n",
       "18950                       0.685529                       0.685529  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_8_pos = ['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']\n",
    "# top_8_players = [x + '_non_top_8_sets' for x in top_8_pos]\n",
    "top_8_prevs = [x + '_non_top_8_sets' for x in top_8_pos]\n",
    "top_8_prevs_lengths = [x + \"_len\" for x in top_8_prevs] # These columns will just keep track of how many sets the player went through to get to the top 8\n",
    "top_8_prevs_scores = [x + \"_score\" for x in top_8_prevs] # These will keep track of their \"score\" that shows how \"well\" they are performing relative to their predicted odds.\n",
    "\n",
    "tournament_df[top_8_prevs_lengths] = tournament_df[top_8_prevs].map(lambda x: len(x)).to_numpy()\n",
    "tournament_df[top_8_prevs_scores] = tournament_df[top_8_prevs].map(prev_set_score).to_numpy()\n",
    "tournament_df[top_8_prevs + top_8_prevs_lengths + top_8_prevs_scores].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column that contains the top 8 starting position of the winner\n",
    "# (or more specifically, the numeric index in top_8_pos)\n",
    "\n",
    "tournament_df['winner_index'] = 8 # Dummy value, has to be 0-7\n",
    "\n",
    "for i,position in enumerate(top_8_pos):\n",
    "    found_filter = (tournament_df['winner_id'] == tournament_df[top_8_pos[i]])\n",
    "    tournament_df.loc[found_filter, 'winner_index'] = i\n",
    "\n",
    "(tournament_df['winner_index'] == 8).sum() # Should be zero (everything found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start pulling in data (like ELO) for each of the top 8 players in the tournaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to have all of the features we've engineered for each of the players that made it to the top 8\n",
    "# We can be clever and pull most of them (elo-based features) from the previous sets in the dataframe\n",
    "# The rest (player vs player stats, also called \"matchup\", but might be renamed) have to be pulled in manually\n",
    "\n",
    "features_elo = ['p1_default_elo', 'p2_default_elo', 'p1_default_rd', 'p2_default_rd',\n",
    "       'p1_default_updates', 'p2_default_updates', 'p1_m1_usage', 'p2_m1_usage',\n",
    "       'p1/m1/m1_alt2_elo', 'p1/m1/m1_alt2_rd', 'p1/m1/m1_alt2_updates',\n",
    "       'p2/m1/m1_alt2_elo', 'p2/m1/m1_alt2_rd', 'p2/m1/m1_alt2_updates',\n",
    "       'p1/m1_alt3_elo', 'p1/m1_alt3_rd', 'p1/m1_alt3_updates',\n",
    "       'p2/m1_alt3_elo', 'p2/m1_alt3_rd', 'p2/m1_alt3_updates']\n",
    "\n",
    "features_matchup = ['matchup_1', 'matchup_2', 'matchup_3', 'matchup_4', 'matchup_5',\n",
    "                    'matchup_6', 'matchup_7', 'matchup_8', 'matchup_9', 'matchup_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f0daa95794af298c7ab69bf9561d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In order to avoid an organizational nightmare, each of the following:\n",
    "#     'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "# will have their data stored in separate dataframes, each held in the following dictionary\n",
    "\n",
    "top_8_stats = {}\n",
    "\n",
    "def pull_data_from_set(loc, outcome):\n",
    "    set_data = dataset_df.loc[loc]\n",
    "    player_num = 'p1' if outcome == (set_data['winner'] == 1.0) else 'p2' # Sneaky way of getting the player number\n",
    "\n",
    "    features_to_pull = [x for x in features_elo if player_num in x]\n",
    "    pulled_data = set_data[features_to_pull].copy()\n",
    "    pulled_data.index = [x.replace(player_num, '') for x in pulled_data.index] # We will add player numbers on an as-needed basis later\n",
    "\n",
    "    return pulled_data\n",
    "\n",
    "for top_8_position in tqdm(top_8_pos):\n",
    "    # First, pull in player 1 data from a previous match.\n",
    "    # Note that the player might NOT be player 1 in the match that we are pulling from\n",
    "    top_8_stats[top_8_position] = tournament_df[top_8_position + '_non_top_8_sets'].apply(lambda x: pull_data_from_set(x[0][0], x[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important information about the players in the top 8 is essentially how likely each player is to win against the other player. We can use our single-set predictor to estimate this. We can also make use of the information on how well each player has been doing in the tournament relative to their skill level/opponent skill levels, possibly in order to \"adjust\" the aforementioned probabilities. Or just to toss it as extra information in whatever ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600614"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing more than half the data when we look up the matchup data makes it faster by roughly 10x\n",
    "smaller_df = dataset_df[dataset_df['matchup_1']!=.5].sort_values('end').reset_index(drop=True)\n",
    "smaller_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid any sets that do not have a pair of players who have appeared in the same top 8 of some tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7407572d5d4073aa8b8ea483a941d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Assuming 'tournament_df' and 'smaller_df' are your DataFrames\n",
    "\n",
    "# Define the columns that contain the top 8 players in each tournament\n",
    "top_8_columns = [\n",
    "    'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2',\n",
    "    'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "]\n",
    "\n",
    "# Initialize a list to store all unique pairs of players who appeared in the same top 8\n",
    "pairs_list = []\n",
    "\n",
    "# Iterate over each tournament to generate all possible pairs of top 8 players\n",
    "for index, row in tqdm(tournament_df.iterrows()):\n",
    "    # Extract the top 8 players for the current tournament\n",
    "    top_8_players = row[top_8_columns].dropna().unique()\n",
    "    \n",
    "    # Generate all unordered pairs of top 8 players\n",
    "    for p1, p2 in itertools.combinations(top_8_players, 2):\n",
    "        min_id, max_id = sorted([p1, p2])\n",
    "        pairs_list.append({'min_id': min_id, 'max_id': max_id})\n",
    "\n",
    "# Create a DataFrame of all relevant player pairs and remove duplicates\n",
    "relevant_pairs_df = pd.DataFrame(pairs_list).drop_duplicates()\n",
    "\n",
    "# Prepare 'smaller_df' by adding 'min_id' and 'max_id' columns for efficient merging\n",
    "smaller_df['min_id'] = smaller_df[['p1_id', 'p2_id']].min(axis=1)\n",
    "smaller_df['max_id'] = smaller_df[['p1_id', 'p2_id']].max(axis=1)\n",
    "\n",
    "# Merge 'smaller_df' with 'relevant_pairs_df' to filter relevant sets\n",
    "filtered_smaller_df = pd.merge(\n",
    "    smaller_df,\n",
    "    relevant_pairs_df,\n",
    "    on=['min_id', 'max_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Drop the 'min_id' and 'max_id' columns if they are no longer needed\n",
    "filtered_smaller_df = filtered_smaller_df.drop(columns=['min_id', 'max_id'])\n",
    "\n",
    "# The 'filtered_smaller_df' now contains only the relevant sets\n",
    "print(filtered_smaller_df.shape[0])  # This prints the number of relevant sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the slower function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.1 ms Â± 149 Î¼s per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def get_matchup(p1_id, p2_id, start, dataset_df=filtered_smaller_df):\n",
    "    \"\"\"Gets the most recent matchup data from before the start of the tournament.\n",
    "        This is pretty slow and will likely slow down this cell a lot.\n",
    "    Args:\n",
    "        p1_id: The ID of player 1.\n",
    "        p2_id: The ID of player 2.\n",
    "        start: The start of the tournament.\n",
    "        dataset_df: Use only the data that have values other than .5 in matchup_1\n",
    "\n",
    "    Returns:\n",
    "        A pd.Series containing the matchup data or default values if no prior sets exist.\n",
    "    \"\"\"\n",
    "    # Ensure the dataset is sorted by 'end'\n",
    "    assert dataset_df['end'].is_monotonic_increasing, \"Dataset must be sorted by 'end'.\"\n",
    "\n",
    "    # Use NumPy for faster filtering\n",
    "    p1_mask = (dataset_df['p1_id'] == p1_id) & (dataset_df['p2_id'] == p2_id)\n",
    "    p2_mask = (dataset_df['p1_id'] == p2_id) & (dataset_df['p2_id'] == p1_id)\n",
    "    mask = (p1_mask | p2_mask).to_numpy()\n",
    "\n",
    "    # Find indices where mask is True\n",
    "    valid_indices = np.where(mask & (dataset_df['end'].to_numpy() < start))[0]\n",
    "\n",
    "    if len(valid_indices) == 0:\n",
    "        # No prior matches, return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "\n",
    "    # Get the last valid index\n",
    "    last_index = valid_indices[-1]\n",
    "    last_row = dataset_df.iloc[last_index]\n",
    "\n",
    "    # Define matchup columns\n",
    "    matchup_cols = [f'matchup_{n}' for n in range(1, 11)]\n",
    "\n",
    "    # Determine if we need to swap values\n",
    "    if p1_id == last_row['p1_id'] and p2_id == last_row['p2_id']:\n",
    "        return last_row[matchup_cols]\n",
    "    elif p1_id == last_row['p2_id'] and p2_id == last_row['p1_id']:\n",
    "        return 1 - last_row[matchup_cols]\n",
    "    else:\n",
    "        # Should not happen but acts as a fallback\n",
    "        print(\"Matchup Data Failed\")\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "%timeit get_matchup(dataset_df.iloc[1_200_000]['p1_id'], dataset_df.iloc[1_200_000]['p2_id'], dataset_df.iloc[1_200_000]['start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell has the optimized function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 Î¼s Â± 99.7 Î¼s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Assume 'filtered_smaller_df' is your dataset_df\n",
    "dataset_df_2 = filtered_smaller_df.copy()\n",
    "\n",
    "# Create 'min_id' and 'max_id' columns to represent unordered player pairs\n",
    "dataset_df_2['min_id'] = dataset_df_2[['p1_id', 'p2_id']].min(axis=1)\n",
    "dataset_df_2['max_id'] = dataset_df_2[['p1_id', 'p2_id']].max(axis=1)\n",
    "\n",
    "# Create a 'pair_key' column as a tuple of (min_id, max_id)\n",
    "dataset_df_2['pair_key'] = list(zip(dataset_df_2['min_id'], dataset_df_2['max_id']))\n",
    "\n",
    "# Sort the dataset by 'end' to ensure matchups are in chronological order\n",
    "dataset_df_2 = dataset_df_2.sort_values('end').reset_index(drop=True)\n",
    "\n",
    "# Group the dataset by 'pair_key' for efficient lookups\n",
    "grouped_pairs = dataset_df_2.groupby('pair_key', sort=False)\n",
    "\n",
    "def get_matchup(p1_id, p2_id, start, grouped_pairs=grouped_pairs):\n",
    "    \"\"\"Gets the most recent matchup data from before the start of the tournament.\n",
    "    \n",
    "    Args:\n",
    "        p1_id: The ID of player 1.\n",
    "        p2_id: The ID of player 2.\n",
    "        start: The start of the tournament.\n",
    "        grouped_pairs: The preprocessed grouped DataFrame by player pairs.\n",
    "        \n",
    "    Returns:\n",
    "        A pd.Series containing the matchup data or default values if no prior sets exist.\n",
    "    \"\"\"\n",
    "    # Create the pair key\n",
    "    min_id, max_id = min(p1_id, p2_id), max(p1_id, p2_id)\n",
    "    pair_key = (min_id, max_id)\n",
    "    \n",
    "    # Check if the pair exists in the grouped data\n",
    "    if pair_key not in grouped_pairs.groups:\n",
    "        # No prior matches, return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "    # Get the group DataFrame for the pair\n",
    "    group_df = grouped_pairs.get_group(pair_key)\n",
    "    \n",
    "    # Filter matches that occurred before the 'start' time\n",
    "    prior_matches = group_df[group_df['end'] < start]\n",
    "    \n",
    "    if prior_matches.empty:\n",
    "        # No prior matches before 'start', return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "    # Get the last match (most recent before 'start')\n",
    "    last_row = prior_matches.iloc[-1]\n",
    "    \n",
    "    # Define matchup columns\n",
    "    matchup_cols = [f'matchup_{n}' for n in range(1, 11)]\n",
    "    \n",
    "    # Determine if we need to swap the matchup data\n",
    "    if (p1_id == last_row['p1_id']) and (p2_id == last_row['p2_id']):\n",
    "        return last_row[matchup_cols]\n",
    "    elif (p1_id == last_row['p2_id']) and (p2_id == last_row['p1_id']):\n",
    "        return 1 - last_row[matchup_cols]\n",
    "        # This case should not occur but acts as a fallback\n",
    "        print(\"Matchup Data Failed\")\n",
    "        return pd.Series(0.5, index=matchup_cols)\n",
    "\n",
    "%timeit get_matchup(dataset_df.iloc[1_200_000]['p1_id'], dataset_df.iloc[1_200_000]['p2_id'], dataset_df.iloc[1_200_000]['start'], grouped_pairs=grouped_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f11b62581246f7b2e9bd42bec42716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairprob/LN_A_p1/LN_A_p1</th>\n",
       "      <th>pairprob/LN_A_p1/LN_A_p2</th>\n",
       "      <th>pairprob/LN_A_p1/LN_B_p1</th>\n",
       "      <th>pairprob/LN_A_p1/LN_B_p2</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_A_p1</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_A_p2</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_B_p1</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_B_p2</th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p2</th>\n",
       "      <th>...</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.358827</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.387373</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.339546</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493806</td>\n",
       "      <td>0.660454</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.530489</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.531903</td>\n",
       "      <td>0.380909</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.370281</td>\n",
       "      <td>0.318002</td>\n",
       "      <td>0.370281</td>\n",
       "      <td>0.468097</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.537121</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.679337</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.462879</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.370281</td>\n",
       "      <td>0.572470</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.361518</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.452239</td>\n",
       "      <td>0.638482</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.330488</td>\n",
       "      <td>0.660067</td>\n",
       "      <td>0.547761</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.370281</td>\n",
       "      <td>0.660067</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.339546</td>\n",
       "      <td>0.436023</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.578557</td>\n",
       "      <td>0.563977</td>\n",
       "      <td>0.598873</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.594981</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.421443</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pairprob/LN_A_p1/LN_A_p1  pairprob/LN_A_p1/LN_A_p2  \\\n",
       "18944                       0.5                  0.500000   \n",
       "18951                       0.5                  0.500000   \n",
       "18948                       0.5                  0.387373   \n",
       "18955                       0.5                  0.500000   \n",
       "18950                       0.5                  0.500000   \n",
       "...                         ...                       ...   \n",
       "39657                       0.5                  0.500000   \n",
       "39672                       0.5                  0.531903   \n",
       "39598                       0.5                  0.500000   \n",
       "39031                       0.5                  0.370281   \n",
       "31228                       0.5                  0.500000   \n",
       "\n",
       "       pairprob/LN_A_p1/LN_B_p1  pairprob/LN_A_p1/LN_B_p2  \\\n",
       "18944                  0.500000                  0.500000   \n",
       "18951                  0.500000                  0.500000   \n",
       "18948                  0.500000                  0.369366   \n",
       "18955                  0.530489                  0.500000   \n",
       "18950                  0.500000                  0.500000   \n",
       "...                         ...                       ...   \n",
       "39657                  0.500000                  0.500000   \n",
       "39672                  0.380909                  0.500000   \n",
       "39598                  0.500000                  0.500000   \n",
       "39031                  0.660067                  0.617841   \n",
       "31228                  0.500000                  0.500000   \n",
       "\n",
       "       pairprob/LN_A_p1/WSF_A_p1  pairprob/LN_A_p1/WSF_A_p2  \\\n",
       "18944                   0.500000                   0.500000   \n",
       "18951                   0.500000                   0.369366   \n",
       "18948                   0.500000                   0.500000   \n",
       "18955                   0.500000                   0.369366   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.369366                   0.500000   \n",
       "39672                   0.500000                   0.370281   \n",
       "39598                   0.370281                   0.572470   \n",
       "39031                   0.339933                   0.339933   \n",
       "31228                   0.500000                   0.500000   \n",
       "\n",
       "       pairprob/LN_A_p1/WSF_B_p1  pairprob/LN_A_p1/WSF_B_p2  \\\n",
       "18944                   0.500000                   0.369366   \n",
       "18951                   0.500000                   0.500000   \n",
       "18948                   0.500000                   0.500000   \n",
       "18955                   0.320943                   0.500000   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.500000                   0.500000   \n",
       "39672                   0.318002                   0.370281   \n",
       "39598                   0.369366                   0.361518   \n",
       "39031                   0.339546                   0.436023   \n",
       "31228                   0.500000                   0.500000   \n",
       "\n",
       "       pairprob/LN_A_p2/LN_A_p1  pairprob/LN_A_p2/LN_A_p2  ...  \\\n",
       "18944                  0.500000                       0.5  ...   \n",
       "18951                  0.500000                       0.5  ...   \n",
       "18948                  0.612627                       0.5  ...   \n",
       "18955                  0.500000                       0.5  ...   \n",
       "18950                  0.500000                       0.5  ...   \n",
       "...                         ...                       ...  ...   \n",
       "39657                  0.500000                       0.5  ...   \n",
       "39672                  0.468097                       0.5  ...   \n",
       "39598                  0.500000                       0.5  ...   \n",
       "39031                  0.629719                       0.5  ...   \n",
       "31228                  0.500000                       0.5  ...   \n",
       "\n",
       "       pairprob/WSF_B_p1/WSF_B_p1  pairprob/WSF_B_p1/WSF_B_p2  \\\n",
       "18944                         0.5                    0.500000   \n",
       "18951                         0.5                    0.500000   \n",
       "18948                         0.5                    0.339546   \n",
       "18955                         0.5                    0.369366   \n",
       "18950                         0.5                    0.500000   \n",
       "...                           ...                         ...   \n",
       "39657                         0.5                    0.500000   \n",
       "39672                         0.5                    0.537121   \n",
       "39598                         0.5                    0.452239   \n",
       "39031                         0.5                    0.578557   \n",
       "31228                         0.5                    0.500000   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_A_p1  pairprob/WSF_B_p2/LN_A_p2  \\\n",
       "18944                   0.630634                   0.500000   \n",
       "18951                   0.500000                   0.500000   \n",
       "18948                   0.500000                   0.629719   \n",
       "18955                   0.500000                   0.500000   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.500000                   0.500000   \n",
       "39672                   0.629719                   0.679337   \n",
       "39598                   0.638482                   0.630634   \n",
       "39031                   0.563977                   0.598873   \n",
       "31228                   0.500000                   0.500000   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_B_p1  pairprob/WSF_B_p2/LN_B_p2  \\\n",
       "18944                   0.500000                   0.500000   \n",
       "18951                   0.500000                   0.500000   \n",
       "18948                   0.500000                   0.612627   \n",
       "18955                   0.500000                   0.500000   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.500000                   0.500000   \n",
       "39672                   0.630634                   0.369366   \n",
       "39598                   0.500000                   0.500000   \n",
       "39031                   0.630634                   0.630634   \n",
       "31228                   0.500000                   0.629719   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_A_p1  pairprob/WSF_B_p2/WSF_A_p2  \\\n",
       "18944                    0.630634                    0.358827   \n",
       "18951                    0.500000                    0.500000   \n",
       "18948                    0.500000                    0.493806   \n",
       "18955                    0.500000                    0.500000   \n",
       "18950                    0.369366                    0.500000   \n",
       "...                           ...                         ...   \n",
       "39657                    0.500000                    0.500000   \n",
       "39672                    0.500000                    0.339933   \n",
       "39598                    0.330488                    0.660067   \n",
       "39031                    0.594981                    0.339933   \n",
       "31228                    0.630634                    0.630634   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_B_p1  pairprob/WSF_B_p2/WSF_B_p2  \n",
       "18944                    0.500000                         0.5  \n",
       "18951                    0.500000                         0.5  \n",
       "18948                    0.660454                         0.5  \n",
       "18955                    0.630634                         0.5  \n",
       "18950                    0.500000                         0.5  \n",
       "...                           ...                         ...  \n",
       "39657                    0.500000                         0.5  \n",
       "39672                    0.462879                         0.5  \n",
       "39598                    0.547761                         0.5  \n",
       "39031                    0.421443                         0.5  \n",
       "31228                    0.500000                         0.5  \n",
       "\n",
       "[15293 rows x 64 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "\n",
    "\n",
    "# First, let's compute pairwise probabilities of one player in the top 8 winning against another player\n",
    "def compute_pairwise_prob(row):\n",
    "    # Row represents p1, column represents p2 (or specifically, the index in top_8_pos). Always follows this order:\n",
    "    players=['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']\n",
    "    pairwise_probs = np.zeros(shape=(8,8))\n",
    "    # pairwise_probs = np.full((8, 8), 0.5)\n",
    "    \n",
    "    # For convenience, put everything into one dataframe and then run the single set model\n",
    "    # This is probably more efficient than doing things line by line\n",
    "    combination_stats = []\n",
    "\n",
    "    for r in range(0,8):\n",
    "        for c in range(0,8):\n",
    "            p1_data = top_8_stats[top_8_pos[r]].loc[row.name]\n",
    "            p1_data.index = ['p1' + x for x in p1_data.index]\n",
    "\n",
    "            p2_data = top_8_stats[top_8_pos[c]].loc[row.name]\n",
    "            p2_data.index = ['p2' + x for x in p2_data.index]\n",
    "\n",
    "            #TODO: Actually populate this with proper data!\n",
    "            #      This is currently only just placeholder data,\n",
    "            #      indicating that the players have never played together before (0.5).\n",
    "            matchup_data = get_matchup(row[players[r]], row[players[c]], row['start'], grouped_pairs=grouped_pairs)\n",
    "\n",
    "            total_data = pd.concat([p1_data, p2_data, matchup_data])\n",
    "            total_data = total_data[features_all_everything] # Entries need to be in the correct order\n",
    "\n",
    "            combination_stats.append(total_data)\n",
    "\n",
    "    combination_stats = pd.DataFrame(combination_stats)\n",
    "\n",
    "    y_prob = single_set_model.predict_proba(combination_stats)\n",
    "\n",
    "    # Now actually populate this probability matrix with data.\n",
    "    # Note that we can just use the same nested loop and read off the entries of the 1D probability array one at a time.\n",
    "    # This will put things in the correct order.\n",
    "    i = 0\n",
    "    for r in range(0,8):\n",
    "        for c in range(0,8):\n",
    "            pairwise_probs[r,c] = y_prob[i,1]\n",
    "            i += 1\n",
    "\n",
    "    # NOTE: Some models that we train are highly non-symmetric, even though they very much should be,\n",
    "    #       given that we have randomized the players. We can fix that issue here.\n",
    "    pairwise_probs = 0.5 * (pairwise_probs + (1 - pairwise_probs.T))\n",
    "\n",
    "    return pairwise_probs.flatten()\n",
    "\n",
    "pairwise_prob = tournament_df.progress_apply(compute_pairwise_prob, axis=1)\n",
    "pairwise_prob = np.stack(pairwise_prob.to_numpy()) # Fixes \"single column of np arrays\" nonsense\n",
    "\n",
    "# Add that data as columns in the original dataframe\n",
    "pairwise_prob_cols = []\n",
    "for r in range(0,8):\n",
    "    for c in range(0,8):\n",
    "        pairwise_prob_cols.append(\"pairprob/\" + top_8_pos[r] + \"/\" + top_8_pos[c])\n",
    "\n",
    "tournament_df[pairwise_prob_cols] = pairwise_prob\n",
    "\n",
    "tournament_df[pairwise_prob_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p1/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p1/LN_A_p2</th>\n",
       "      <th>pairprob/LN_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/LN_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_B_p2</th>\n",
       "      <th>...</th>\n",
       "      <th>pairprob/WSF_B_p1/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.358827</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.578557</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.586920</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660067</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493806</td>\n",
       "      <td>0.660454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.469511</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339546</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>0.468097</td>\n",
       "      <td>0.619091</td>\n",
       "      <td>0.403177</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.431827</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.679337</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.462879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.334028</td>\n",
       "      <td>0.369366</td>\n",
       "      <td>0.638482</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.330488</td>\n",
       "      <td>0.660067</td>\n",
       "      <td>0.547761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.320663</td>\n",
       "      <td>0.382159</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.319215</td>\n",
       "      <td>0.660067</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.641173</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.403177</td>\n",
       "      <td>0.318002</td>\n",
       "      <td>0.563977</td>\n",
       "      <td>0.598873</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.594981</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.421443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612627</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400530</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629719</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.630634</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pairprob/LN_A_p2/LN_A_p1  pairprob/LN_B_p1/LN_A_p1  \\\n",
       "18944                  0.500000                  0.500000   \n",
       "18951                  0.500000                  0.500000   \n",
       "18948                  0.612627                  0.500000   \n",
       "18955                  0.500000                  0.469511   \n",
       "18950                  0.500000                  0.500000   \n",
       "...                         ...                       ...   \n",
       "39657                  0.500000                  0.500000   \n",
       "39672                  0.468097                  0.619091   \n",
       "39598                  0.500000                  0.500000   \n",
       "39031                  0.629719                  0.339933   \n",
       "31228                  0.500000                  0.500000   \n",
       "\n",
       "       pairprob/LN_B_p1/LN_A_p2  pairprob/LN_B_p2/LN_A_p1  \\\n",
       "18944                  0.500000                  0.500000   \n",
       "18951                  0.500000                  0.500000   \n",
       "18948                  0.500000                  0.630634   \n",
       "18955                  0.500000                  0.500000   \n",
       "18950                  0.500000                  0.500000   \n",
       "...                         ...                       ...   \n",
       "39657                  0.500000                  0.500000   \n",
       "39672                  0.403177                  0.500000   \n",
       "39598                  0.500000                  0.500000   \n",
       "39031                  0.320663                  0.382159   \n",
       "31228                  0.500000                  0.500000   \n",
       "\n",
       "       pairprob/LN_B_p2/LN_A_p2  pairprob/LN_B_p2/LN_B_p1  \\\n",
       "18944                  0.500000                  0.500000   \n",
       "18951                  0.500000                  0.500000   \n",
       "18948                  0.578557                  0.500000   \n",
       "18955                  0.500000                  0.500000   \n",
       "18950                  0.500000                  0.500000   \n",
       "...                         ...                       ...   \n",
       "39657                  0.500000                  0.500000   \n",
       "39672                  0.500000                  0.630634   \n",
       "39598                  0.500000                  0.500000   \n",
       "39031                  0.500000                  0.319215   \n",
       "31228                  0.500000                  0.500000   \n",
       "\n",
       "       pairprob/WSF_A_p1/LN_A_p1  pairprob/WSF_A_p1/LN_A_p2  \\\n",
       "18944                   0.500000                   0.500000   \n",
       "18951                   0.500000                   0.500000   \n",
       "18948                   0.500000                   0.586920   \n",
       "18955                   0.500000                   0.500000   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.630634                   0.500000   \n",
       "39672                   0.500000                   0.500000   \n",
       "39598                   0.629719                   0.630634   \n",
       "39031                   0.660067                   0.500000   \n",
       "31228                   0.500000                   0.612627   \n",
       "\n",
       "       pairprob/WSF_A_p1/LN_B_p1  pairprob/WSF_A_p1/LN_B_p2  ...  \\\n",
       "18944                   0.500000                   0.500000  ...   \n",
       "18951                   0.500000                   0.500000  ...   \n",
       "18948                   0.500000                   0.500000  ...   \n",
       "18955                   0.500000                   0.500000  ...   \n",
       "18950                   0.500000                   0.500000  ...   \n",
       "...                          ...                        ...  ...   \n",
       "39657                   0.500000                   0.500000  ...   \n",
       "39672                   0.500000                   0.500000  ...   \n",
       "39598                   0.500000                   0.630634  ...   \n",
       "39031                   0.641173                   0.500000  ...   \n",
       "31228                   0.629719                   0.630634  ...   \n",
       "\n",
       "       pairprob/WSF_B_p1/LN_B_p2  pairprob/WSF_B_p1/WSF_A_p1  \\\n",
       "18944                   0.500000                    0.500000   \n",
       "18951                   0.500000                    0.500000   \n",
       "18948                   0.660067                    0.612627   \n",
       "18955                   0.500000                    0.500000   \n",
       "18950                   0.500000                    0.500000   \n",
       "...                          ...                         ...   \n",
       "39657                   0.500000                    0.500000   \n",
       "39672                   0.500000                    0.500000   \n",
       "39598                   0.500000                    0.334028   \n",
       "39031                   0.612627                    0.403177   \n",
       "31228                   0.500000                    0.500000   \n",
       "\n",
       "       pairprob/WSF_B_p1/WSF_A_p2  pairprob/WSF_B_p2/LN_A_p1  \\\n",
       "18944                    0.500000                   0.630634   \n",
       "18951                    0.500000                   0.500000   \n",
       "18948                    0.369366                   0.500000   \n",
       "18955                    0.339546                   0.500000   \n",
       "18950                    0.500000                   0.500000   \n",
       "...                           ...                        ...   \n",
       "39657                    0.500000                   0.500000   \n",
       "39672                    0.431827                   0.629719   \n",
       "39598                    0.369366                   0.638482   \n",
       "39031                    0.318002                   0.563977   \n",
       "31228                    0.400530                   0.500000   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_A_p2  pairprob/WSF_B_p2/LN_B_p1  \\\n",
       "18944                   0.500000                   0.500000   \n",
       "18951                   0.500000                   0.500000   \n",
       "18948                   0.629719                   0.500000   \n",
       "18955                   0.500000                   0.500000   \n",
       "18950                   0.500000                   0.500000   \n",
       "...                          ...                        ...   \n",
       "39657                   0.500000                   0.500000   \n",
       "39672                   0.679337                   0.630634   \n",
       "39598                   0.630634                   0.500000   \n",
       "39031                   0.598873                   0.630634   \n",
       "31228                   0.500000                   0.500000   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_B_p2  pairprob/WSF_B_p2/WSF_A_p1  \\\n",
       "18944                   0.500000                    0.630634   \n",
       "18951                   0.500000                    0.500000   \n",
       "18948                   0.612627                    0.500000   \n",
       "18955                   0.500000                    0.500000   \n",
       "18950                   0.500000                    0.369366   \n",
       "...                          ...                         ...   \n",
       "39657                   0.500000                    0.500000   \n",
       "39672                   0.369366                    0.500000   \n",
       "39598                   0.500000                    0.330488   \n",
       "39031                   0.630634                    0.594981   \n",
       "31228                   0.629719                    0.630634   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_A_p2  pairprob/WSF_B_p2/WSF_B_p1  \n",
       "18944                    0.358827                    0.500000  \n",
       "18951                    0.500000                    0.500000  \n",
       "18948                    0.493806                    0.660454  \n",
       "18955                    0.500000                    0.630634  \n",
       "18950                    0.500000                    0.500000  \n",
       "...                           ...                         ...  \n",
       "39657                    0.500000                    0.500000  \n",
       "39672                    0.339933                    0.462879  \n",
       "39598                    0.660067                    0.547761  \n",
       "39031                    0.339933                    0.421443  \n",
       "31228                    0.630634                    0.500000  \n",
       "\n",
       "[15293 rows x 28 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add that data as columns in the original dataframe\n",
    "\n",
    "# Note that we only really need the strictly lower triangular part of the probability matrix\n",
    "# Everything else is redundant (the diagonal is 0.5, upper triangular part is 1 - lower triangular)\n",
    "# The entire matrix is kept in there just for easy reading.\n",
    "\n",
    "pairwise_prob_cols = []\n",
    "pairwise_prob_cols_reduced = []\n",
    "\n",
    "for r in range(0,8):\n",
    "    for c in range(0,8):\n",
    "        col_name = \"pairprob/\" + top_8_pos[r] + \"/\" + top_8_pos[c]\n",
    "\n",
    "        pairwise_prob_cols.append(col_name)\n",
    "\n",
    "        if r > c:\n",
    "            pairwise_prob_cols_reduced.append(col_name)\n",
    "\n",
    "tournament_df[pairwise_prob_cols] = pairwise_prob\n",
    "tournament_df[pairwise_prob_cols_reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can (disclaimer: slightly inaccurately) compute all possible paths throughout the top 8, and the probability of winning along each path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slighltly incorrectly implemented algorithm that goes through all possible paths throughout the top 8,\n",
    "# and computes the corresponding probabilities of each player making it through.\n",
    "def compute_path_prob(row):\n",
    "    pairwise_probs = row[pairwise_prob_cols].to_numpy().astype(float).reshape((8,8))\n",
    "    pairwise_probs_zero_diagonal = pairwise_probs - 0.5 * np.identity(8) # Used for janky computations\n",
    "\n",
    "    # Now start building the tree structure of how the tournament can play out.\n",
    "    # Each \"cell\" will represent some set in the tournament played by some p1 and p2.\n",
    "    # The cell will have to keep track of all of the probabilities of each player making it to that point.\n",
    "    #\n",
    "    # Links should have the form (cell, 'winner') or (cell, 'loser'),\n",
    "    # describing if it is the winner or the loser of the previous that gets to this one\n",
    "    class cell:\n",
    "        def __init__(self, p1=None, p2=None, p1_link=None, p2_link=None):\n",
    "            if p1==None:\n",
    "                self.p1_probs = None\n",
    "            else:\n",
    "                self.p1_probs = np.zeros(8)\n",
    "                self.p1_probs[p1] = 1.0\n",
    "\n",
    "            if p2==None:\n",
    "                self.p2_probs = None\n",
    "            else:\n",
    "                self.p2_probs = np.zeros(8)\n",
    "                self.p2_probs[p2] = 1.0\n",
    "\n",
    "            # Links to previous cells\n",
    "            self.p1_link = p1_link\n",
    "            self.p2_link = p2_link\n",
    "\n",
    "            # Used for a (hopefully) temporary patch on the fact that these computations are not entirely accurate\n",
    "            self.pairwise_probs_zero_diagonal = pairwise_probs - 0.5 * np.identity(8)\n",
    "\n",
    "        # Get the probabilities from the previous cell.\n",
    "        # Should not be called if there are no links to previous cells.\n",
    "        def fetch_probs(self):\n",
    "            self.p1_probs = self.p1_link[0].compute_winner_probs() if self.p1_link[1] == 'winner' else self.p1_link[0].compute_loser_probs()\n",
    "            self.p2_probs = self.p2_link[0].compute_winner_probs() if self.p2_link[1] == 'winner' else self.p2_link[0].compute_loser_probs()\n",
    "        \n",
    "        # Probability of making it to this cell, and then proceeding to win\n",
    "        def compute_winner_probs(self):\n",
    "            if self.p1_probs is None or self.p2_probs is None:\n",
    "                self.fetch_probs()\n",
    "\n",
    "            probs = np.zeros(8)\n",
    "\n",
    "            # Old code, far less efficient. Might make the numpy operations make sense though.\n",
    "            '''\n",
    "            for p1 in range(0,8):\n",
    "                # Save a result for p1.\n",
    "                # It will be the sum over all p2 of\n",
    "                # (probability that p1 got there) * (probability that p2 got there) * (probability p1 beats p2)\n",
    "                for p2 in range(0,8):\n",
    "                    probs[p1] += self.p1_probs[p1] * self.p2_probs[p2] * pairwise_probs[p1, p2]\n",
    "                    probs[p2] += self.p1_probs[p1] * self.p2_probs[p2] * (1.0 - pairwise_probs[p1, p2])\n",
    "            '''\n",
    "            # Just remember that 1-pairwise_probs is the transpose of pairwise_probs, by symmetry\n",
    "            #\n",
    "            # TODO: I just realized that the probability of a certain player becoming p1 and another becoming p2 are NOT independent.\n",
    "            #       In particular, these probabilities become correlated when you could potentially have the same player as p1 or p2.\n",
    "            #       This is a bit of a janky patch that hopefully gives accurate enough probabilities, but we should come up with a proper fix.       \n",
    "            probs += self.p1_probs * (pairwise_probs_zero_diagonal @ self.p2_probs) # Probability that (specific p1) wins\n",
    "            probs += self.p2_probs * (pairwise_probs_zero_diagonal @ self.p1_probs) # Same but p2\n",
    "\n",
    "            probs /= probs.sum() # Purely due to zeroing out the diagonal of pairwise_probs\n",
    "\n",
    "            return probs\n",
    "\n",
    "        # Probability of making it to this cell, and then proceeding to lose\n",
    "        def compute_loser_probs(self):\n",
    "            if self.p1_probs is None or self.p2_probs is None:\n",
    "                self.fetch_probs()\n",
    "\n",
    "            probs = np.zeros(8)\n",
    "\n",
    "            '''\n",
    "            for p1 in range(0,8):\n",
    "                # Same, except use probability of p1 losing\n",
    "                for p2 in range(0,8):\n",
    "                    probs[p1] += self.p1_probs[p1] * self.p2_probs[p2] * (1.0 - pairwise_probs[p1, p2])\n",
    "                    probs[p2] += self.p1_probs[p1] * self.p2_probs[p2] * pairwise_probs[p1, p2]\n",
    "            '''\n",
    "            # TODO: Same janky patch as in winners case here.\n",
    "            probs += self.p1_probs * (pairwise_probs_zero_diagonal.T @ self.p2_probs)\n",
    "            probs += self.p2_probs * (pairwise_probs_zero_diagonal.T @ self.p1_probs)\n",
    "\n",
    "            probs /= probs.sum()\n",
    "             \n",
    "            return probs\n",
    "        \n",
    "    # 'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "    WSFA = cell(p1=4, p2=5)\n",
    "    WSFB = cell(p1=6, p2=7)\n",
    "    LNA  = cell(p1=0, p2=1)\n",
    "    LNB  = cell(p1=2, p2=3)\n",
    "\n",
    "    WF = cell(p1_link=(WSFA, 'winner'), p2_link=(WSFB, 'winner'))\n",
    "\n",
    "    LQFA = cell(p1_link=(WSFA, 'loser'), p2_link=(LNA, 'winner'))\n",
    "    LQFB = cell(p1_link=(WSFB, 'loser'), p2_link=(LNB, 'winner'))\n",
    "\n",
    "    LSF = cell(p1_link=(LQFA, 'winner'), p2_link=(LQFB, 'winner'))\n",
    "\n",
    "    LF = cell(p1_link=(WF, 'loser'), p2_link=(LSF, 'winner'))\n",
    "\n",
    "    GF = cell(p1_link=(WF, 'winner'), p2_link=(LF, 'winner'))\n",
    "\n",
    "    # From the Grand Final onwards, some special cases are required, due to how the Grand Final Reset works\n",
    "    GF.fetch_probs()\n",
    "\n",
    "    # TODO: Again, same janky fix as before, \"removing\" correlation between p1 and p2\n",
    "    win_as_p1_probs = GF.p1_probs * (pairwise_probs_zero_diagonal @ GF.p2_probs) # direct win as p1 (WF winner)\n",
    "    win_as_p1_probs += GF.p1_probs * ((pairwise_probs_zero_diagonal.T * pairwise_probs_zero_diagonal) @ GF.p2_probs) # p2 win, then p1 win in GFR\n",
    "\n",
    "    win_as_p2_probs = GF.p2_probs * ((pairwise_probs_zero_diagonal ** 2) @ GF.p1_probs) # win by 2 required for LF winner\n",
    "\n",
    "    probs = win_as_p1_probs + win_as_p2_probs\n",
    "    probs /= probs.sum() # Again due to that janky fix\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking and baselines\n",
    "\n",
    "Here, we start comparing the performance of a few \"obvious\" models, such as just choosing the person with the highest ELO out of the top 8 (or winners' side of the top 8), or simulating all possible paths throughout the top 8 and computing the probability of winning as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features += pairwise_prob_cols_reduced\n",
    "features += top_8_prevs_lengths + top_8_prevs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline of \"who has the higher elo\"\n",
    "\n",
    "def pull_elo_from_set(loc, outcome):\n",
    "    set_data = dataset_df.loc[loc]\n",
    "    player_num = 'p1' if outcome == (set_data['winner'] == 1.0) else 'p2' # Sneaky way of getting the player number\n",
    "\n",
    "    feature_to_pull = player_num + '_default_elo'\n",
    "    pulled_data = set_data[feature_to_pull]\n",
    "\n",
    "    return pulled_data\n",
    "\n",
    "# First, pull in player 1 data from a previous match.\n",
    "# Note that the player might NOT be player 1 in the match that we are pulling from\n",
    "tournament_df[[x + '_elo' for x in top_8_pos]] = tournament_df[[x + '_non_top_8_sets' for x in top_8_pos]].map(lambda x: pull_elo_from_set(x[0][0], x[0][1])).to_numpy()\n",
    "\n",
    "tournament_df['elo_prediction'] = tournament_df[[x + '_elo' for x in top_8_pos]].idxmax(axis=1).apply(lambda x: x.replace('_elo', ''))\n",
    "tournament_df['elo_prediction'] = tournament_df['elo_prediction'].apply(lambda x: top_8_pos.index(x))\n",
    "\n",
    "tournament_df['elo_WSF_prediction'] = tournament_df[[x + '_elo' for x in top_8_pos if \"WSF\" in x]].idxmax(axis=1).apply(lambda x: x.replace('_elo', ''))\n",
    "tournament_df['elo_WSF_prediction'] = tournament_df['elo_WSF_prediction'].apply(lambda x: top_8_pos.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor of \"who has the highest path probability, taking into account all possible paths on how the top 8 will play out\"\n",
    "\n",
    "result = tournament_df.apply(compute_path_prob, axis=1)\n",
    "tournament_df = pd.concat([tournament_df, pd.DataFrame(np.stack(result.to_numpy()), index=result.index, columns=[x + '_winprob' for x in top_8_pos])], axis=1)\n",
    "\n",
    "tournament_df['path_prediction'] = tournament_df[[x + '_winprob' for x in top_8_pos]].idxmax(axis=1).apply(lambda x: x.replace('_winprob', ''))\n",
    "tournament_df['path_prediction'] = tournament_df['path_prediction'].apply(lambda x: top_8_pos.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tournament_df[(tournament_df['start'] >= datetime.datetime(2023,1,1)) & (tournament_df['end'] <= datetime.datetime(2023,12,31))].copy()\n",
    "test_df  = tournament_df[(tournament_df['start'] >= datetime.datetime(2024,1,1)) & (tournament_df['end'] <= datetime.datetime(2024,12,31))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set baselines:\n",
      "Highest ELO out of top 8, accuracy:                0.5\n",
      "Highest ELO out of WSF, accuracy:                  35.6\n",
      "Computing all ways top 8 can play out, accuracy:   57.7\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set baselines:\")\n",
    "print(\"Highest ELO out of top 8, accuracy:               \", round(100.0 * (train_df['winner_index'] == train_df['elo_prediction']).astype(float).mean(), 1))\n",
    "print(\"Highest ELO out of WSF, accuracy:                 \", round(100.0 * (train_df['winner_index'] == train_df['elo_WSF_prediction']).astype(float).mean(), 1))\n",
    "print(\"Computing all ways top 8 can play out, accuracy:  \", round(100.0 * (train_df['winner_index'] == train_df['path_prediction']).astype(float).mean(), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more advanced model and hyperparameter tuning\n",
    "\n",
    "Just because choosing the highest ELO seems to be such a powerful predictor to begin with, we will make sure to add those to the list of features that we will use. We won't add any of the other old engineered features, because the model already has a bunch of new \"fancier\" engineered features, and too many might make it perform worse.\n",
    "\n",
    "**NOTE:** Hyperparameter tuning trials was reduced down to a very low number, so that this entire notebook could be run in a reasonable amount of time. Optimal parameters from a proper number of trials have already been found and are already provided after the hyperparameter tuning block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [x + '_elo' for x in top_8_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling ELO!\n"
     ]
    }
   ],
   "source": [
    "# Some features should NOT be scaled, like probabilities.\n",
    "# Let's just manually scale ELO (note that we will be using regularization)\n",
    "if tournament_df[[x + '_elo' for x in top_8_pos][0]].mean() >= 400.0: # Prevents this from accidentally being run twice.\n",
    "    print(\"Scaling ELO!\")\n",
    "    tournament_df[[x + '_elo' for x in top_8_pos]] /= 1500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 17:16:55,899] A new study created in memory with name: no-name-cfe781bc-4e8f-4b9d-ada7-bb8949ba18f2\n",
      "[I 2024-11-29 17:17:06,347] Trial 0 finished with value: 0.6285657639887958 and parameters: {'max_depth': 4, 'learning_rate': 0.060837364058206556, 'n_estimators': 450, 'subsample': 0.6438767271165243, 'colsample_bytree': 0.9355679560877713, 'gamma': 2.78242915137471, 'min_child_weight': 2, 'lambda': 0.061206871371436794, 'alpha': 0.0649397153599502}. Best is trial 0 with value: 0.6285657639887958.\n",
      "[I 2024-11-29 17:17:07,324] Trial 1 finished with value: 0.6269159664007944 and parameters: {'max_depth': 4, 'learning_rate': 0.0677847159104045, 'n_estimators': 150, 'subsample': 0.734077969632672, 'colsample_bytree': 0.9619273019344874, 'gamma': 3.5112062966734205, 'min_child_weight': 5, 'lambda': 8.019597176001758, 'alpha': 0.045275689176209104}. Best is trial 0 with value: 0.6285657639887958.\n",
      "[I 2024-11-29 17:17:10,404] Trial 2 finished with value: 0.6296325856487718 and parameters: {'max_depth': 6, 'learning_rate': 0.059179156541488726, 'n_estimators': 400, 'subsample': 0.9907451568123322, 'colsample_bytree': 0.6629042257544608, 'gamma': 1.6959386013762778, 'min_child_weight': 5, 'lambda': 0.30930621405743247, 'alpha': 4.077449611700586}. Best is trial 2 with value: 0.6296325856487718.\n",
      "[I 2024-11-29 17:17:40,588] Trial 3 finished with value: 0.6303118675507612 and parameters: {'max_depth': 6, 'learning_rate': 0.016304739602902737, 'n_estimators': 650, 'subsample': 0.7749465805467357, 'colsample_bytree': 0.7661963755069445, 'gamma': 3.401056835924059, 'min_child_weight': 8, 'lambda': 0.08015778171340451, 'alpha': 0.11684396769964843}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:17:57,349] Trial 4 finished with value: 0.6186686165096117 and parameters: {'max_depth': 2, 'learning_rate': 0.012074322546871123, 'n_estimators': 350, 'subsample': 0.8958684144207693, 'colsample_bytree': 0.9269533904146137, 'gamma': 4.174595186005317, 'min_child_weight': 2, 'lambda': 0.10643691956006887, 'alpha': 0.04822586715895501}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:18:47,978] Trial 5 finished with value: 0.6285651709021526 and parameters: {'max_depth': 5, 'learning_rate': 0.01008421871699347, 'n_estimators': 950, 'subsample': 0.8275056270619455, 'colsample_bytree': 0.7769214561846703, 'gamma': 3.5158397658127494, 'min_child_weight': 6, 'lambda': 6.7687212103488665, 'alpha': 0.01810372433438871}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:19:09,871] Trial 6 finished with value: 0.6276925145122654 and parameters: {'max_depth': 10, 'learning_rate': 0.07452613990020096, 'n_estimators': 800, 'subsample': 0.9211891586298316, 'colsample_bytree': 0.9377228058409097, 'gamma': 0.8482948814905183, 'min_child_weight': 8, 'lambda': 0.0041015002532455574, 'alpha': 0.010476617534768628}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:19:14,472] Trial 7 finished with value: 0.6263340071927289 and parameters: {'max_depth': 10, 'learning_rate': 0.1938304020314193, 'n_estimators': 450, 'subsample': 0.8373714416116835, 'colsample_bytree': 0.7805023788117871, 'gamma': 1.794016111351061, 'min_child_weight': 4, 'lambda': 0.7140067204474823, 'alpha': 0.06750454727621381}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:19:38,202] Trial 8 finished with value: 0.6295357713148279 and parameters: {'max_depth': 9, 'learning_rate': 0.018697596910247447, 'n_estimators': 450, 'subsample': 0.7838429945680798, 'colsample_bytree': 0.9326500842721143, 'gamma': 3.4976257819223537, 'min_child_weight': 7, 'lambda': 0.10707839380145286, 'alpha': 0.9254436386360487}. Best is trial 3 with value: 0.6303118675507612.\n",
      "[I 2024-11-29 17:19:59,832] Trial 9 finished with value: 0.6289540098023102 and parameters: {'max_depth': 4, 'learning_rate': 0.04383444732729029, 'n_estimators': 400, 'subsample': 0.7543908190614002, 'colsample_bytree': 0.9826639005062047, 'gamma': 0.6362011767046594, 'min_child_weight': 7, 'lambda': 3.5773228972134903, 'alpha': 0.012604859492733411}. Best is trial 3 with value: 0.6303118675507612.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  10\n",
      "Best trial:\n",
      "  Value: 0.6303118675507612\n",
      "  Params: \n",
      "    max_depth: 6\n",
      "    learning_rate: 0.016304739602902737\n",
      "    n_estimators: 650\n",
      "    subsample: 0.7749465805467357\n",
      "    colsample_bytree: 0.7661963755069445\n",
      "    gamma: 3.401056835924059\n",
      "    min_child_weight: 8\n",
      "    lambda: 0.08015778171340451\n",
      "    alpha: 0.11684396769964843\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning on XGBoost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth        = trial.suggest_int(\"max_depth\", 2, 10, step=1)\n",
    "    learning_rate    = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    n_estimators     = trial.suggest_int(\"n_estimators\", 50, 1000, step=50)\n",
    "    subsample        = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "    gamma            = trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    reg_lambda       = trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True)\n",
    "    reg_alpha        = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "\n",
    "    model = xgb.XGBClassifier(max_depth=max_depth,\n",
    "                              learning_rate=learning_rate,\n",
    "                              n_estimators=n_estimators,\n",
    "                              subsample=subsample,\n",
    "                              colsample_bytree=colsample_bytree,\n",
    "                              gamma=gamma,\n",
    "                              min_child_weight=min_child_weight,\n",
    "                              reg_lambda=reg_lambda,\n",
    "                              reg_alpha=reg_alpha)\n",
    "    \n",
    "    # The percentage of people that win the tournament when starting from losers side is very small, but not zero\n",
    "    # Hence, it is probably good to use a stratified k-fold split for cross-validation\n",
    "\n",
    "    n_splits = 3\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    results = np.zeros(n_splits)\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(skf.split(train_df[features], train_df['winner_index'])):\n",
    "        model.fit(train_df.iloc[train_index][features], train_df.iloc[train_index]['winner_index'])\n",
    "\n",
    "        y_pred = model.predict(train_df.iloc[val_index][features])\n",
    "        results[i] = accuracy_score(train_df.iloc[val_index]['winner_index'], y_pred)\n",
    "    \n",
    "    return results.mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=10, timeout=1800)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on test set:  63.9\n"
     ]
    }
   ],
   "source": [
    "# Plucked from the above hyperparameter tuning session.\n",
    "# Doesn't really seem to be getting much better.\n",
    "xgb_tuned = xgb.XGBClassifier(max_depth=5,\n",
    "                              learning_rate=0.013278022811244645,\n",
    "                              n_estimators=300,\n",
    "                              subsample=0.7451791331241274,\n",
    "                              colsample_bytree=0.7785615347277948,\n",
    "                              gamma=2.819394518381603,\n",
    "                              min_child_weight=6,\n",
    "                              reg_lambda=0.41270859938111326,\n",
    "                              reg_alpha=1.9859484482942584)\n",
    "\n",
    "xgb_tuned.fit(train_df[features], train_df['winner_index'])\n",
    "print(\"Accuracy of XGBoost on test set: \", round(100.0 * accuracy_score(test_df['winner_index'], xgb_tuned.predict(test_df[features])), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set baselines:\n",
      "\n",
      "Highest ELO out of top 8, accuracy:                0.4\n",
      "Highest ELO out of WSF, accuracy:                  35.7\n",
      "Computing all ways top 8 can play out, accuracy:   59.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set baselines:\")\n",
    "print()\n",
    "print(\"Highest ELO out of top 8, accuracy:               \", round(100.0 * (test_df['winner_index'] == test_df['elo_prediction']).astype(float).mean(), 1))\n",
    "print(\"Highest ELO out of WSF, accuracy:                 \", round(100.0 * (test_df['winner_index'] == test_df['elo_WSF_prediction']).astype(float).mean(), 1))\n",
    "print(\"Computing all ways top 8 can play out, accuracy:  \", round(100.0 * (test_df['winner_index'] == test_df['path_prediction']).astype(float).mean(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
