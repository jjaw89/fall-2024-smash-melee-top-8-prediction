{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "#import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from glicko2 import Player\n",
    "import multiprocessing\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "if os.path.exists('/workspace/data_2'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data_2/'\n",
    "else:\n",
    "    data_path = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the single-set model saved from earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 single-set performance metrics\n",
      "\n",
      "On all sets:\n",
      "Log loss:  0.441\n",
      "Accuracy:  79.8\n",
      "\n",
      "Restricting to top 8 sets only:\n",
      "Log loss:  0.514\n",
      "Accuracy:  75.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "dataset_df = pd.read_pickle(data_path + 'dataset_full.pkl')\n",
    "dataset_df.sort_index(inplace=True) # For convenience, mostly. Not really necessary, we use .loc[] anyways\n",
    "\n",
    "# Note that there is no real reason to keep separately computing the individual probabilities of winning each individual set.\n",
    "# Let's just compute them all at once here.\n",
    "\n",
    "single_set_model = None\n",
    "with open(data_path + 'single_set_model.pkl', 'rb') as f:\n",
    "    single_set_model = pickle.load(f)\n",
    "\n",
    "# Make sure these match up with what features the model was trained on.\n",
    "features_all_everything = ['p1_default_elo', 'p2_default_elo', 'p1_default_rd', 'p2_default_rd',\n",
    "       'p1_default_updates', 'p2_default_updates', 'matchup_1', 'matchup_2',\n",
    "       'matchup_3', 'matchup_4', 'matchup_5', 'matchup_6', 'matchup_7',\n",
    "       'matchup_8', 'matchup_9', 'matchup_10', 'p1_m1_usage', 'p2_m1_usage',\n",
    "       'p1/m1/m1_alt2_elo', 'p1/m1/m1_alt2_rd', 'p1/m1/m1_alt2_updates',\n",
    "       'p2/m1/m1_alt2_elo', 'p2/m1/m1_alt2_rd', 'p2/m1/m1_alt2_updates',\n",
    "       'p1/m1_alt3_elo', 'p1/m1_alt3_rd', 'p1/m1_alt3_updates',\n",
    "       'p2/m1_alt3_elo', 'p2/m1_alt3_rd', 'p2/m1_alt3_updates']\n",
    "\n",
    "dataset_df['p1_win_prob'] = single_set_model.predict_proba(dataset_df[features_all_everything])[:,1]\n",
    "\n",
    "# As a sanity check, let's verify the accuracy and log loss on 2024 data\n",
    "# Total accuracy and log loss (including lots of data that the model was trained on)\n",
    "date_filter = (dataset_df['start'] >= datetime.datetime(2024,1,1)) & (dataset_df['end'] <= datetime.datetime(2024,12,31))\n",
    "print(\"2024 single-set performance metrics\")\n",
    "print()\n",
    "print(\"On all sets:\")\n",
    "print(\"Log loss: \", round(log_loss(dataset_df[date_filter]['winner'], dataset_df[date_filter]['p1_win_prob']), 3))\n",
    "print(\"Accuracy: \", round(100.0 * accuracy_score(dataset_df[date_filter]['winner'], dataset_df[date_filter]['p1_win_prob'] >= 0.5), 1))\n",
    "print()\n",
    "print(\"Restricting to top 8 sets only:\")\n",
    "print(\"Log loss: \", round(log_loss(dataset_df[date_filter & dataset_df['top_8']]['winner'], dataset_df[date_filter & dataset_df['top_8']]['p1_win_prob']), 3))\n",
    "print(\"Accuracy: \", round(100.0 * accuracy_score(dataset_df[date_filter & dataset_df['top_8']]['winner'], dataset_df[date_filter & dataset_df['top_8']]['p1_win_prob'] >= 0.5), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean up the tournament dataframe\n",
    "\n",
    "In particular, this dataframe contains info on all top 8 players, along with the paths that they took to get to where they are in the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_id</th>\n",
       "      <th>LN_A_p1</th>\n",
       "      <th>LN_A_p2</th>\n",
       "      <th>LN_B_p1</th>\n",
       "      <th>LN_B_p2</th>\n",
       "      <th>WSF_A_p1</th>\n",
       "      <th>WSF_A_p2</th>\n",
       "      <th>WSF_B_p1</th>\n",
       "      <th>WSF_B_p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>374889</td>\n",
       "      <td>212438</td>\n",
       "      <td>262548</td>\n",
       "      <td>378028</td>\n",
       "      <td>1727716</td>\n",
       "      <td>1971084</td>\n",
       "      <td>374889</td>\n",
       "      <td>29873</td>\n",
       "      <td>21515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>2931588</td>\n",
       "      <td>1652036</td>\n",
       "      <td>2720652</td>\n",
       "      <td>2512785</td>\n",
       "      <td>3188220</td>\n",
       "      <td>2931588</td>\n",
       "      <td>1470721</td>\n",
       "      <td>3188222</td>\n",
       "      <td>2551763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>701767</td>\n",
       "      <td>2670568</td>\n",
       "      <td>1693244</td>\n",
       "      <td>2159124</td>\n",
       "      <td>2382715</td>\n",
       "      <td>2998349</td>\n",
       "      <td>579172</td>\n",
       "      <td>2207927</td>\n",
       "      <td>701767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>26574</td>\n",
       "      <td>1482652</td>\n",
       "      <td>264041</td>\n",
       "      <td>2326935</td>\n",
       "      <td>650242</td>\n",
       "      <td>3024047</td>\n",
       "      <td>26574</td>\n",
       "      <td>674084</td>\n",
       "      <td>557126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>631158</td>\n",
       "      <td>2559523</td>\n",
       "      <td>1240442</td>\n",
       "      <td>1077370</td>\n",
       "      <td>3013285</td>\n",
       "      <td>631158</td>\n",
       "      <td>1007980</td>\n",
       "      <td>3188449</td>\n",
       "      <td>2557927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>2788878</td>\n",
       "      <td>3596098</td>\n",
       "      <td>3540721</td>\n",
       "      <td>4110509</td>\n",
       "      <td>287537</td>\n",
       "      <td>2410418</td>\n",
       "      <td>2788878</td>\n",
       "      <td>2956817</td>\n",
       "      <td>3815971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>180292</td>\n",
       "      <td>2298994</td>\n",
       "      <td>519020</td>\n",
       "      <td>36152</td>\n",
       "      <td>4916</td>\n",
       "      <td>36285</td>\n",
       "      <td>180292</td>\n",
       "      <td>37001</td>\n",
       "      <td>25701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>19641</td>\n",
       "      <td>405463</td>\n",
       "      <td>1445708</td>\n",
       "      <td>246491</td>\n",
       "      <td>769516</td>\n",
       "      <td>19641</td>\n",
       "      <td>2249893</td>\n",
       "      <td>3822249</td>\n",
       "      <td>148391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>267849</td>\n",
       "      <td>533918</td>\n",
       "      <td>56918</td>\n",
       "      <td>55591</td>\n",
       "      <td>342875</td>\n",
       "      <td>893866</td>\n",
       "      <td>267849</td>\n",
       "      <td>216979</td>\n",
       "      <td>512704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>609081</td>\n",
       "      <td>34804</td>\n",
       "      <td>25647</td>\n",
       "      <td>7564</td>\n",
       "      <td>1602510</td>\n",
       "      <td>698885</td>\n",
       "      <td>136697</td>\n",
       "      <td>10565</td>\n",
       "      <td>609081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      winner_id  LN_A_p1  LN_A_p2  LN_B_p1  LN_B_p2 WSF_A_p1 WSF_A_p2  \\\n",
       "18944    374889   212438   262548   378028  1727716  1971084   374889   \n",
       "18951   2931588  1652036  2720652  2512785  3188220  2931588  1470721   \n",
       "18948    701767  2670568  1693244  2159124  2382715  2998349   579172   \n",
       "18955     26574  1482652   264041  2326935   650242  3024047    26574   \n",
       "18950    631158  2559523  1240442  1077370  3013285   631158  1007980   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "39657   2788878  3596098  3540721  4110509   287537  2410418  2788878   \n",
       "39672    180292  2298994   519020    36152     4916    36285   180292   \n",
       "39598     19641   405463  1445708   246491   769516    19641  2249893   \n",
       "39031    267849   533918    56918    55591   342875   893866   267849   \n",
       "31228    609081    34804    25647     7564  1602510   698885   136697   \n",
       "\n",
       "      WSF_B_p1 WSF_B_p2  \n",
       "18944    29873    21515  \n",
       "18951  3188222  2551763  \n",
       "18948  2207927   701767  \n",
       "18955   674084   557126  \n",
       "18950  3188449  2557927  \n",
       "...        ...      ...  \n",
       "39657  2956817  3815971  \n",
       "39672    37001    25701  \n",
       "39598  3822249   148391  \n",
       "39031   216979   512704  \n",
       "31228    10565   609081  \n",
       "\n",
       "[15293 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_df = pd.read_pickle(data_path + 'top_8_tournament_previous_sets_and_results_with_winners_df')\n",
    "\n",
    "# Filter down to tournaments which actually have valid top 8 data, and previous data on getting there.\n",
    "tournament_df = tournament_df.loc[tournament_df[['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2',\n",
    "                                                 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2',\n",
    "                                                 'LN_A_p1_non_top_8_sets', 'LN_A_p2_non_top_8_sets',\n",
    "                                                 'LN_B_p1_non_top_8_sets', 'LN_B_p2_non_top_8_sets',\n",
    "                                                 'WSF_A_p1_non_top_8_sets', 'WSF_A_p2_non_top_8_sets',\n",
    "                                                 'WSF_B_p1_non_top_8_sets', 'WSF_B_p2_non_top_8_sets']].dropna().index]\n",
    "\n",
    "\n",
    "# Very rarely (not sure where the problem is) you get something not actually in the single-set dataframe\n",
    "# It is not actually that common though, so let's just delete those instances.\n",
    "def references_valid_sets(prev_sets):\n",
    "    for x in prev_sets:\n",
    "        if x[0] not in dataset_df.index:\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "filter = tournament_df[['LN_A_p1_non_top_8_sets', 'LN_A_p2_non_top_8_sets',\n",
    "                        'LN_B_p1_non_top_8_sets', 'LN_B_p2_non_top_8_sets',\n",
    "                        'WSF_A_p1_non_top_8_sets', 'WSF_A_p2_non_top_8_sets',\n",
    "                        'WSF_B_p1_non_top_8_sets', 'WSF_B_p2_non_top_8_sets']].map(references_valid_sets).all(axis=1)\n",
    "\n",
    "tournament_df = tournament_df[filter]\n",
    "\n",
    "# Likewise, some of these sets don't seem to have a valid winner\n",
    "tournament_df = tournament_df[~tournament_df['winner_id'].isna()]\n",
    "\n",
    "# A bit more cleanup, for sanity\n",
    "min_date = datetime.datetime(2015,1,1)\n",
    "max_date = datetime.datetime(2024,12,31)\n",
    "\n",
    "tournament_df = tournament_df[(tournament_df['start'] >= min_date) &\n",
    "                              (tournament_df['end'] >= min_date) &\n",
    "                              (tournament_df['start'] <= max_date) &\n",
    "                              (tournament_df['end'] <= max_date)]\n",
    "\n",
    "# We will only be dealing with data from 2023 onwards, because the single-set predictor that we will be using\n",
    "# was trained on data up to the end of 2022, and we don't want it leaking data.\n",
    "# This will also speed up computations by not performing them on data we don't care about.\n",
    "tournament_df = tournament_df[tournament_df['start'] >= datetime.datetime(2023,1,1)]\n",
    "\n",
    "tournament_df.sort_values(by=['end', 'start'], inplace=True)\n",
    "\n",
    "tournament_df[['winner_id', 'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit more feature engineering\n",
    "\n",
    "Here, we compute a \"score\" that shows how well a player is doing relative to their skill level and the skill level of their opponents in this tournament. If they are beating players well beyond their normal skill level, their score goes up. If they lose, it goes down.\n",
    "\n",
    "More specifically, we compute the probability that they win, and add the negative log of that probability if they indeed win. Losses are similar, but based on the probability that they lose, and subtracted instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1531552, True), (1531561, True), (1531566, False), (1531590, True)]\n",
      "\n",
      "         p1_default_elo  p2_default_elo  winner  p1_win_prob\n",
      "1531552     1744.647701     1068.270218     1.0     0.970317\n",
      "1531561     1694.260131     1744.647701     0.0     0.388579\n",
      "1531566     1744.647701     1500.000000     0.0     0.871613\n",
      "1531590     1599.596283     1744.647701     0.0     0.135352\n",
      "\n",
      "Previous set score:  -1.3851688378848603\n"
     ]
    }
   ],
   "source": [
    "# Compute a score based on how likely it was that they actually made it to the top.\n",
    "# A sort of sum of negative log probabilities, where wins are positive and losses are negative\n",
    "def prev_set_score(prev_sets):\n",
    "    result = 0\n",
    "\n",
    "    for x in prev_sets:\n",
    "        data = dataset_df.loc[x[0], ['winner', 'p1_win_prob']]\n",
    "        outcome = x[1]\n",
    "\n",
    "        # We don't know if this player is p1 or p2 in this list, but this can determine it without looking at player id\n",
    "        # Compare if (player we are interested in wins) vs (did p1 win)\n",
    "        if outcome == (data['winner'] == 1.0): # The player is p1\n",
    "            if outcome: # player wins, as p1\n",
    "                result += (-np.log(data['p1_win_prob']))\n",
    "            else:       # player loses, as p1\n",
    "                result -= (-np.log(1-data['p1_win_prob']))\n",
    "        else:                                  # The player is p2\n",
    "            if outcome: # player wins, as p2\n",
    "                result += (-np.log(1-data['p1_win_prob']))\n",
    "            else:       # player loses, as p2\n",
    "                result -= (-np.log(data['p1_win_prob']))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example data (note that there is a consistent ELO throughout this entire dataset)\n",
    "prev_sets = tournament_df.iloc[10000]['LN_A_p1_non_top_8_sets']\n",
    "print(prev_sets)\n",
    "print()\n",
    "print(dataset_df.loc[[x[0] for x in prev_sets], ['p1_default_elo', 'p2_default_elo', 'winner', 'p1_win_prob']])\n",
    "print()\n",
    "print(\"Previous set score: \", prev_set_score(tournament_df.iloc[10000]['LN_A_p1_non_top_8_sets']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we will keep track of all of the necessary data for each player in the top 8 by keeping track of what their starting position was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LN_A_p1_non_top_8_sets</th>\n",
       "      <th>LN_A_p2_non_top_8_sets</th>\n",
       "      <th>LN_B_p1_non_top_8_sets</th>\n",
       "      <th>LN_B_p2_non_top_8_sets</th>\n",
       "      <th>WSF_A_p1_non_top_8_sets</th>\n",
       "      <th>WSF_A_p2_non_top_8_sets</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets</th>\n",
       "      <th>LN_A_p1_non_top_8_sets_len</th>\n",
       "      <th>LN_A_p2_non_top_8_sets_len</th>\n",
       "      <th>...</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets_len</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets_len</th>\n",
       "      <th>LN_A_p1_non_top_8_sets_score</th>\n",
       "      <th>LN_A_p2_non_top_8_sets_score</th>\n",
       "      <th>LN_B_p1_non_top_8_sets_score</th>\n",
       "      <th>LN_B_p2_non_top_8_sets_score</th>\n",
       "      <th>WSF_A_p1_non_top_8_sets_score</th>\n",
       "      <th>WSF_A_p2_non_top_8_sets_score</th>\n",
       "      <th>WSF_B_p1_non_top_8_sets_score</th>\n",
       "      <th>WSF_B_p2_non_top_8_sets_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>[(1028338, True), (1028347, True), (1028351, F...</td>\n",
       "      <td>[(1028335, True), (1028345, True), (1028350, F...</td>\n",
       "      <td>[(1028337, True), (1028346, False), (1028361, ...</td>\n",
       "      <td>[(1028330, True), (1028341, True), (1028348, F...</td>\n",
       "      <td>[(1028342, True), (1028349, True)]</td>\n",
       "      <td>[(1028340, True), (1028348, True)]</td>\n",
       "      <td>[(1028344, True), (1028350, True)]</td>\n",
       "      <td>[(1028346, True), (1028351, True)]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.348273</td>\n",
       "      <td>3.581404</td>\n",
       "      <td>3.483719</td>\n",
       "      <td>2.586742</td>\n",
       "      <td>0.356917</td>\n",
       "      <td>0.155761</td>\n",
       "      <td>0.487661</td>\n",
       "      <td>0.352467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>[(1028523, False), (1028528, True)]</td>\n",
       "      <td>[(1028522, False)]</td>\n",
       "      <td>[(1028521, False)]</td>\n",
       "      <td>[(1028519, True), (1028520, False)]</td>\n",
       "      <td>[(1028520, True)]</td>\n",
       "      <td>[(1028521, True)]</td>\n",
       "      <td>[(1028522, True)]</td>\n",
       "      <td>[(1028523, True)]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670509</td>\n",
       "      <td>-0.701147</td>\n",
       "      <td>-0.680330</td>\n",
       "      <td>0.592403</td>\n",
       "      <td>0.227003</td>\n",
       "      <td>0.680330</td>\n",
       "      <td>0.701147</td>\n",
       "      <td>0.316062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>[(1028465, True), (1028469, False), (1028478, ...</td>\n",
       "      <td>[(1028463, True), (1028468, False), (1028479, ...</td>\n",
       "      <td>[(1028459, True), (1028466, False), (1028477, ...</td>\n",
       "      <td>[(1028461, True), (1028467, False), (1028476, ...</td>\n",
       "      <td>[(1028460, True), (1028467, True)]</td>\n",
       "      <td>[(1028458, True), (1028466, True)]</td>\n",
       "      <td>[(1028464, True), (1028469, True)]</td>\n",
       "      <td>[(1028462, True), (1028468, True)]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>0.898460</td>\n",
       "      <td>1.131986</td>\n",
       "      <td>-0.424911</td>\n",
       "      <td>0.785745</td>\n",
       "      <td>0.172685</td>\n",
       "      <td>0.214940</td>\n",
       "      <td>0.132570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>[(1028610, True), (1028614, False), (1028622, ...</td>\n",
       "      <td>[(1028608, True), (1028613, False), (1028623, ...</td>\n",
       "      <td>[(1028606, True), (1028612, False), (1028624, ...</td>\n",
       "      <td>[(1028605, True), (1028611, False), (1028625, ...</td>\n",
       "      <td>[(1028607, True), (1028612, True)]</td>\n",
       "      <td>[(1028611, True)]</td>\n",
       "      <td>[(1028609, True), (1028614, True)]</td>\n",
       "      <td>[(1028613, True)]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.194331</td>\n",
       "      <td>-0.036581</td>\n",
       "      <td>-0.606350</td>\n",
       "      <td>1.206678</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.069473</td>\n",
       "      <td>0.323127</td>\n",
       "      <td>0.247039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>[(1028500, True), (1028504, False)]</td>\n",
       "      <td>[(1028501, True), (1028505, False), (1028510, ...</td>\n",
       "      <td>[(1028500, False), (1028511, True)]</td>\n",
       "      <td>[(1028501, False), (1028512, True)]</td>\n",
       "      <td>[(1028502, True)]</td>\n",
       "      <td>[(1028503, True)]</td>\n",
       "      <td>[(1028504, True)]</td>\n",
       "      <td>[(1028505, True)]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.934742</td>\n",
       "      <td>-0.438122</td>\n",
       "      <td>-0.149440</td>\n",
       "      <td>-0.249527</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.092795</td>\n",
       "      <td>1.442649</td>\n",
       "      <td>1.039704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LN_A_p1_non_top_8_sets  \\\n",
       "18944  [(1028338, True), (1028347, True), (1028351, F...   \n",
       "18951                [(1028523, False), (1028528, True)]   \n",
       "18948  [(1028465, True), (1028469, False), (1028478, ...   \n",
       "18955  [(1028610, True), (1028614, False), (1028622, ...   \n",
       "18950                [(1028500, True), (1028504, False)]   \n",
       "\n",
       "                                  LN_A_p2_non_top_8_sets  \\\n",
       "18944  [(1028335, True), (1028345, True), (1028350, F...   \n",
       "18951                                 [(1028522, False)]   \n",
       "18948  [(1028463, True), (1028468, False), (1028479, ...   \n",
       "18955  [(1028608, True), (1028613, False), (1028623, ...   \n",
       "18950  [(1028501, True), (1028505, False), (1028510, ...   \n",
       "\n",
       "                                  LN_B_p1_non_top_8_sets  \\\n",
       "18944  [(1028337, True), (1028346, False), (1028361, ...   \n",
       "18951                                 [(1028521, False)]   \n",
       "18948  [(1028459, True), (1028466, False), (1028477, ...   \n",
       "18955  [(1028606, True), (1028612, False), (1028624, ...   \n",
       "18950                [(1028500, False), (1028511, True)]   \n",
       "\n",
       "                                  LN_B_p2_non_top_8_sets  \\\n",
       "18944  [(1028330, True), (1028341, True), (1028348, F...   \n",
       "18951                [(1028519, True), (1028520, False)]   \n",
       "18948  [(1028461, True), (1028467, False), (1028476, ...   \n",
       "18955  [(1028605, True), (1028611, False), (1028625, ...   \n",
       "18950                [(1028501, False), (1028512, True)]   \n",
       "\n",
       "                  WSF_A_p1_non_top_8_sets             WSF_A_p2_non_top_8_sets  \\\n",
       "18944  [(1028342, True), (1028349, True)]  [(1028340, True), (1028348, True)]   \n",
       "18951                   [(1028520, True)]                   [(1028521, True)]   \n",
       "18948  [(1028460, True), (1028467, True)]  [(1028458, True), (1028466, True)]   \n",
       "18955  [(1028607, True), (1028612, True)]                   [(1028611, True)]   \n",
       "18950                   [(1028502, True)]                   [(1028503, True)]   \n",
       "\n",
       "                  WSF_B_p1_non_top_8_sets             WSF_B_p2_non_top_8_sets  \\\n",
       "18944  [(1028344, True), (1028350, True)]  [(1028346, True), (1028351, True)]   \n",
       "18951                   [(1028522, True)]                   [(1028523, True)]   \n",
       "18948  [(1028464, True), (1028469, True)]  [(1028462, True), (1028468, True)]   \n",
       "18955  [(1028609, True), (1028614, True)]                   [(1028613, True)]   \n",
       "18950                   [(1028504, True)]                   [(1028505, True)]   \n",
       "\n",
       "       LN_A_p1_non_top_8_sets_len  LN_A_p2_non_top_8_sets_len  ...  \\\n",
       "18944                           4                           4  ...   \n",
       "18951                           2                           1  ...   \n",
       "18948                           3                           3  ...   \n",
       "18955                           3                           3  ...   \n",
       "18950                           2                           3  ...   \n",
       "\n",
       "       WSF_B_p1_non_top_8_sets_len  WSF_B_p2_non_top_8_sets_len  \\\n",
       "18944                            2                            2   \n",
       "18951                            1                            1   \n",
       "18948                            2                            2   \n",
       "18955                            2                            1   \n",
       "18950                            1                            1   \n",
       "\n",
       "       LN_A_p1_non_top_8_sets_score  LN_A_p2_non_top_8_sets_score  \\\n",
       "18944                      0.348273                      3.581404   \n",
       "18951                      0.670509                     -0.701147   \n",
       "18948                      0.420448                      0.898460   \n",
       "18955                      1.194331                     -0.036581   \n",
       "18950                     -0.934742                     -0.438122   \n",
       "\n",
       "       LN_B_p1_non_top_8_sets_score  LN_B_p2_non_top_8_sets_score  \\\n",
       "18944                      3.483719                      2.586742   \n",
       "18951                     -0.680330                      0.592403   \n",
       "18948                      1.131986                     -0.424911   \n",
       "18955                     -0.606350                      1.206678   \n",
       "18950                     -0.149440                     -0.249527   \n",
       "\n",
       "       WSF_A_p1_non_top_8_sets_score  WSF_A_p2_non_top_8_sets_score  \\\n",
       "18944                       0.356917                       0.155761   \n",
       "18951                       0.227003                       0.680330   \n",
       "18948                       0.785745                       0.172685   \n",
       "18955                       0.893398                       0.069473   \n",
       "18950                       0.057306                       0.092795   \n",
       "\n",
       "       WSF_B_p1_non_top_8_sets_score  WSF_B_p2_non_top_8_sets_score  \n",
       "18944                       0.487661                       0.352467  \n",
       "18951                       0.701147                       0.316062  \n",
       "18948                       0.214940                       0.132570  \n",
       "18955                       0.323127                       0.247039  \n",
       "18950                       1.442649                       1.039704  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_8_pos = ['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']\n",
    "top_8_prevs = [x + '_non_top_8_sets' for x in top_8_pos]\n",
    "top_8_prevs_lengths = [x + \"_len\" for x in top_8_prevs] # These columns will just keep track of how many sets the player went through to get to the top 8\n",
    "top_8_prevs_scores = [x + \"_score\" for x in top_8_prevs] # These will keep track of their \"score\" that shows how \"well\" they are performing relative to their predicted odds.\n",
    "\n",
    "tournament_df[top_8_prevs_lengths] = tournament_df[top_8_prevs].map(lambda x: len(x)).to_numpy()\n",
    "tournament_df[top_8_prevs_scores] = tournament_df[top_8_prevs].map(prev_set_score).to_numpy()\n",
    "tournament_df[top_8_prevs + top_8_prevs_lengths + top_8_prevs_scores].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column that contains the top 8 starting position of the winner\n",
    "# (or more specifically, the numeric index in top_8_pos)\n",
    "\n",
    "tournament_df['winner_index'] = 8 # Dummy value, has to be 0-7\n",
    "\n",
    "for i,position in enumerate(top_8_pos):\n",
    "    found_filter = (tournament_df['winner_id'] == tournament_df[top_8_pos[i]])\n",
    "    tournament_df.loc[found_filter, 'winner_index'] = i\n",
    "\n",
    "(tournament_df['winner_index'] == 8).sum() # Should be zero (everything found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start pulling in data (like ELO) for each of the top 8 players in the tournaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to have all of the features we've engineered for each of the players that made it to the top 8\n",
    "# We can be clever and pull most of them (elo-based features) from the previous sets in the dataframe\n",
    "# The rest (player vs player stats, also called \"matchup\", but might be renamed) have to be pulled in manually\n",
    "\n",
    "features_elo = ['p1_default_elo', 'p2_default_elo', 'p1_default_rd', 'p2_default_rd',\n",
    "       'p1_default_updates', 'p2_default_updates', 'p1_m1_usage', 'p2_m1_usage',\n",
    "       'p1/m1/m1_alt2_elo', 'p1/m1/m1_alt2_rd', 'p1/m1/m1_alt2_updates',\n",
    "       'p2/m1/m1_alt2_elo', 'p2/m1/m1_alt2_rd', 'p2/m1/m1_alt2_updates',\n",
    "       'p1/m1_alt3_elo', 'p1/m1_alt3_rd', 'p1/m1_alt3_updates',\n",
    "       'p2/m1_alt3_elo', 'p2/m1_alt3_rd', 'p2/m1_alt3_updates']\n",
    "\n",
    "features_matchup = ['matchup_1', 'matchup_2', 'matchup_3', 'matchup_4', 'matchup_5',\n",
    "                    'matchup_6', 'matchup_7', 'matchup_8', 'matchup_9', 'matchup_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3958f690954fe7a74571ec1769550c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In order to avoid an organizational nightmare, each of the following:\n",
    "#     'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "# will have their data stored in separate dataframes, each held in the following dictionary\n",
    "\n",
    "top_8_stats = {}\n",
    "\n",
    "def pull_data_from_set(loc, outcome):\n",
    "    set_data = dataset_df.loc[loc]\n",
    "    player_num = 'p1' if outcome == (set_data['winner'] == 1.0) else 'p2' # Sneaky way of getting the player number\n",
    "\n",
    "    features_to_pull = [x for x in features_elo if player_num in x]\n",
    "    pulled_data = set_data[features_to_pull].copy()\n",
    "    pulled_data.index = [x.replace(player_num, '') for x in pulled_data.index] # We will add player numbers on an as-needed basis later\n",
    "\n",
    "    return pulled_data\n",
    "\n",
    "for top_8_position in tqdm(top_8_pos):\n",
    "    # First, pull in player 1 data from a previous match.\n",
    "    # Note that the player might NOT be player 1 in the match that we are pulling from\n",
    "    top_8_stats[top_8_position] = tournament_df[top_8_position + '_non_top_8_sets'].apply(lambda x: pull_data_from_set(x[0][0], x[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important information about the players in the top 8 is essentially how likely each player is to win against the other player. We can use our single-set predictor to estimate this. We can also make use of the information on how well each player has been doing in the tournament relative to their skill level/opponent skill levels, possibly in order to \"adjust\" the aforementioned probabilities. Or just to toss it as extra information in whatever ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600206"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing more than half the data when we look up the matchup data makes it faster by roughly 10x\n",
    "smaller_df = dataset_df[dataset_df['matchup_1']!=.5].sort_values('end').copy()\n",
    "smaller_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid any sets that do not have a pair of players who have appeared in the same top 8 of some tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d124faf40ea4619b40f0c176a8ac822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# Assuming 'tournament_df' and 'smaller_df' are your DataFrames\n",
    "\n",
    "# Define the columns that contain the top 8 players in each tournament\n",
    "top_8_columns = [\n",
    "    'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2',\n",
    "    'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "]\n",
    "\n",
    "# Initialize a list to store all unique pairs of players who appeared in the same top 8\n",
    "pairs_list = []\n",
    "\n",
    "# Iterate over each tournament to generate all possible pairs of top 8 players\n",
    "for index, row in tqdm(tournament_df.iterrows()):\n",
    "    # Extract the top 8 players for the current tournament\n",
    "    top_8_players = row[top_8_columns].dropna().unique()\n",
    "    \n",
    "    # Generate all unordered pairs of top 8 players\n",
    "    for p1, p2 in itertools.combinations(top_8_players, 2):\n",
    "        min_id, max_id = sorted([p1, p2])\n",
    "        pairs_list.append({'min_id': min_id, 'max_id': max_id})\n",
    "\n",
    "# Create a DataFrame of all relevant player pairs and remove duplicates\n",
    "relevant_pairs_df = pd.DataFrame(pairs_list).drop_duplicates()\n",
    "\n",
    "# Prepare 'smaller_df' by adding 'min_id' and 'max_id' columns for efficient merging\n",
    "smaller_df['min_id'] = smaller_df[['p1_id', 'p2_id']].min(axis=1)\n",
    "smaller_df['max_id'] = smaller_df[['p1_id', 'p2_id']].max(axis=1)\n",
    "\n",
    "# Merge 'smaller_df' with 'relevant_pairs_df' to filter relevant sets\n",
    "filtered_smaller_df = pd.merge(\n",
    "    smaller_df,\n",
    "    relevant_pairs_df,\n",
    "    on=['min_id', 'max_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Drop the 'min_id' and 'max_id' columns if they are no longer needed\n",
    "filtered_smaller_df = filtered_smaller_df.drop(columns=['min_id', 'max_id'])\n",
    "\n",
    "# The 'filtered_smaller_df' now contains only the relevant sets\n",
    "print(filtered_smaller_df.shape[0])  # This prints the number of relevant sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the slower function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6 ms Â± 149 Î¼s per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def get_matchup(p1_id, p2_id, start, dataset_df=filtered_smaller_df):\n",
    "    \"\"\"Gets the most recent matchup data from before the start of the tournament.\n",
    "        This is pretty slow and will likely slow down this cell a lot.\n",
    "    Args:\n",
    "        p1_id: The ID of player 1.\n",
    "        p2_id: The ID of player 2.\n",
    "        start: The start of the tournament.\n",
    "        dataset_df: Use only the data that have values other than .5 in matchup_1\n",
    "\n",
    "    Returns:\n",
    "        A pd.Series containing the matchup data or default values if no prior sets exist.\n",
    "    \"\"\"\n",
    "    # Ensure the dataset is sorted by 'end'\n",
    "    assert dataset_df['end'].is_monotonic_increasing, \"Dataset must be sorted by 'end'.\"\n",
    "\n",
    "    # Use NumPy for faster filtering\n",
    "    p1_mask = (dataset_df['p1_id'] == p1_id) & (dataset_df['p2_id'] == p2_id)\n",
    "    p2_mask = (dataset_df['p1_id'] == p2_id) & (dataset_df['p2_id'] == p1_id)\n",
    "    mask = (p1_mask | p2_mask).to_numpy()\n",
    "\n",
    "    # Find indices where mask is True\n",
    "    valid_indices = np.where(mask & (dataset_df['end'].to_numpy() < start))[0]\n",
    "\n",
    "    if len(valid_indices) == 0:\n",
    "        # No prior matches, return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "\n",
    "    # Get the last valid index\n",
    "    last_index = valid_indices[-1]\n",
    "    last_row = dataset_df.iloc[last_index]\n",
    "\n",
    "    # Define matchup columns\n",
    "    matchup_cols = [f'matchup_{n}' for n in range(1, 11)]\n",
    "\n",
    "    # Determine if we need to swap values\n",
    "    if p1_id == last_row['p1_id'] and p2_id == last_row['p2_id']:\n",
    "        return last_row[matchup_cols]\n",
    "    elif p1_id == last_row['p2_id'] and p2_id == last_row['p1_id']:\n",
    "        return 1 - last_row[matchup_cols]\n",
    "    else:\n",
    "        # Should not happen but acts as a fallback\n",
    "        print(\"Matchup Data Failed\")\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "%timeit get_matchup(dataset_df.iloc[1_200_000]['p1_id'], dataset_df.iloc[1_200_000]['p2_id'], dataset_df.iloc[1_200_000]['start'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell has the optimized function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571 Î¼s Â± 134 Î¼s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Assume 'filtered_smaller_df' is your dataset_df\n",
    "dataset_df_2 = filtered_smaller_df.copy()\n",
    "\n",
    "# Create 'min_id' and 'max_id' columns to represent unordered player pairs\n",
    "dataset_df_2['min_id'] = dataset_df_2[['p1_id', 'p2_id']].min(axis=1)\n",
    "dataset_df_2['max_id'] = dataset_df_2[['p1_id', 'p2_id']].max(axis=1)\n",
    "\n",
    "# Create a 'pair_key' column as a tuple of (min_id, max_id)\n",
    "dataset_df_2['pair_key'] = list(zip(dataset_df_2['min_id'], dataset_df_2['max_id']))\n",
    "\n",
    "# Sort the dataset by 'end' to ensure matchups are in chronological order\n",
    "dataset_df_2 = dataset_df_2.sort_values('end').reset_index(drop=True)\n",
    "\n",
    "# Group the dataset by 'pair_key' for efficient lookups\n",
    "grouped_pairs = dataset_df_2.groupby('pair_key', sort=False)\n",
    "\n",
    "def get_matchup(p1_id, p2_id, start, grouped_pairs=grouped_pairs):\n",
    "    \"\"\"Gets the most recent matchup data from before the start of the tournament.\n",
    "    \n",
    "    Args:\n",
    "        p1_id: The ID of player 1.\n",
    "        p2_id: The ID of player 2.\n",
    "        start: The start of the tournament.\n",
    "        grouped_pairs: The preprocessed grouped DataFrame by player pairs.\n",
    "        \n",
    "    Returns:\n",
    "        A pd.Series containing the matchup data or default values if no prior sets exist.\n",
    "    \"\"\"\n",
    "    # Create the pair key\n",
    "    min_id, max_id = min(p1_id, p2_id), max(p1_id, p2_id)\n",
    "    pair_key = (min_id, max_id)\n",
    "    \n",
    "    # Check if the pair exists in the grouped data\n",
    "    if pair_key not in grouped_pairs.groups:\n",
    "        # No prior matches, return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "    # Get the group DataFrame for the pair\n",
    "    group_df = grouped_pairs.get_group(pair_key)\n",
    "    \n",
    "    # Filter matches that occurred before the 'start' time\n",
    "    prior_matches = group_df[group_df['end'] < start]\n",
    "    \n",
    "    if prior_matches.empty:\n",
    "        # No prior matches before 'start', return default values\n",
    "        return pd.Series(0.5, index=[f'matchup_{n}' for n in range(1, 11)])\n",
    "    \n",
    "    # Get the last match (most recent before 'start')\n",
    "    last_row = prior_matches.iloc[-1]\n",
    "    \n",
    "    # Define matchup columns\n",
    "    matchup_cols = [f'matchup_{n}' for n in range(1, 11)]\n",
    "    \n",
    "    # Determine if we need to swap the matchup data\n",
    "    if (p1_id == last_row['p1_id']) and (p2_id == last_row['p2_id']):\n",
    "        return last_row[matchup_cols]\n",
    "    elif (p1_id == last_row['p2_id']) and (p2_id == last_row['p1_id']):\n",
    "        return 1 - last_row[matchup_cols]\n",
    "        # This case should not occur but acts as a fallback\n",
    "        print(\"Matchup Data Failed\")\n",
    "        return pd.Series(0.5, index=matchup_cols)\n",
    "\n",
    "%timeit get_matchup(dataset_df.iloc[1_200_000]['p1_id'], dataset_df.iloc[1_200_000]['p2_id'], dataset_df.iloc[1_200_000]['start'], grouped_pairs=grouped_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330e7f5abea94df78b5f99f635708b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairprob/LN_A_p1/LN_A_p1</th>\n",
       "      <th>pairprob/LN_A_p1/LN_A_p2</th>\n",
       "      <th>pairprob/LN_A_p1/LN_B_p1</th>\n",
       "      <th>pairprob/LN_A_p1/LN_B_p2</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_A_p1</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_A_p2</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_B_p1</th>\n",
       "      <th>pairprob/LN_A_p1/WSF_B_p2</th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p2</th>\n",
       "      <th>...</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.890509</td>\n",
       "      <td>0.852432</td>\n",
       "      <td>0.872104</td>\n",
       "      <td>0.370693</td>\n",
       "      <td>0.070255</td>\n",
       "      <td>0.446105</td>\n",
       "      <td>0.197773</td>\n",
       "      <td>0.109491</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.294398</td>\n",
       "      <td>0.802227</td>\n",
       "      <td>0.886035</td>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.881124</td>\n",
       "      <td>0.718817</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.705602</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.341775</td>\n",
       "      <td>0.355264</td>\n",
       "      <td>0.413097</td>\n",
       "      <td>0.141854</td>\n",
       "      <td>0.176179</td>\n",
       "      <td>0.413097</td>\n",
       "      <td>0.268372</td>\n",
       "      <td>0.658225</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.347865</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>0.634808</td>\n",
       "      <td>0.610338</td>\n",
       "      <td>0.652135</td>\n",
       "      <td>0.294078</td>\n",
       "      <td>0.586523</td>\n",
       "      <td>0.652135</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.357299</td>\n",
       "      <td>0.420535</td>\n",
       "      <td>0.282338</td>\n",
       "      <td>0.328865</td>\n",
       "      <td>0.097825</td>\n",
       "      <td>0.141711</td>\n",
       "      <td>0.082159</td>\n",
       "      <td>0.642701</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.149739</td>\n",
       "      <td>0.917841</td>\n",
       "      <td>0.935993</td>\n",
       "      <td>0.917265</td>\n",
       "      <td>0.920165</td>\n",
       "      <td>0.913170</td>\n",
       "      <td>0.669152</td>\n",
       "      <td>0.850261</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.494464</td>\n",
       "      <td>0.514107</td>\n",
       "      <td>0.458946</td>\n",
       "      <td>0.500059</td>\n",
       "      <td>0.060690</td>\n",
       "      <td>0.167319</td>\n",
       "      <td>0.200874</td>\n",
       "      <td>0.505536</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.799126</td>\n",
       "      <td>0.784415</td>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.796112</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.229262</td>\n",
       "      <td>0.574498</td>\n",
       "      <td>0.417159</td>\n",
       "      <td>0.068485</td>\n",
       "      <td>0.151151</td>\n",
       "      <td>0.756258</td>\n",
       "      <td>0.414889</td>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.293731</td>\n",
       "      <td>0.585111</td>\n",
       "      <td>0.340115</td>\n",
       "      <td>0.610354</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>0.214632</td>\n",
       "      <td>0.706269</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.243661</td>\n",
       "      <td>0.221014</td>\n",
       "      <td>0.338694</td>\n",
       "      <td>0.194618</td>\n",
       "      <td>0.235543</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>0.339257</td>\n",
       "      <td>0.756339</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.684905</td>\n",
       "      <td>0.660743</td>\n",
       "      <td>0.312041</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.315095</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.380903</td>\n",
       "      <td>0.398434</td>\n",
       "      <td>0.174738</td>\n",
       "      <td>0.179369</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.041974</td>\n",
       "      <td>0.054029</td>\n",
       "      <td>0.619097</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.615689</td>\n",
       "      <td>0.945971</td>\n",
       "      <td>0.940585</td>\n",
       "      <td>0.945976</td>\n",
       "      <td>0.741612</td>\n",
       "      <td>0.866365</td>\n",
       "      <td>0.302917</td>\n",
       "      <td>0.384311</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741958</td>\n",
       "      <td>0.147051</td>\n",
       "      <td>0.901396</td>\n",
       "      <td>0.057887</td>\n",
       "      <td>0.452737</td>\n",
       "      <td>0.169667</td>\n",
       "      <td>0.127674</td>\n",
       "      <td>0.258042</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.407935</td>\n",
       "      <td>0.872326</td>\n",
       "      <td>0.934296</td>\n",
       "      <td>0.461910</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.084816</td>\n",
       "      <td>0.826207</td>\n",
       "      <td>0.592065</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.134118</td>\n",
       "      <td>0.358433</td>\n",
       "      <td>0.743080</td>\n",
       "      <td>0.093580</td>\n",
       "      <td>0.050296</td>\n",
       "      <td>0.067764</td>\n",
       "      <td>0.133463</td>\n",
       "      <td>0.865882</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.675258</td>\n",
       "      <td>0.866537</td>\n",
       "      <td>0.654290</td>\n",
       "      <td>0.741645</td>\n",
       "      <td>0.936694</td>\n",
       "      <td>0.647324</td>\n",
       "      <td>0.090804</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.329977</td>\n",
       "      <td>0.450283</td>\n",
       "      <td>0.106987</td>\n",
       "      <td>0.137019</td>\n",
       "      <td>0.080050</td>\n",
       "      <td>0.093868</td>\n",
       "      <td>0.084305</td>\n",
       "      <td>0.670023</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.171431</td>\n",
       "      <td>0.915695</td>\n",
       "      <td>0.928520</td>\n",
       "      <td>0.925003</td>\n",
       "      <td>0.860943</td>\n",
       "      <td>0.926753</td>\n",
       "      <td>0.640252</td>\n",
       "      <td>0.828569</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pairprob/LN_A_p1/LN_A_p1  pairprob/LN_A_p1/LN_A_p2  \\\n",
       "18944                       0.5                  0.890509   \n",
       "18951                       0.5                  0.341775   \n",
       "18948                       0.5                  0.357299   \n",
       "18955                       0.5                  0.494464   \n",
       "18950                       0.5                  0.229262   \n",
       "...                         ...                       ...   \n",
       "39657                       0.5                  0.243661   \n",
       "39672                       0.5                  0.380903   \n",
       "39598                       0.5                  0.741958   \n",
       "39031                       0.5                  0.134118   \n",
       "31228                       0.5                  0.329977   \n",
       "\n",
       "       pairprob/LN_A_p1/LN_B_p1  pairprob/LN_A_p1/LN_B_p2  \\\n",
       "18944                  0.852432                  0.872104   \n",
       "18951                  0.355264                  0.413097   \n",
       "18948                  0.420535                  0.282338   \n",
       "18955                  0.514107                  0.458946   \n",
       "18950                  0.574498                  0.417159   \n",
       "...                         ...                       ...   \n",
       "39657                  0.221014                  0.338694   \n",
       "39672                  0.398434                  0.174738   \n",
       "39598                  0.147051                  0.901396   \n",
       "39031                  0.358433                  0.743080   \n",
       "31228                  0.450283                  0.106987   \n",
       "\n",
       "       pairprob/LN_A_p1/WSF_A_p1  pairprob/LN_A_p1/WSF_A_p2  \\\n",
       "18944                   0.370693                   0.070255   \n",
       "18951                   0.141854                   0.176179   \n",
       "18948                   0.328865                   0.097825   \n",
       "18955                   0.500059                   0.060690   \n",
       "18950                   0.068485                   0.151151   \n",
       "...                          ...                        ...   \n",
       "39657                   0.194618                   0.235543   \n",
       "39672                   0.179369                   0.054565   \n",
       "39598                   0.057887                   0.452737   \n",
       "39031                   0.093580                   0.050296   \n",
       "31228                   0.137019                   0.080050   \n",
       "\n",
       "       pairprob/LN_A_p1/WSF_B_p1  pairprob/LN_A_p1/WSF_B_p2  \\\n",
       "18944                   0.446105                   0.197773   \n",
       "18951                   0.413097                   0.268372   \n",
       "18948                   0.141711                   0.082159   \n",
       "18955                   0.167319                   0.200874   \n",
       "18950                   0.756258                   0.414889   \n",
       "...                          ...                        ...   \n",
       "39657                   0.232614                   0.339257   \n",
       "39672                   0.041974                   0.054029   \n",
       "39598                   0.169667                   0.127674   \n",
       "39031                   0.067764                   0.133463   \n",
       "31228                   0.093868                   0.084305   \n",
       "\n",
       "       pairprob/LN_A_p2/LN_A_p1  pairprob/LN_A_p2/LN_A_p2  ...  \\\n",
       "18944                  0.109491                       0.5  ...   \n",
       "18951                  0.658225                       0.5  ...   \n",
       "18948                  0.642701                       0.5  ...   \n",
       "18955                  0.505536                       0.5  ...   \n",
       "18950                  0.770738                       0.5  ...   \n",
       "...                         ...                       ...  ...   \n",
       "39657                  0.756339                       0.5  ...   \n",
       "39672                  0.619097                       0.5  ...   \n",
       "39598                  0.258042                       0.5  ...   \n",
       "39031                  0.865882                       0.5  ...   \n",
       "31228                  0.670023                       0.5  ...   \n",
       "\n",
       "       pairprob/WSF_B_p1/WSF_B_p1  pairprob/WSF_B_p1/WSF_B_p2  \\\n",
       "18944                         0.5                    0.294398   \n",
       "18951                         0.5                    0.347865   \n",
       "18948                         0.5                    0.149739   \n",
       "18955                         0.5                    0.467538   \n",
       "18950                         0.5                    0.293731   \n",
       "...                           ...                         ...   \n",
       "39657                         0.5                    0.684905   \n",
       "39672                         0.5                    0.615689   \n",
       "39598                         0.5                    0.407935   \n",
       "39031                         0.5                    0.675258   \n",
       "31228                         0.5                    0.171431   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_A_p1  pairprob/WSF_B_p2/LN_A_p2  \\\n",
       "18944                   0.802227                   0.886035   \n",
       "18951                   0.731628                   0.634808   \n",
       "18948                   0.917841                   0.935993   \n",
       "18955                   0.799126                   0.784415   \n",
       "18950                   0.585111                   0.340115   \n",
       "...                          ...                        ...   \n",
       "39657                   0.660743                   0.312041   \n",
       "39672                   0.945971                   0.940585   \n",
       "39598                   0.872326                   0.934296   \n",
       "39031                   0.866537                   0.654290   \n",
       "31228                   0.915695                   0.928520   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_B_p1  pairprob/WSF_B_p2/LN_B_p2  \\\n",
       "18944                   0.868897                   0.881124   \n",
       "18951                   0.610338                   0.652135   \n",
       "18948                   0.917265                   0.920165   \n",
       "18955                   0.774007                   0.796112   \n",
       "18950                   0.610354                   0.462603   \n",
       "...                          ...                        ...   \n",
       "39657                   0.335139                   0.456473   \n",
       "39672                   0.945976                   0.741612   \n",
       "39598                   0.461910                   0.925452   \n",
       "39031                   0.741645                   0.936694   \n",
       "31228                   0.925003                   0.860943   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_A_p1  pairprob/WSF_B_p2/WSF_A_p2  \\\n",
       "18944                    0.718817                    0.127591   \n",
       "18951                    0.294078                    0.586523   \n",
       "18948                    0.913170                    0.669152   \n",
       "18955                    0.745964                    0.109419   \n",
       "18950                    0.043111                    0.214632   \n",
       "...                           ...                         ...   \n",
       "39657                    0.266067                    0.312205   \n",
       "39672                    0.866365                    0.302917   \n",
       "39598                    0.084816                    0.826207   \n",
       "39031                    0.647324                    0.090804   \n",
       "31228                    0.926753                    0.640252   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_B_p1  pairprob/WSF_B_p2/WSF_B_p2  \n",
       "18944                    0.705602                         0.5  \n",
       "18951                    0.652135                         0.5  \n",
       "18948                    0.850261                         0.5  \n",
       "18955                    0.532462                         0.5  \n",
       "18950                    0.706269                         0.5  \n",
       "...                           ...                         ...  \n",
       "39657                    0.315095                         0.5  \n",
       "39672                    0.384311                         0.5  \n",
       "39598                    0.592065                         0.5  \n",
       "39031                    0.324742                         0.5  \n",
       "31228                    0.828569                         0.5  \n",
       "\n",
       "[15293 rows x 64 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "\n",
    "\n",
    "# First, let's compute pairwise probabilities of one player in the top 8 winning against another player\n",
    "def compute_pairwise_prob(row):\n",
    "    # Row represents p1, column represents p2 (or specifically, the index in top_8_pos). Always follows this order:\n",
    "    players=['LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2']\n",
    "    pairwise_probs = np.zeros(shape=(8,8))\n",
    "    # pairwise_probs = np.full((8, 8), 0.5)\n",
    "    \n",
    "    # For convenience, put everything into one dataframe and then run the single set model\n",
    "    # This is probably more efficient than doing things line by line\n",
    "    combination_stats = []\n",
    "\n",
    "    for r in range(0,8):\n",
    "        for c in range(0,8):\n",
    "            p1_data = top_8_stats[top_8_pos[r]].loc[row.name]\n",
    "            p1_data.index = ['p1' + x for x in p1_data.index]\n",
    "\n",
    "            p2_data = top_8_stats[top_8_pos[c]].loc[row.name]\n",
    "            p2_data.index = ['p2' + x for x in p2_data.index]\n",
    "\n",
    "            #TODO: Actually populate this with proper data!\n",
    "            #      This is currently only just placeholder data,\n",
    "            #      indicating that the players have never played together before (0.5).\n",
    "            matchup_data = get_matchup(row[players[r]], row[players[c]], row['start'], grouped_pairs=grouped_pairs)\n",
    "\n",
    "            total_data = pd.concat([p1_data, p2_data, matchup_data])\n",
    "            total_data = total_data[features_all_everything] # Entries need to be in the correct order\n",
    "\n",
    "            combination_stats.append(total_data)\n",
    "\n",
    "    combination_stats = pd.DataFrame(combination_stats)\n",
    "\n",
    "    y_prob = single_set_model.predict_proba(combination_stats)\n",
    "\n",
    "    # Now actually populate this probability matrix with data.\n",
    "    # Note that we can just use the same nested loop and read off the entries of the 1D probability array one at a time.\n",
    "    # This will put things in the correct order.\n",
    "    i = 0\n",
    "    for r in range(0,8):\n",
    "        for c in range(0,8):\n",
    "            pairwise_probs[r,c] = y_prob[i,1]\n",
    "            i += 1\n",
    "\n",
    "    # NOTE: Some models that we train are highly non-symmetric, even though they very much should be,\n",
    "    #       given that we have randomized the players. We can fix that issue here.\n",
    "    pairwise_probs = 0.5 * (pairwise_probs + (1 - pairwise_probs.T))\n",
    "\n",
    "    return pairwise_probs.flatten()\n",
    "\n",
    "pairwise_prob = tournament_df.progress_apply(compute_pairwise_prob, axis=1)\n",
    "pairwise_prob = np.stack(pairwise_prob.to_numpy()) # Fixes \"single column of np arrays\" nonsense\n",
    "\n",
    "# Add that data as columns in the original dataframe\n",
    "pairwise_prob_cols = []\n",
    "for r in range(0,8):\n",
    "    for c in range(0,8):\n",
    "        pairwise_prob_cols.append(\"pairprob/\" + top_8_pos[r] + \"/\" + top_8_pos[c])\n",
    "\n",
    "tournament_df[pairwise_prob_cols] = pairwise_prob\n",
    "\n",
    "tournament_df[pairwise_prob_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairprob/LN_A_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p1/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p1/LN_A_p2</th>\n",
       "      <th>pairprob/LN_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/LN_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/LN_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_A_p1/LN_B_p2</th>\n",
       "      <th>...</th>\n",
       "      <th>pairprob/WSF_B_p1/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p1/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/LN_B_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p1</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_A_p2</th>\n",
       "      <th>pairprob/WSF_B_p2/WSF_B_p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>0.109491</td>\n",
       "      <td>0.147568</td>\n",
       "      <td>0.560340</td>\n",
       "      <td>0.127896</td>\n",
       "      <td>0.778422</td>\n",
       "      <td>0.733066</td>\n",
       "      <td>0.629307</td>\n",
       "      <td>0.858608</td>\n",
       "      <td>0.836600</td>\n",
       "      <td>0.858480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783884</td>\n",
       "      <td>0.418945</td>\n",
       "      <td>0.086071</td>\n",
       "      <td>0.802227</td>\n",
       "      <td>0.886035</td>\n",
       "      <td>0.868897</td>\n",
       "      <td>0.881124</td>\n",
       "      <td>0.718817</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.705602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>0.658225</td>\n",
       "      <td>0.644736</td>\n",
       "      <td>0.527030</td>\n",
       "      <td>0.586903</td>\n",
       "      <td>0.488552</td>\n",
       "      <td>0.455060</td>\n",
       "      <td>0.858146</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>0.780279</td>\n",
       "      <td>0.791784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.208216</td>\n",
       "      <td>0.451674</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>0.634808</td>\n",
       "      <td>0.610338</td>\n",
       "      <td>0.652135</td>\n",
       "      <td>0.294078</td>\n",
       "      <td>0.586523</td>\n",
       "      <td>0.652135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>0.642701</td>\n",
       "      <td>0.579465</td>\n",
       "      <td>0.421759</td>\n",
       "      <td>0.717662</td>\n",
       "      <td>0.580664</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>0.671135</td>\n",
       "      <td>0.606114</td>\n",
       "      <td>0.607849</td>\n",
       "      <td>0.472069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790583</td>\n",
       "      <td>0.774104</td>\n",
       "      <td>0.331855</td>\n",
       "      <td>0.917841</td>\n",
       "      <td>0.935993</td>\n",
       "      <td>0.917265</td>\n",
       "      <td>0.920165</td>\n",
       "      <td>0.913170</td>\n",
       "      <td>0.669152</td>\n",
       "      <td>0.850261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>0.505536</td>\n",
       "      <td>0.485893</td>\n",
       "      <td>0.541610</td>\n",
       "      <td>0.541054</td>\n",
       "      <td>0.534828</td>\n",
       "      <td>0.495115</td>\n",
       "      <td>0.499941</td>\n",
       "      <td>0.528534</td>\n",
       "      <td>0.482402</td>\n",
       "      <td>0.504324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.744929</td>\n",
       "      <td>0.093361</td>\n",
       "      <td>0.799126</td>\n",
       "      <td>0.784415</td>\n",
       "      <td>0.774007</td>\n",
       "      <td>0.796112</td>\n",
       "      <td>0.745964</td>\n",
       "      <td>0.109419</td>\n",
       "      <td>0.532462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>0.770738</td>\n",
       "      <td>0.425502</td>\n",
       "      <td>0.268448</td>\n",
       "      <td>0.582841</td>\n",
       "      <td>0.366259</td>\n",
       "      <td>0.648973</td>\n",
       "      <td>0.931515</td>\n",
       "      <td>0.937490</td>\n",
       "      <td>0.938933</td>\n",
       "      <td>0.938377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283199</td>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.197225</td>\n",
       "      <td>0.585111</td>\n",
       "      <td>0.340115</td>\n",
       "      <td>0.610354</td>\n",
       "      <td>0.462603</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>0.214632</td>\n",
       "      <td>0.706269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39657</th>\n",
       "      <td>0.756339</td>\n",
       "      <td>0.778986</td>\n",
       "      <td>0.504637</td>\n",
       "      <td>0.661306</td>\n",
       "      <td>0.367962</td>\n",
       "      <td>0.364845</td>\n",
       "      <td>0.805382</td>\n",
       "      <td>0.627646</td>\n",
       "      <td>0.584842</td>\n",
       "      <td>0.698226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637497</td>\n",
       "      <td>0.345618</td>\n",
       "      <td>0.470329</td>\n",
       "      <td>0.660743</td>\n",
       "      <td>0.312041</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.315095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39672</th>\n",
       "      <td>0.619097</td>\n",
       "      <td>0.601566</td>\n",
       "      <td>0.244213</td>\n",
       "      <td>0.825262</td>\n",
       "      <td>0.752130</td>\n",
       "      <td>0.852503</td>\n",
       "      <td>0.820631</td>\n",
       "      <td>0.722906</td>\n",
       "      <td>0.830637</td>\n",
       "      <td>0.448308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873133</td>\n",
       "      <td>0.913572</td>\n",
       "      <td>0.494360</td>\n",
       "      <td>0.945971</td>\n",
       "      <td>0.940585</td>\n",
       "      <td>0.945976</td>\n",
       "      <td>0.741612</td>\n",
       "      <td>0.866365</td>\n",
       "      <td>0.302917</td>\n",
       "      <td>0.384311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>0.258042</td>\n",
       "      <td>0.852949</td>\n",
       "      <td>0.899345</td>\n",
       "      <td>0.098604</td>\n",
       "      <td>0.153377</td>\n",
       "      <td>0.089267</td>\n",
       "      <td>0.942113</td>\n",
       "      <td>0.938737</td>\n",
       "      <td>0.890623</td>\n",
       "      <td>0.948434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918402</td>\n",
       "      <td>0.070573</td>\n",
       "      <td>0.639354</td>\n",
       "      <td>0.872326</td>\n",
       "      <td>0.934296</td>\n",
       "      <td>0.461910</td>\n",
       "      <td>0.925452</td>\n",
       "      <td>0.084816</td>\n",
       "      <td>0.826207</td>\n",
       "      <td>0.592065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39031</th>\n",
       "      <td>0.865882</td>\n",
       "      <td>0.641567</td>\n",
       "      <td>0.309669</td>\n",
       "      <td>0.256920</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.069609</td>\n",
       "      <td>0.906420</td>\n",
       "      <td>0.656821</td>\n",
       "      <td>0.756968</td>\n",
       "      <td>0.922970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953487</td>\n",
       "      <td>0.552122</td>\n",
       "      <td>0.096877</td>\n",
       "      <td>0.866537</td>\n",
       "      <td>0.654290</td>\n",
       "      <td>0.741645</td>\n",
       "      <td>0.936694</td>\n",
       "      <td>0.647324</td>\n",
       "      <td>0.090804</td>\n",
       "      <td>0.324742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>0.670023</td>\n",
       "      <td>0.549717</td>\n",
       "      <td>0.361419</td>\n",
       "      <td>0.893013</td>\n",
       "      <td>0.861876</td>\n",
       "      <td>0.896016</td>\n",
       "      <td>0.862981</td>\n",
       "      <td>0.786826</td>\n",
       "      <td>0.902803</td>\n",
       "      <td>0.335081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570919</td>\n",
       "      <td>0.805317</td>\n",
       "      <td>0.218730</td>\n",
       "      <td>0.915695</td>\n",
       "      <td>0.928520</td>\n",
       "      <td>0.925003</td>\n",
       "      <td>0.860943</td>\n",
       "      <td>0.926753</td>\n",
       "      <td>0.640252</td>\n",
       "      <td>0.828569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15293 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pairprob/LN_A_p2/LN_A_p1  pairprob/LN_B_p1/LN_A_p1  \\\n",
       "18944                  0.109491                  0.147568   \n",
       "18951                  0.658225                  0.644736   \n",
       "18948                  0.642701                  0.579465   \n",
       "18955                  0.505536                  0.485893   \n",
       "18950                  0.770738                  0.425502   \n",
       "...                         ...                       ...   \n",
       "39657                  0.756339                  0.778986   \n",
       "39672                  0.619097                  0.601566   \n",
       "39598                  0.258042                  0.852949   \n",
       "39031                  0.865882                  0.641567   \n",
       "31228                  0.670023                  0.549717   \n",
       "\n",
       "       pairprob/LN_B_p1/LN_A_p2  pairprob/LN_B_p2/LN_A_p1  \\\n",
       "18944                  0.560340                  0.127896   \n",
       "18951                  0.527030                  0.586903   \n",
       "18948                  0.421759                  0.717662   \n",
       "18955                  0.541610                  0.541054   \n",
       "18950                  0.268448                  0.582841   \n",
       "...                         ...                       ...   \n",
       "39657                  0.504637                  0.661306   \n",
       "39672                  0.244213                  0.825262   \n",
       "39598                  0.899345                  0.098604   \n",
       "39031                  0.309669                  0.256920   \n",
       "31228                  0.361419                  0.893013   \n",
       "\n",
       "       pairprob/LN_B_p2/LN_A_p2  pairprob/LN_B_p2/LN_B_p1  \\\n",
       "18944                  0.778422                  0.733066   \n",
       "18951                  0.488552                  0.455060   \n",
       "18948                  0.580664                  0.640270   \n",
       "18955                  0.534828                  0.495115   \n",
       "18950                  0.366259                  0.648973   \n",
       "...                         ...                       ...   \n",
       "39657                  0.367962                  0.364845   \n",
       "39672                  0.752130                  0.852503   \n",
       "39598                  0.153377                  0.089267   \n",
       "39031                  0.091599                  0.069609   \n",
       "31228                  0.861876                  0.896016   \n",
       "\n",
       "       pairprob/WSF_A_p1/LN_A_p1  pairprob/WSF_A_p1/LN_A_p2  \\\n",
       "18944                   0.629307                   0.858608   \n",
       "18951                   0.858146                   0.810027   \n",
       "18948                   0.671135                   0.606114   \n",
       "18955                   0.499941                   0.528534   \n",
       "18950                   0.931515                   0.937490   \n",
       "...                          ...                        ...   \n",
       "39657                   0.805382                   0.627646   \n",
       "39672                   0.820631                   0.722906   \n",
       "39598                   0.942113                   0.938737   \n",
       "39031                   0.906420                   0.656821   \n",
       "31228                   0.862981                   0.786826   \n",
       "\n",
       "       pairprob/WSF_A_p1/LN_B_p1  pairprob/WSF_A_p1/LN_B_p2  ...  \\\n",
       "18944                   0.836600                   0.858480  ...   \n",
       "18951                   0.780279                   0.791784  ...   \n",
       "18948                   0.607849                   0.472069  ...   \n",
       "18955                   0.482402                   0.504324  ...   \n",
       "18950                   0.938933                   0.938377  ...   \n",
       "...                          ...                        ...  ...   \n",
       "39657                   0.584842                   0.698226  ...   \n",
       "39672                   0.830637                   0.448308  ...   \n",
       "39598                   0.890623                   0.948434  ...   \n",
       "39031                   0.756968                   0.922970  ...   \n",
       "31228                   0.902803                   0.335081  ...   \n",
       "\n",
       "       pairprob/WSF_B_p1/LN_B_p2  pairprob/WSF_B_p1/WSF_A_p1  \\\n",
       "18944                   0.783884                    0.418945   \n",
       "18951                   0.500000                    0.208216   \n",
       "18948                   0.790583                    0.774104   \n",
       "18955                   0.782730                    0.744929   \n",
       "18950                   0.283199                    0.087591   \n",
       "...                          ...                         ...   \n",
       "39657                   0.637497                    0.345618   \n",
       "39672                   0.873133                    0.913572   \n",
       "39598                   0.918402                    0.070573   \n",
       "39031                   0.953487                    0.552122   \n",
       "31228                   0.570919                    0.805317   \n",
       "\n",
       "       pairprob/WSF_B_p1/WSF_A_p2  pairprob/WSF_B_p2/LN_A_p1  \\\n",
       "18944                    0.086071                   0.802227   \n",
       "18951                    0.451674                   0.731628   \n",
       "18948                    0.331855                   0.917841   \n",
       "18955                    0.093361                   0.799126   \n",
       "18950                    0.197225                   0.585111   \n",
       "...                           ...                        ...   \n",
       "39657                    0.470329                   0.660743   \n",
       "39672                    0.494360                   0.945971   \n",
       "39598                    0.639354                   0.872326   \n",
       "39031                    0.096877                   0.866537   \n",
       "31228                    0.218730                   0.915695   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_A_p2  pairprob/WSF_B_p2/LN_B_p1  \\\n",
       "18944                   0.886035                   0.868897   \n",
       "18951                   0.634808                   0.610338   \n",
       "18948                   0.935993                   0.917265   \n",
       "18955                   0.784415                   0.774007   \n",
       "18950                   0.340115                   0.610354   \n",
       "...                          ...                        ...   \n",
       "39657                   0.312041                   0.335139   \n",
       "39672                   0.940585                   0.945976   \n",
       "39598                   0.934296                   0.461910   \n",
       "39031                   0.654290                   0.741645   \n",
       "31228                   0.928520                   0.925003   \n",
       "\n",
       "       pairprob/WSF_B_p2/LN_B_p2  pairprob/WSF_B_p2/WSF_A_p1  \\\n",
       "18944                   0.881124                    0.718817   \n",
       "18951                   0.652135                    0.294078   \n",
       "18948                   0.920165                    0.913170   \n",
       "18955                   0.796112                    0.745964   \n",
       "18950                   0.462603                    0.043111   \n",
       "...                          ...                         ...   \n",
       "39657                   0.456473                    0.266067   \n",
       "39672                   0.741612                    0.866365   \n",
       "39598                   0.925452                    0.084816   \n",
       "39031                   0.936694                    0.647324   \n",
       "31228                   0.860943                    0.926753   \n",
       "\n",
       "       pairprob/WSF_B_p2/WSF_A_p2  pairprob/WSF_B_p2/WSF_B_p1  \n",
       "18944                    0.127591                    0.705602  \n",
       "18951                    0.586523                    0.652135  \n",
       "18948                    0.669152                    0.850261  \n",
       "18955                    0.109419                    0.532462  \n",
       "18950                    0.214632                    0.706269  \n",
       "...                           ...                         ...  \n",
       "39657                    0.312205                    0.315095  \n",
       "39672                    0.302917                    0.384311  \n",
       "39598                    0.826207                    0.592065  \n",
       "39031                    0.090804                    0.324742  \n",
       "31228                    0.640252                    0.828569  \n",
       "\n",
       "[15293 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add that data as columns in the original dataframe\n",
    "\n",
    "# Note that we only really need the strictly lower triangular part of the probability matrix\n",
    "# Everything else is redundant (the diagonal is 0.5, upper triangular part is 1 - lower triangular)\n",
    "# The entire matrix is kept in there just for easy reading.\n",
    "\n",
    "pairwise_prob_cols = []\n",
    "pairwise_prob_cols_reduced = []\n",
    "\n",
    "for r in range(0,8):\n",
    "    for c in range(0,8):\n",
    "        col_name = \"pairprob/\" + top_8_pos[r] + \"/\" + top_8_pos[c]\n",
    "\n",
    "        pairwise_prob_cols.append(col_name)\n",
    "\n",
    "        if r > c:\n",
    "            pairwise_prob_cols_reduced.append(col_name)\n",
    "\n",
    "tournament_df[pairwise_prob_cols] = pairwise_prob\n",
    "tournament_df[pairwise_prob_cols_reduced]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can (disclaimer: slightly inaccurately) compute all possible paths throughout the top 8, and the probability of winning along each path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slighltly incorrectly implemented algorithm that goes through all possible paths throughout the top 8,\n",
    "# and computes the corresponding probabilities of each player making it through.\n",
    "def compute_path_prob(row):\n",
    "    pairwise_probs = row[pairwise_prob_cols].to_numpy().astype(float).reshape((8,8))\n",
    "    pairwise_probs_zero_diagonal = pairwise_probs - 0.5 * np.identity(8) # Used for janky computations\n",
    "\n",
    "    # Now start building the tree structure of how the tournament can play out.\n",
    "    # Each \"cell\" will represent some set in the tournament played by some p1 and p2.\n",
    "    # The cell will have to keep track of all of the probabilities of each player making it to that point.\n",
    "    #\n",
    "    # Links should have the form (cell, 'winner') or (cell, 'loser'),\n",
    "    # describing if it is the winner or the loser of the previous that gets to this one\n",
    "    class cell:\n",
    "        def __init__(self, p1=None, p2=None, p1_link=None, p2_link=None):\n",
    "            if p1==None:\n",
    "                self.p1_probs = None\n",
    "            else:\n",
    "                self.p1_probs = np.zeros(8)\n",
    "                self.p1_probs[p1] = 1.0\n",
    "\n",
    "            if p2==None:\n",
    "                self.p2_probs = None\n",
    "            else:\n",
    "                self.p2_probs = np.zeros(8)\n",
    "                self.p2_probs[p2] = 1.0\n",
    "\n",
    "            # Links to previous cells\n",
    "            self.p1_link = p1_link\n",
    "            self.p2_link = p2_link\n",
    "\n",
    "            # Used for a (hopefully) temporary patch on the fact that these computations are not entirely accurate\n",
    "            self.pairwise_probs_zero_diagonal = pairwise_probs - 0.5 * np.identity(8)\n",
    "\n",
    "        # Get the probabilities from the previous cell.\n",
    "        # Should not be called if there are no links to previous cells.\n",
    "        def fetch_probs(self):\n",
    "            self.p1_probs = self.p1_link[0].compute_winner_probs() if self.p1_link[1] == 'winner' else self.p1_link[0].compute_loser_probs()\n",
    "            self.p2_probs = self.p2_link[0].compute_winner_probs() if self.p2_link[1] == 'winner' else self.p2_link[0].compute_loser_probs()\n",
    "        \n",
    "        # Probability of making it to this cell, and then proceeding to win\n",
    "        def compute_winner_probs(self):\n",
    "            if self.p1_probs is None or self.p2_probs is None:\n",
    "                self.fetch_probs()\n",
    "\n",
    "            probs = np.zeros(8)\n",
    "\n",
    "            # Old code, far less efficient. Might make the numpy operations make sense though.\n",
    "            '''\n",
    "            for p1 in range(0,8):\n",
    "                # Save a result for p1.\n",
    "                # It will be the sum over all p2 of\n",
    "                # (probability that p1 got there) * (probability that p2 got there) * (probability p1 beats p2)\n",
    "                for p2 in range(0,8):\n",
    "                    probs[p1] += self.p1_probs[p1] * self.p2_probs[p2] * pairwise_probs[p1, p2]\n",
    "                    probs[p2] += self.p1_probs[p1] * self.p2_probs[p2] * (1.0 - pairwise_probs[p1, p2])\n",
    "            '''\n",
    "            # Just remember that 1-pairwise_probs is the transpose of pairwise_probs, by symmetry\n",
    "            #\n",
    "            # TODO: I just realized that the probability of a certain player becoming p1 and another becoming p2 are NOT independent.\n",
    "            #       In particular, these probabilities become correlated when you could potentially have the same player as p1 or p2.\n",
    "            #       This is a bit of a janky patch that hopefully gives accurate enough probabilities, but we should come up with a proper fix.       \n",
    "            probs += self.p1_probs * (pairwise_probs_zero_diagonal @ self.p2_probs) # Probability that (specific p1) wins\n",
    "            probs += self.p2_probs * (pairwise_probs_zero_diagonal @ self.p1_probs) # Same but p2\n",
    "\n",
    "            probs /= probs.sum() # Purely due to zeroing out the diagonal of pairwise_probs\n",
    "\n",
    "            return probs\n",
    "\n",
    "        # Probability of making it to this cell, and then proceeding to lose\n",
    "        def compute_loser_probs(self):\n",
    "            if self.p1_probs is None or self.p2_probs is None:\n",
    "                self.fetch_probs()\n",
    "\n",
    "            probs = np.zeros(8)\n",
    "\n",
    "            '''\n",
    "            for p1 in range(0,8):\n",
    "                # Same, except use probability of p1 losing\n",
    "                for p2 in range(0,8):\n",
    "                    probs[p1] += self.p1_probs[p1] * self.p2_probs[p2] * (1.0 - pairwise_probs[p1, p2])\n",
    "                    probs[p2] += self.p1_probs[p1] * self.p2_probs[p2] * pairwise_probs[p1, p2]\n",
    "            '''\n",
    "            # TODO: Same janky patch as in winners case here.\n",
    "            probs += self.p1_probs * (pairwise_probs_zero_diagonal.T @ self.p2_probs)\n",
    "            probs += self.p2_probs * (pairwise_probs_zero_diagonal.T @ self.p1_probs)\n",
    "\n",
    "            probs /= probs.sum()\n",
    "             \n",
    "            return probs\n",
    "        \n",
    "    # 'LN_A_p1', 'LN_A_p2', 'LN_B_p1', 'LN_B_p2', 'WSF_A_p1', 'WSF_A_p2', 'WSF_B_p1', 'WSF_B_p2'\n",
    "    WSFA = cell(p1=4, p2=5)\n",
    "    WSFB = cell(p1=6, p2=7)\n",
    "    LNA  = cell(p1=0, p2=1)\n",
    "    LNB  = cell(p1=2, p2=3)\n",
    "\n",
    "    WF = cell(p1_link=(WSFA, 'winner'), p2_link=(WSFB, 'winner'))\n",
    "\n",
    "    LQFA = cell(p1_link=(WSFA, 'loser'), p2_link=(LNA, 'winner'))\n",
    "    LQFB = cell(p1_link=(WSFB, 'loser'), p2_link=(LNB, 'winner'))\n",
    "\n",
    "    LSF = cell(p1_link=(LQFA, 'winner'), p2_link=(LQFB, 'winner'))\n",
    "\n",
    "    LF = cell(p1_link=(WF, 'loser'), p2_link=(LSF, 'winner'))\n",
    "\n",
    "    GF = cell(p1_link=(WF, 'winner'), p2_link=(LF, 'winner'))\n",
    "\n",
    "    # From the Grand Final onwards, some special cases are required, due to how the Grand Final Reset works\n",
    "    GF.fetch_probs()\n",
    "\n",
    "    # TODO: Again, same janky fix as before, \"removing\" correlation between p1 and p2\n",
    "    win_as_p1_probs = GF.p1_probs * (pairwise_probs_zero_diagonal @ GF.p2_probs) # direct win as p1 (WF winner)\n",
    "    win_as_p1_probs += GF.p1_probs * ((pairwise_probs_zero_diagonal.T * pairwise_probs_zero_diagonal) @ GF.p2_probs) # p2 win, then p1 win in GFR\n",
    "\n",
    "    win_as_p2_probs = GF.p2_probs * ((pairwise_probs_zero_diagonal ** 2) @ GF.p1_probs) # win by 2 required for LF winner\n",
    "\n",
    "    probs = win_as_p1_probs + win_as_p2_probs\n",
    "    probs /= probs.sum() # Again due to that janky fix\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking and baselines\n",
    "\n",
    "Here, we start comparing the performance of a few \"obvious\" models, such as just choosing the person with the highest ELO out of the top 8 (or winners' side of the top 8), or simulating all possible paths throughout the top 8 and computing the probability of winning as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features += pairwise_prob_cols_reduced\n",
    "features += top_8_prevs_lengths + top_8_prevs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline of \"who has the higher elo\"\n",
    "\n",
    "def pull_elo_from_set(loc, outcome):\n",
    "    set_data = dataset_df.loc[loc]\n",
    "    player_num = 'p1' if outcome == (set_data['winner'] == 1.0) else 'p2' # Sneaky way of getting the player number\n",
    "\n",
    "    feature_to_pull = player_num + '_default_elo'\n",
    "    pulled_data = set_data[feature_to_pull]\n",
    "\n",
    "    return pulled_data\n",
    "\n",
    "# First, pull in player 1 data from a previous match.\n",
    "# Note that the player might NOT be player 1 in the match that we are pulling from\n",
    "tournament_df[[x + '_elo' for x in top_8_pos]] = tournament_df[[x + '_non_top_8_sets' for x in top_8_pos]].map(lambda x: pull_elo_from_set(x[0][0], x[0][1])).to_numpy()\n",
    "\n",
    "tournament_df['elo_prediction'] = tournament_df[[x + '_elo' for x in top_8_pos]].idxmax(axis=1).apply(lambda x: x.replace('_elo', ''))\n",
    "tournament_df['elo_prediction'] = tournament_df['elo_prediction'].apply(lambda x: top_8_pos.index(x))\n",
    "\n",
    "tournament_df['elo_WSF_prediction'] = tournament_df[[x + '_elo' for x in top_8_pos if \"WSF\" in x]].idxmax(axis=1).apply(lambda x: x.replace('_elo', ''))\n",
    "tournament_df['elo_WSF_prediction'] = tournament_df['elo_WSF_prediction'].apply(lambda x: top_8_pos.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor of \"who has the highest path probability, taking into account all possible paths on how the top 8 will play out\"\n",
    "\n",
    "result = tournament_df.apply(compute_path_prob, axis=1)\n",
    "tournament_df = pd.concat([tournament_df, pd.DataFrame(np.stack(result.to_numpy()), index=result.index, columns=[x + '_winprob' for x in top_8_pos])], axis=1)\n",
    "\n",
    "tournament_df['path_prediction'] = tournament_df[[x + '_winprob' for x in top_8_pos]].idxmax(axis=1).apply(lambda x: x.replace('_winprob', ''))\n",
    "tournament_df['path_prediction'] = tournament_df['path_prediction'].apply(lambda x: top_8_pos.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tournament_df[(tournament_df['start'] >= datetime.datetime(2023,1,1)) & (tournament_df['end'] <= datetime.datetime(2023,12,31))].copy()\n",
    "test_df  = tournament_df[(tournament_df['start'] >= datetime.datetime(2024,1,1)) & (tournament_df['end'] <= datetime.datetime(2024,12,31))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>key</th>\n",
       "      <th>cleaned_name</th>\n",
       "      <th>source</th>\n",
       "      <th>tournament_name</th>\n",
       "      <th>tournament_event</th>\n",
       "      <th>season</th>\n",
       "      <th>rank</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>...</th>\n",
       "      <th>elo_WSF_prediction</th>\n",
       "      <th>LN_A_p1_winprob</th>\n",
       "      <th>LN_A_p2_winprob</th>\n",
       "      <th>LN_B_p1_winprob</th>\n",
       "      <th>LN_B_p2_winprob</th>\n",
       "      <th>WSF_A_p1_winprob</th>\n",
       "      <th>WSF_A_p2_winprob</th>\n",
       "      <th>WSF_B_p1_winprob</th>\n",
       "      <th>WSF_B_p2_winprob</th>\n",
       "      <th>path_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18944</th>\n",
       "      <td>melee</td>\n",
       "      <td>kyojin-dojo__melee-singles</td>\n",
       "      <td>Kyojin Dojo</td>\n",
       "      <td>gg</td>\n",
       "      <td>kyojin-dojo</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>22</td>\n",
       "      <td></td>\n",
       "      <td>2023-01-01 11:00:00</td>\n",
       "      <td>2023-01-01 19:55:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3.573428e-06</td>\n",
       "      <td>1.565439e-05</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.860298</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.091003</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18951</th>\n",
       "      <td>melee</td>\n",
       "      <td>smash-scott-s-14__melee-singles</td>\n",
       "      <td>Smash @ Scott's #14</td>\n",
       "      <td>gg</td>\n",
       "      <td>smash-scott-s-14</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-01-01 20:00:00</td>\n",
       "      <td>2023-01-01 23:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>6.159430e-03</td>\n",
       "      <td>8.491993e-03</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.609582</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.072382</td>\n",
       "      <td>0.207516</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18948</th>\n",
       "      <td>melee</td>\n",
       "      <td>fight-of-the-fearless-33__fight-of-the-fearles...</td>\n",
       "      <td>Fight of the Fearless 33</td>\n",
       "      <td>gg</td>\n",
       "      <td>fight-of-the-fearless-33</td>\n",
       "      <td>fight-of-the-fearless-single</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-01-01 18:00:00</td>\n",
       "      <td>2023-01-01 23:59:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.443519e-04</td>\n",
       "      <td>6.080430e-05</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.272241</td>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.668195</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>melee</td>\n",
       "      <td>kalvar-cup-73-new-year-new-cup__melee-singles</td>\n",
       "      <td>kalvar Cup #73 New year New Cup</td>\n",
       "      <td>gg</td>\n",
       "      <td>kalvar-cup-73-new-year-new-cup</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "      <td>2023-01-02 03:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>3.515723e-04</td>\n",
       "      <td>3.821340e-04</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.877779</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.061392</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>melee</td>\n",
       "      <td>the-oven-no-29-ultimate-melee-weekly__smash-me...</td>\n",
       "      <td>The Oven No. 29 | Ultimate/Melee Weekly!</td>\n",
       "      <td>gg</td>\n",
       "      <td>the-oven-no-29-ultimate-melee-weekly</td>\n",
       "      <td>smash-melee-singles-bracket</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-01-01 19:00:00</td>\n",
       "      <td>2023-01-02 04:30:00</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>4.895094e-03</td>\n",
       "      <td>3.953563e-04</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.913414</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.019766</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32849</th>\n",
       "      <td>melee</td>\n",
       "      <td>melee-at-night-175__singles</td>\n",
       "      <td>Melee at Night #175</td>\n",
       "      <td>gg</td>\n",
       "      <td>melee-at-night-175</td>\n",
       "      <td>singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-30 05:00:00</td>\n",
       "      <td>2023-12-30 08:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>1.002784e-02</td>\n",
       "      <td>1.270200e-03</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.930893</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.040807</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32850</th>\n",
       "      <td>melee</td>\n",
       "      <td>smol-end-of-year-edition__melee-singles</td>\n",
       "      <td>SMOL: End of Year Edition</td>\n",
       "      <td>gg</td>\n",
       "      <td>smol-end-of-year-edition</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-30 07:00:00</td>\n",
       "      <td>2023-12-30 10:59:00</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1.311718e-03</td>\n",
       "      <td>6.772164e-03</td>\n",
       "      <td>0.279017</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.596631</td>\n",
       "      <td>0.028718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32848</th>\n",
       "      <td>melee</td>\n",
       "      <td>your-12th-restock__melee-singles</td>\n",
       "      <td>Your 12th Restock!</td>\n",
       "      <td>gg</td>\n",
       "      <td>your-12th-restock</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-30 05:00:00</td>\n",
       "      <td>2023-12-30 11:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2.389435e-05</td>\n",
       "      <td>2.039743e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.287602</td>\n",
       "      <td>0.221832</td>\n",
       "      <td>0.097256</td>\n",
       "      <td>0.393226</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32851</th>\n",
       "      <td>melee</td>\n",
       "      <td>super-smash-bxl-winter-chill-editions-1__dorfball</td>\n",
       "      <td>Super Smash BXL: Winter Chill Editions 1</td>\n",
       "      <td>gg</td>\n",
       "      <td>super-smash-bxl-winter-chill-editions-1</td>\n",
       "      <td>dorfball</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-29 23:00:00</td>\n",
       "      <td>2023-12-30 22:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4.081673e-03</td>\n",
       "      <td>2.942790e-05</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.187950</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32866</th>\n",
       "      <td>melee</td>\n",
       "      <td>the-melee-corner-abu-23__melee-singles</td>\n",
       "      <td>The Melee corner @ABU 23</td>\n",
       "      <td>gg</td>\n",
       "      <td>the-melee-corner-abu-23</td>\n",
       "      <td>melee-singles</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-30 21:00:00</td>\n",
       "      <td>2023-12-31 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>8.502935e-07</td>\n",
       "      <td>1.817182e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.404504</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10306 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game                                                key  \\\n",
       "18944  melee                         kyojin-dojo__melee-singles   \n",
       "18951  melee                    smash-scott-s-14__melee-singles   \n",
       "18948  melee  fight-of-the-fearless-33__fight-of-the-fearles...   \n",
       "18955  melee      kalvar-cup-73-new-year-new-cup__melee-singles   \n",
       "18950  melee  the-oven-no-29-ultimate-melee-weekly__smash-me...   \n",
       "...      ...                                                ...   \n",
       "32849  melee                        melee-at-night-175__singles   \n",
       "32850  melee            smol-end-of-year-edition__melee-singles   \n",
       "32848  melee                   your-12th-restock__melee-singles   \n",
       "32851  melee  super-smash-bxl-winter-chill-editions-1__dorfball   \n",
       "32866  melee             the-melee-corner-abu-23__melee-singles   \n",
       "\n",
       "                                   cleaned_name source  \\\n",
       "18944                               Kyojin Dojo     gg   \n",
       "18951                       Smash @ Scott's #14     gg   \n",
       "18948                  Fight of the Fearless 33     gg   \n",
       "18955           kalvar Cup #73 New year New Cup     gg   \n",
       "18950  The Oven No. 29 | Ultimate/Melee Weekly!     gg   \n",
       "...                                         ...    ...   \n",
       "32849                       Melee at Night #175     gg   \n",
       "32850                 SMOL: End of Year Edition     gg   \n",
       "32848                        Your 12th Restock!     gg   \n",
       "32851  Super Smash BXL: Winter Chill Editions 1     gg   \n",
       "32866                  The Melee corner @ABU 23     gg   \n",
       "\n",
       "                               tournament_name              tournament_event  \\\n",
       "18944                              kyojin-dojo                 melee-singles   \n",
       "18951                         smash-scott-s-14                 melee-singles   \n",
       "18948                 fight-of-the-fearless-33  fight-of-the-fearless-single   \n",
       "18955           kalvar-cup-73-new-year-new-cup                 melee-singles   \n",
       "18950     the-oven-no-29-ultimate-melee-weekly   smash-melee-singles-bracket   \n",
       "...                                        ...                           ...   \n",
       "32849                       melee-at-night-175                       singles   \n",
       "32850                 smol-end-of-year-edition                 melee-singles   \n",
       "32848                        your-12th-restock                 melee-singles   \n",
       "32851  super-smash-bxl-winter-chill-editions-1                      dorfball   \n",
       "32866                  the-melee-corner-abu-23                 melee-singles   \n",
       "\n",
       "      season rank               start                 end  ...  \\\n",
       "18944     22      2023-01-01 11:00:00 2023-01-01 19:55:00  ...   \n",
       "18951     23      2023-01-01 20:00:00 2023-01-01 23:00:00  ...   \n",
       "18948     23      2023-01-01 18:00:00 2023-01-01 23:59:00  ...   \n",
       "18955     23      2023-01-02 00:00:00 2023-01-02 03:00:00  ...   \n",
       "18950     23      2023-01-01 19:00:00 2023-01-02 04:30:00  ...   \n",
       "...      ...  ...                 ...                 ...  ...   \n",
       "32849     23      2023-12-30 05:00:00 2023-12-30 08:00:00  ...   \n",
       "32850     23      2023-12-30 07:00:00 2023-12-30 10:59:00  ...   \n",
       "32848     23      2023-12-30 05:00:00 2023-12-30 11:00:00  ...   \n",
       "32851     23      2023-12-29 23:00:00 2023-12-30 22:00:00  ...   \n",
       "32866     23      2023-12-30 21:00:00 2023-12-31 00:00:00  ...   \n",
       "\n",
       "      elo_WSF_prediction LN_A_p1_winprob LN_A_p2_winprob  LN_B_p1_winprob  \\\n",
       "18944                  5        0.001199    3.573428e-06     1.565439e-05   \n",
       "18951                  4        0.000413    6.159430e-03     8.491993e-03   \n",
       "18948                  7        0.000038    1.443519e-04     6.080430e-05   \n",
       "18955                  5        0.000242    3.515723e-04     3.821340e-04   \n",
       "18950                  4        0.000278    4.895094e-03     3.953563e-04   \n",
       "...                  ...             ...             ...              ...   \n",
       "32849                  5        0.001771    1.002784e-02     1.270200e-03   \n",
       "32850                  6        0.000712    1.311718e-03     6.772164e-03   \n",
       "32848                  5        0.000028    2.389435e-05     2.039743e-05   \n",
       "32851                  5        0.000013    4.081673e-03     2.942790e-05   \n",
       "32866                  7        0.000146    8.502935e-07     1.817182e-07   \n",
       "\n",
       "      LN_B_p2_winprob WSF_A_p1_winprob WSF_A_p2_winprob  WSF_B_p1_winprob  \\\n",
       "18944        0.000029         0.024960         0.860298          0.022492   \n",
       "18951        0.004781         0.609582         0.090675          0.072382   \n",
       "18948        0.000386         0.006876         0.272241          0.052058   \n",
       "18955        0.000260         0.010260         0.877779          0.049333   \n",
       "18950        0.002500         0.913414         0.046387          0.012365   \n",
       "...               ...              ...              ...               ...   \n",
       "32849        0.000028         0.010421         0.930893          0.004782   \n",
       "32850        0.279017         0.033600         0.053238          0.596631   \n",
       "32848        0.000012         0.287602         0.221832          0.097256   \n",
       "32851        0.000179         0.006610         0.797727          0.003410   \n",
       "32866        0.000003         0.001549         0.590604          0.003194   \n",
       "\n",
       "       WSF_B_p2_winprob  path_prediction  \n",
       "18944          0.091003                5  \n",
       "18951          0.207516                4  \n",
       "18948          0.668195                7  \n",
       "18955          0.061392                5  \n",
       "18950          0.019766                4  \n",
       "...                 ...              ...  \n",
       "32849          0.040807                5  \n",
       "32850          0.028718                6  \n",
       "32848          0.393226                7  \n",
       "32851          0.187950                5  \n",
       "32866          0.404504                5  \n",
       "\n",
       "[10306 rows x 137 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set baselines:\n",
      "Highest ELO out of top 8, accuracy:                66.3\n",
      "Highest ELO out of WSF, accuracy:                  68.5\n",
      "Computing all ways top 8 can play out, accuracy:   69.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set baselines:\")\n",
    "print(\"Highest ELO out of top 8, accuracy:               \", round(100.0 * (train_df['winner_index'] == train_df['elo_prediction']).astype(float).mean(), 1))\n",
    "print(\"Highest ELO out of WSF, accuracy:                 \", round(100.0 * (train_df['winner_index'] == train_df['elo_WSF_prediction']).astype(float).mean(), 1))\n",
    "print(\"Computing all ways top 8 can play out, accuracy:  \", round(100.0 * (train_df['winner_index'] == train_df['path_prediction']).astype(float).mean(), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more advanced model and hyperparameter tuning\n",
    "\n",
    "Just because choosing the highest ELO seems to be such a powerful predictor to begin with, we will make sure to add those to the list of features that we will use. We won't add any of the other old engineered features, because the model already has a bunch of new \"fancier\" engineered features, and too many might make it perform worse.\n",
    "\n",
    "**NOTE:** Hyperparameter tuning trials was reduced down to a very low number, so that this entire notebook could be run in a reasonable amount of time. Optimal parameters from a proper number of trials have already been found and are already provided after the hyperparameter tuning block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features += [x + '_elo' for x in top_8_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling ELO!\n"
     ]
    }
   ],
   "source": [
    "# Some features should NOT be scaled, like probabilities.\n",
    "# Let's just manually scale ELO (note that we will be using regularization)\n",
    "if tournament_df[[x + '_elo' for x in top_8_pos][0]].mean() >= 400.0: # Prevents this from accidentally being run twice.\n",
    "    print(\"Scaling ELO!\")\n",
    "    tournament_df[[x + '_elo' for x in top_8_pos]] /= 1500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 19:31:30,415] A new study created in memory with name: no-name-484766e6-3642-4321-8991-8888be910c13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 19:31:37,880] Trial 0 finished with value: 0.6842623329543227 and parameters: {'max_depth': 8, 'learning_rate': 0.1947534461077171, 'n_estimators': 300, 'subsample': 0.6017574047996106, 'colsample_bytree': 0.8497990504804047, 'gamma': 2.4833642202341433, 'min_child_weight': 10, 'lambda': 3.7789607073314855, 'alpha': 0.023684603933503544}. Best is trial 0 with value: 0.6842623329543227.\n",
      "[I 2024-11-29 19:31:53,583] Trial 1 finished with value: 0.6944504600375395 and parameters: {'max_depth': 9, 'learning_rate': 0.024632629061069267, 'n_estimators': 1000, 'subsample': 0.936956598811366, 'colsample_bytree': 0.6101009247093665, 'gamma': 4.20615154900435, 'min_child_weight': 10, 'lambda': 0.3644492590384484, 'alpha': 0.05375044209447076}. Best is trial 1 with value: 0.6944504600375395.\n",
      "[I 2024-11-29 19:32:22,326] Trial 2 finished with value: 0.6902778978072175 and parameters: {'max_depth': 8, 'learning_rate': 0.01180346695248142, 'n_estimators': 900, 'subsample': 0.9708328430801261, 'colsample_bytree': 0.945153356119045, 'gamma': 2.6115554743068206, 'min_child_weight': 8, 'lambda': 0.2401166287365501, 'alpha': 0.02116886962391556}. Best is trial 1 with value: 0.6944504600375395.\n",
      "[I 2024-11-29 19:32:36,991] Trial 3 finished with value: 0.6908603653752629 and parameters: {'max_depth': 7, 'learning_rate': 0.0480761069495391, 'n_estimators': 700, 'subsample': 0.8952279546824564, 'colsample_bytree': 0.9351486745099623, 'gamma': 1.5703983242133406, 'min_child_weight': 5, 'lambda': 3.4876715781045204, 'alpha': 0.04450965427010376}. Best is trial 1 with value: 0.6944504600375395.\n",
      "[I 2024-11-29 19:33:04,752] Trial 4 finished with value: 0.6945474720670312 and parameters: {'max_depth': 9, 'learning_rate': 0.014952521614597994, 'n_estimators': 600, 'subsample': 0.9536024605451823, 'colsample_bytree': 0.9854085593780513, 'gamma': 1.3262717335334684, 'min_child_weight': 7, 'lambda': 0.002089715482012244, 'alpha': 4.252282539536335}. Best is trial 4 with value: 0.6945474720670312.\n",
      "[I 2024-11-29 19:33:07,497] Trial 5 finished with value: 0.6943535044924901 and parameters: {'max_depth': 4, 'learning_rate': 0.023624504612717607, 'n_estimators': 100, 'subsample': 0.9510475645420405, 'colsample_bytree': 0.7381715841125386, 'gamma': 4.179760643514473, 'min_child_weight': 10, 'lambda': 0.1827364571357143, 'alpha': 0.012438567565567741}. Best is trial 4 with value: 0.6945474720670312.\n",
      "[I 2024-11-29 19:33:17,861] Trial 6 finished with value: 0.6967791723786559 and parameters: {'max_depth': 7, 'learning_rate': 0.015856362509936224, 'n_estimators': 500, 'subsample': 0.8976999833180626, 'colsample_bytree': 0.8121331803124322, 'gamma': 4.4147777477785946, 'min_child_weight': 4, 'lambda': 0.004763748204749599, 'alpha': 4.4068379950888374}. Best is trial 6 with value: 0.6967791723786559.\n",
      "[W 2024-11-29 19:33:21,241] Trial 7 failed with parameters: {'max_depth': 8, 'learning_rate': 0.20292587940866846, 'n_estimators': 450, 'subsample': 0.7830743853360028, 'colsample_bytree': 0.7994445915695656, 'gamma': 2.6520613470115935, 'min_child_weight': 9, 'lambda': 2.2772111697271717, 'alpha': 0.3941246943013597} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2186329/1769072175.py\", line 37, in objective\n",
      "    model.fit(train_df.iloc[train_index][features], train_df.iloc[train_index]['winner_index'])\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-29 19:33:21,244] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     45\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of finished trials: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_splits)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, val_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(train_df[features], train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinner_index\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwinner_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(train_df\u001b[38;5;241m.\u001b[39miloc[val_index][features])\n\u001b[1;32m     40\u001b[0m     results[i] \u001b[38;5;241m=\u001b[39m accuracy_score(train_df\u001b[38;5;241m.\u001b[39miloc[val_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinner_index\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning on XGBoost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth        = trial.suggest_int(\"max_depth\", 2, 15, step=1)\n",
    "    learning_rate    = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    n_estimators     = trial.suggest_int(\"n_estimators\", 50, 1000, step=25)\n",
    "    subsample        = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "    gamma            = trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    reg_lambda       = trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True)\n",
    "    reg_alpha        = trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True)\n",
    "\n",
    "    model = xgb.XGBClassifier(max_depth=max_depth,\n",
    "                              learning_rate=learning_rate,\n",
    "                              n_estimators=n_estimators,\n",
    "                              subsample=subsample,\n",
    "                              colsample_bytree=colsample_bytree,\n",
    "                              gamma=gamma,\n",
    "                              min_child_weight=min_child_weight,\n",
    "                              reg_lambda=reg_lambda,\n",
    "                              reg_alpha=reg_alpha)\n",
    "    \n",
    "    # The percentage of people that win the tournament when starting from losers side is very small, but not zero\n",
    "    # Hence, it is probably good to use a stratified k-fold split for cross-validation\n",
    "\n",
    "    n_splits = 3\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    results = np.zeros(n_splits)\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(skf.split(train_df[features], train_df['winner_index'])):\n",
    "        model.fit(train_df.iloc[train_index][features], train_df.iloc[train_index]['winner_index'])\n",
    "\n",
    "        y_pred = model.predict(train_df.iloc[val_index][features])\n",
    "        results[i] = accuracy_score(train_df.iloc[val_index]['winner_index'], y_pred)\n",
    "    \n",
    "    return results.mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=50, timeout=3600)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 19:41:50,554] A new study created in memory with name: no-name-3bb6ff78-7726-4c63-a7b8-386c6481b11a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512258cc602b4934949f3e387ab242e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 19:41:59,070] Trial 0 finished with value: 0.6915395625505889 and parameters: {'max_depth': 11, 'learning_rate': 0.10699616715731652, 'n_estimators': 200, 'subsample': 0.8050347328590993, 'colsample_bytree': 0.960056991948947, 'gamma': 4.243102240338591, 'min_child_weight': 9, 'reg_lambda': 0.004402583550744662, 'reg_alpha': 1.8930354942554257}. Best is trial 0 with value: 0.6915395625505889.\n",
      "[I 2024-11-29 19:42:44,614] Trial 1 finished with value: 0.6810599192611383 and parameters: {'max_depth': 10, 'learning_rate': 0.1664639531247863, 'n_estimators': 300, 'subsample': 0.7496115264813294, 'colsample_bytree': 0.8258281258583777, 'gamma': 0.11838893198305278, 'min_child_weight': 2, 'reg_lambda': 0.0017921279591632353, 'reg_alpha': 1.7856120248686316}. Best is trial 0 with value: 0.6915395625505889.\n",
      "[I 2024-11-29 19:43:00,712] Trial 2 finished with value: 0.6882404192501239 and parameters: {'max_depth': 6, 'learning_rate': 0.11453221839150102, 'n_estimators': 500, 'subsample': 0.744860667170449, 'colsample_bytree': 0.6427852340168022, 'gamma': 2.184069131507553, 'min_child_weight': 3, 'reg_lambda': 1.4038449514765552, 'reg_alpha': 0.03351123911093865}. Best is trial 0 with value: 0.6915395625505889.\n",
      "[I 2024-11-29 19:43:13,012] Trial 3 finished with value: 0.6940623271929095 and parameters: {'max_depth': 3, 'learning_rate': 0.05535384016606249, 'n_estimators': 200, 'subsample': 0.8167842640839046, 'colsample_bytree': 0.8192961488971373, 'gamma': 4.854221217865167, 'min_child_weight': 8, 'reg_lambda': 2.6750914247617703, 'reg_alpha': 0.002994268187489348}. Best is trial 3 with value: 0.6940623271929095.\n",
      "[I 2024-11-29 19:43:24,638] Trial 4 finished with value: 0.689211245600568 and parameters: {'max_depth': 8, 'learning_rate': 0.06657147832551227, 'n_estimators': 450, 'subsample': 0.9491455090857265, 'colsample_bytree': 0.9451369464353956, 'gamma': 2.0292772383823694, 'min_child_weight': 3, 'reg_lambda': 0.8712364843422317, 'reg_alpha': 0.13572054108063653}. Best is trial 3 with value: 0.6940623271929095.\n",
      "[I 2024-11-29 19:43:44,332] Trial 5 finished with value: 0.69513002436174 and parameters: {'max_depth': 3, 'learning_rate': 0.016868512494921033, 'n_estimators': 500, 'subsample': 0.7673953876074122, 'colsample_bytree': 0.9342020672798422, 'gamma': 1.7021904938220018, 'min_child_weight': 6, 'reg_lambda': 0.042865986986411544, 'reg_alpha': 0.00474283315502315}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:43:57,928] Trial 6 finished with value: 0.6933833277131313 and parameters: {'max_depth': 4, 'learning_rate': 0.07214282226173965, 'n_estimators': 350, 'subsample': 0.7671135476456821, 'colsample_bytree': 0.9485345604294887, 'gamma': 3.111168446452724, 'min_child_weight': 8, 'reg_lambda': 0.2823978518967545, 'reg_alpha': 0.009823352073568296}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:44:15,015] Trial 7 finished with value: 0.6948386211243905 and parameters: {'max_depth': 3, 'learning_rate': 0.010406740499988886, 'n_estimators': 300, 'subsample': 0.6422337160558765, 'colsample_bytree': 0.7933093830775486, 'gamma': 3.5160990229126927, 'min_child_weight': 4, 'reg_lambda': 0.010701252889080257, 'reg_alpha': 0.04845084505981279}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:44:18,893] Trial 8 finished with value: 0.6916364898534173 and parameters: {'max_depth': 4, 'learning_rate': 0.01492572359724544, 'n_estimators': 100, 'subsample': 0.8187170988218492, 'colsample_bytree': 0.9822354044033443, 'gamma': 4.421086646353938, 'min_child_weight': 6, 'reg_lambda': 0.018096945358150242, 'reg_alpha': 0.0010854188557423749}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:44:25,750] Trial 9 finished with value: 0.6920247074247105 and parameters: {'max_depth': 9, 'learning_rate': 0.05642486426538264, 'n_estimators': 250, 'subsample': 0.7295260061937161, 'colsample_bytree': 0.8105854910372823, 'gamma': 4.652232584065185, 'min_child_weight': 4, 'reg_lambda': 0.09457233724850353, 'reg_alpha': 0.003932515596259889}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:45:20,537] Trial 10 finished with value: 0.6895987571163337 and parameters: {'max_depth': 15, 'learning_rate': 0.02280221548212936, 'n_estimators': 400, 'subsample': 0.93424510256529, 'colsample_bytree': 0.8791797033030208, 'gamma': 1.033508952128189, 'min_child_weight': 6, 'reg_lambda': 0.06339245513338397, 'reg_alpha': 0.32336462674576805}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:45:39,821] Trial 11 finished with value: 0.6947415243682356 and parameters: {'max_depth': 6, 'learning_rate': 0.0103706395354319, 'n_estimators': 350, 'subsample': 0.6241285096848228, 'colsample_bytree': 0.7050551276175087, 'gamma': 3.283661798666858, 'min_child_weight': 5, 'reg_lambda': 0.013683120672349914, 'reg_alpha': 0.01573685989300555}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:46:35,685] Trial 12 finished with value: 0.6927037916311521 and parameters: {'max_depth': 6, 'learning_rate': 0.025460828416829295, 'n_estimators': 500, 'subsample': 0.6373010906844595, 'colsample_bytree': 0.7263801762610392, 'gamma': 1.3891277500893824, 'min_child_weight': 1, 'reg_lambda': 0.02857509188956146, 'reg_alpha': 0.056480799594747326}. Best is trial 5 with value: 0.69513002436174.\n",
      "[I 2024-11-29 19:47:05,766] Trial 13 finished with value: 0.6952266692423571 and parameters: {'max_depth': 3, 'learning_rate': 0.030922142331274844, 'n_estimators': 400, 'subsample': 0.6783471204348663, 'colsample_bytree': 0.8745935700261118, 'gamma': 3.335819404634185, 'min_child_weight': 7, 'reg_lambda': 0.0062650308198516505, 'reg_alpha': 0.25944080147979626}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:47:43,184] Trial 14 finished with value: 0.6901810834732736 and parameters: {'max_depth': 13, 'learning_rate': 0.029547141682214804, 'n_estimators': 450, 'subsample': 0.6852956871984957, 'colsample_bytree': 0.8814472016143176, 'gamma': 2.718820527119997, 'min_child_weight': 10, 'reg_lambda': 0.0017773973591046924, 'reg_alpha': 0.43659602322590424}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:48:09,637] Trial 15 finished with value: 0.6909569820136591 and parameters: {'max_depth': 5, 'learning_rate': 0.03529249522605244, 'n_estimators': 400, 'subsample': 0.8767595045606691, 'colsample_bytree': 0.896095426700671, 'gamma': 1.4860323632650048, 'min_child_weight': 7, 'reg_lambda': 0.3892305762873931, 'reg_alpha': 0.33093260178373674}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:49:08,157] Trial 16 finished with value: 0.69076332510355 and parameters: {'max_depth': 7, 'learning_rate': 0.01752301774596751, 'n_estimators': 450, 'subsample': 0.7041725815503233, 'colsample_bytree': 0.905807749797195, 'gamma': 0.5463438549857091, 'min_child_weight': 7, 'reg_lambda': 0.006454683217068703, 'reg_alpha': 7.490114210976633}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:50:03,030] Trial 17 finished with value: 0.6911515709170645 and parameters: {'max_depth': 3, 'learning_rate': 0.0388410857522163, 'n_estimators': 500, 'subsample': 0.6792774282050283, 'colsample_bytree': 0.7502465135599835, 'gamma': 3.677829808275023, 'min_child_weight': 5, 'reg_lambda': 6.765293498680706, 'reg_alpha': 0.14728436994743435}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:51:23,279] Trial 18 finished with value: 0.6931889929897159 and parameters: {'max_depth': 5, 'learning_rate': 0.01565982610148432, 'n_estimators': 400, 'subsample': 0.8864606341564486, 'colsample_bytree': 0.9992292576148216, 'gamma': 2.476522524566341, 'min_child_weight': 7, 'reg_lambda': 0.054753661994149806, 'reg_alpha': 1.025561046998442}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:51:31,727] Trial 19 finished with value: 0.6868821378683562 and parameters: {'max_depth': 12, 'learning_rate': 0.2908040708647021, 'n_estimators': 350, 'subsample': 0.6055174638133499, 'colsample_bytree': 0.8461090915412575, 'gamma': 4.030888064679619, 'min_child_weight': 10, 'reg_lambda': 0.22599332633706742, 'reg_alpha': 0.013108286290853406}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:51:57,990] Trial 20 finished with value: 0.6913457079449322 and parameters: {'max_depth': 8, 'learning_rate': 0.04210998600638082, 'n_estimators': 450, 'subsample': 0.8519895587953106, 'colsample_bytree': 0.9171354207435566, 'gamma': 1.8120012288067942, 'min_child_weight': 8, 'reg_lambda': 0.0045538213106138346, 'reg_alpha': 9.6973490365813}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:52:32,389] Trial 21 finished with value: 0.6948386776088328 and parameters: {'max_depth': 3, 'learning_rate': 0.010082586164365987, 'n_estimators': 300, 'subsample': 0.6501776721433876, 'colsample_bytree': 0.7874697351468781, 'gamma': 3.5842686812844016, 'min_child_weight': 4, 'reg_lambda': 0.010510951775336378, 'reg_alpha': 0.042169978294694085}. Best is trial 13 with value: 0.6952266692423571.\n",
      "[I 2024-11-29 19:52:53,201] Trial 22 finished with value: 0.6955179595108222 and parameters: {'max_depth': 4, 'learning_rate': 0.01923206887200762, 'n_estimators': 300, 'subsample': 0.6647824536785198, 'colsample_bytree': 0.7607416293787163, 'gamma': 2.798027432594983, 'min_child_weight': 4, 'reg_lambda': 0.036736527745457014, 'reg_alpha': 0.005316793797548735}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:53:24,373] Trial 23 finished with value: 0.694644794760955 and parameters: {'max_depth': 5, 'learning_rate': 0.021058209172971836, 'n_estimators': 250, 'subsample': 0.7109707250670477, 'colsample_bytree': 0.6692759643757806, 'gamma': 2.6499943304270985, 'min_child_weight': 6, 'reg_lambda': 0.02985655848662119, 'reg_alpha': 0.0015420378234658981}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:54:02,729] Trial 24 finished with value: 0.6942564359785562 and parameters: {'max_depth': 4, 'learning_rate': 0.0151787387129799, 'n_estimators': 400, 'subsample': 0.9977477067853013, 'colsample_bytree': 0.8601316003787078, 'gamma': 2.912014770142284, 'min_child_weight': 5, 'reg_lambda': 0.0010707156101113218, 'reg_alpha': 0.005871551401620254}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:54:55,565] Trial 25 finished with value: 0.6928010578406337 and parameters: {'max_depth': 4, 'learning_rate': 0.029718553652855112, 'n_estimators': 350, 'subsample': 0.6722167694900111, 'colsample_bytree': 0.7627482199828105, 'gamma': 2.29966978000593, 'min_child_weight': 7, 'reg_lambda': 0.16744976243188348, 'reg_alpha': 0.02134238611543928}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:55:45,233] Trial 26 finished with value: 0.6939651174678702 and parameters: {'max_depth': 7, 'learning_rate': 0.01966915430758465, 'n_estimators': 250, 'subsample': 0.7611963716137551, 'colsample_bytree': 0.9214316429566609, 'gamma': 1.7470638002706569, 'min_child_weight': 3, 'reg_lambda': 0.03544572188941291, 'reg_alpha': 0.0022076570083318678}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:55:48,542] Trial 27 finished with value: 0.6931891342008214 and parameters: {'max_depth': 5, 'learning_rate': 0.012974364855544394, 'n_estimators': 100, 'subsample': 0.7758339192270783, 'colsample_bytree': 0.8546174963094714, 'gamma': 1.0073973966043348, 'min_child_weight': 6, 'reg_lambda': 0.13776076546623336, 'reg_alpha': 0.007311762644457371}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:56:02,761] Trial 28 finished with value: 0.6929951383840591 and parameters: {'max_depth': 3, 'learning_rate': 0.03118810661183244, 'n_estimators': 500, 'subsample': 0.7183098926096493, 'colsample_bytree': 0.7617509382396441, 'gamma': 3.9936471060677547, 'min_child_weight': 9, 'reg_lambda': 0.0026619757139327693, 'reg_alpha': 0.08940363751583709}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:56:17,445] Trial 29 finished with value: 0.6935773517721148 and parameters: {'max_depth': 4, 'learning_rate': 0.04335247604743436, 'n_estimators': 200, 'subsample': 0.7879475480175089, 'colsample_bytree': 0.9664986722807026, 'gamma': 2.9597334208197097, 'min_child_weight': 9, 'reg_lambda': 0.006826326205275817, 'reg_alpha': 0.810813397813465}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:56:30,370] Trial 30 finished with value: 0.694450573006424 and parameters: {'max_depth': 7, 'learning_rate': 0.024803949777398252, 'n_estimators': 150, 'subsample': 0.6645093805960317, 'colsample_bytree': 0.7046978666507888, 'gamma': 3.3040431993214403, 'min_child_weight': 5, 'reg_lambda': 0.060825323166370356, 'reg_alpha': 0.004911246736598051}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:56:45,285] Trial 31 finished with value: 0.694353476250269 and parameters: {'max_depth': 3, 'learning_rate': 0.01269646269128791, 'n_estimators': 300, 'subsample': 0.6019620097964584, 'colsample_bytree': 0.7796686432146301, 'gamma': 3.691854492873364, 'min_child_weight': 4, 'reg_lambda': 0.01653277384552744, 'reg_alpha': 0.03220008417808414}. Best is trial 22 with value: 0.6955179595108222.\n",
      "[I 2024-11-29 19:57:26,787] Trial 32 finished with value: 0.6958087414193072 and parameters: {'max_depth': 3, 'learning_rate': 0.01280216411439689, 'n_estimators': 300, 'subsample': 0.6960466589785876, 'colsample_bytree': 0.8395891254823703, 'gamma': 3.8263660986218144, 'min_child_weight': 2, 'reg_lambda': 0.010121853758433445, 'reg_alpha': 0.15076122149685417}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 19:57:47,083] Trial 33 finished with value: 0.6948386776088329 and parameters: {'max_depth': 4, 'learning_rate': 0.0182619582703325, 'n_estimators': 250, 'subsample': 0.6939577850092389, 'colsample_bytree': 0.8383862309950243, 'gamma': 4.282815161198999, 'min_child_weight': 1, 'reg_lambda': 0.0034343369579282004, 'reg_alpha': 3.939524885987083}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 19:58:35,798] Trial 34 finished with value: 0.6946443711276383 and parameters: {'max_depth': 10, 'learning_rate': 0.012828430599338692, 'n_estimators': 300, 'subsample': 0.7444444252549132, 'colsample_bytree': 0.6044757098884053, 'gamma': 2.3439492836821003, 'min_child_weight': 2, 'reg_lambda': 0.022396435316558258, 'reg_alpha': 0.2000769357915735}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 19:59:46,271] Trial 35 finished with value: 0.695129798423971 and parameters: {'max_depth': 5, 'learning_rate': 0.024673505635625134, 'n_estimators': 350, 'subsample': 0.7419432347236247, 'colsample_bytree': 0.9384278232434778, 'gamma': 4.006631329052407, 'min_child_weight': 3, 'reg_lambda': 0.008494472333562203, 'reg_alpha': 0.07155250013416943}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:00:07,862] Trial 36 finished with value: 0.6915396755194733 and parameters: {'max_depth': 3, 'learning_rate': 0.09984433099444474, 'n_estimators': 300, 'subsample': 0.8045864752492604, 'colsample_bytree': 0.8175757061464692, 'gamma': 2.0104947447969037, 'min_child_weight': 2, 'reg_lambda': 0.04464695025829558, 'reg_alpha': 0.6569984942447388}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:00:43,800] Trial 37 finished with value: 0.6947417785482256 and parameters: {'max_depth': 6, 'learning_rate': 0.018804837790689453, 'n_estimators': 450, 'subsample': 0.7207584134427462, 'colsample_bytree': 0.8771827136070878, 'gamma': 3.2241291431459045, 'min_child_weight': 2, 'reg_lambda': 0.6759745467152688, 'reg_alpha': 0.21144627903101282}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:01:00,269] Trial 38 finished with value: 0.6945475567936946 and parameters: {'max_depth': 4, 'learning_rate': 0.012730369266869655, 'n_estimators': 200, 'subsample': 0.6559799561447004, 'colsample_bytree': 0.8288575875823956, 'gamma': 2.781303095858865, 'min_child_weight': 8, 'reg_lambda': 0.09845664067000848, 'reg_alpha': 0.025570044465017934}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:01:40,172] Trial 39 finished with value: 0.6954206650591194 and parameters: {'max_depth': 3, 'learning_rate': 0.01593158320151157, 'n_estimators': 400, 'subsample': 0.8296303618029234, 'colsample_bytree': 0.9357800297162653, 'gamma': 4.936942109957817, 'min_child_weight': 4, 'reg_lambda': 0.005049121969268751, 'reg_alpha': 1.807053042367961}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:01:56,337] Trial 40 finished with value: 0.6940624684040152 and parameters: {'max_depth': 3, 'learning_rate': 0.05051978731476798, 'n_estimators': 350, 'subsample': 0.8364148443924566, 'colsample_bytree': 0.9616823073456859, 'gamma': 4.919259892974263, 'min_child_weight': 3, 'reg_lambda': 0.00216426196349932, 'reg_alpha': 1.6133701430109895}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:02:27,099] Trial 41 finished with value: 0.6932860897458708 and parameters: {'max_depth': 4, 'learning_rate': 0.015366030309814703, 'n_estimators': 400, 'subsample': 0.8271854088006944, 'colsample_bytree': 0.9352207179573794, 'gamma': 4.654048622104159, 'min_child_weight': 4, 'reg_lambda': 0.004486099769891019, 'reg_alpha': 1.8745309270087978}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:02:43,206] Trial 42 finished with value: 0.6938683031339264 and parameters: {'max_depth': 3, 'learning_rate': 0.020502194083943454, 'n_estimators': 250, 'subsample': 0.7899216012226741, 'colsample_bytree': 0.8961921485948796, 'gamma': 4.509654352818023, 'min_child_weight': 6, 'reg_lambda': 0.014962589830427257, 'reg_alpha': 3.2802297071654882}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:03:14,274] Trial 43 finished with value: 0.6937712911044347 and parameters: {'max_depth': 4, 'learning_rate': 0.011706214903173808, 'n_estimators': 300, 'subsample': 0.6238973985663443, 'colsample_bytree': 0.8692277562892142, 'gamma': 3.8613940673879252, 'min_child_weight': 5, 'reg_lambda': 0.00622851762551862, 'reg_alpha': 0.10413557866809617}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:04:21,781] Trial 44 finished with value: 0.6928980981123464 and parameters: {'max_depth': 5, 'learning_rate': 0.01671051091330637, 'n_estimators': 500, 'subsample': 0.8655043383618681, 'colsample_bytree': 0.9784719204526507, 'gamma': 3.3677831105704494, 'min_child_weight': 4, 'reg_lambda': 0.0012804545945176132, 'reg_alpha': 0.0027152660487728612}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:04:45,770] Trial 45 finished with value: 0.6931892471697059 and parameters: {'max_depth': 3, 'learning_rate': 0.027787466379296865, 'n_estimators': 350, 'subsample': 0.894263743746902, 'colsample_bytree': 0.9251530004647356, 'gamma': 3.0456163611354747, 'min_child_weight': 1, 'reg_lambda': 0.01116934299093485, 'reg_alpha': 0.009579839681236834}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:06:04,572] Trial 46 finished with value: 0.6930919527180031 and parameters: {'max_depth': 15, 'learning_rate': 0.023323789702125862, 'n_estimators': 400, 'subsample': 0.7000613495759347, 'colsample_bytree': 0.8113923387774621, 'gamma': 4.239735814245742, 'min_child_weight': 3, 'reg_lambda': 0.021891935198476944, 'reg_alpha': 0.5065210176979331}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:06:51,681] Trial 47 finished with value: 0.6914424093099917 and parameters: {'max_depth': 6, 'learning_rate': 0.03613077068508852, 'n_estimators': 450, 'subsample': 0.9188173953978933, 'colsample_bytree': 0.8988698144390659, 'gamma': 2.144914700258242, 'min_child_weight': 6, 'reg_lambda': 0.08326663681220381, 'reg_alpha': 0.0010241467310910977}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:07:41,089] Trial 48 finished with value: 0.6936744485282696 and parameters: {'max_depth': 4, 'learning_rate': 0.013509223437534662, 'n_estimators': 450, 'subsample': 0.630017892981571, 'colsample_bytree': 0.7362227855703652, 'gamma': 4.753066139271147, 'min_child_weight': 7, 'reg_lambda': 0.002875594213129038, 'reg_alpha': 0.24139090147952202}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:08:14,379] Trial 49 finished with value: 0.6915399296994632 and parameters: {'max_depth': 5, 'learning_rate': 0.07621257234929056, 'n_estimators': 400, 'subsample': 0.7357485823115477, 'colsample_bytree': 0.9408432644987087, 'gamma': 2.557586109150468, 'min_child_weight': 5, 'reg_lambda': 0.03785999105390081, 'reg_alpha': 1.044014398554665}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:08:51,580] Trial 50 finished with value: 0.6925099935099376 and parameters: {'max_depth': 14, 'learning_rate': 0.021648018294749813, 'n_estimators': 350, 'subsample': 0.6864065110136439, 'colsample_bytree': 0.8351091110745178, 'gamma': 1.1674231409488596, 'min_child_weight': 2, 'reg_lambda': 0.0041472564161947655, 'reg_alpha': 2.8229603035890234}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:09:12,615] Trial 51 finished with value: 0.6955180724797065 and parameters: {'max_depth': 3, 'learning_rate': 0.02566339319529303, 'n_estimators': 350, 'subsample': 0.7552914144941021, 'colsample_bytree': 0.9111600564250242, 'gamma': 3.843937816560951, 'min_child_weight': 3, 'reg_lambda': 0.008179537866192904, 'reg_alpha': 0.07975798250286639}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:09:44,543] Trial 52 finished with value: 0.6952266692423571 and parameters: {'max_depth': 3, 'learning_rate': 0.017560897206586382, 'n_estimators': 300, 'subsample': 0.7610890507137673, 'colsample_bytree': 0.9065379936556479, 'gamma': 3.4867772920274462, 'min_child_weight': 3, 'reg_lambda': 0.00970022072371744, 'reg_alpha': 0.1406730456194507}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:10:19,257] Trial 53 finished with value: 0.6941595369179488 and parameters: {'max_depth': 3, 'learning_rate': 0.03370875908397926, 'n_estimators': 300, 'subsample': 0.7639155868281756, 'colsample_bytree': 0.9114544749125986, 'gamma': 3.4684390252844057, 'min_child_weight': 3, 'reg_lambda': 0.0067190684409859855, 'reg_alpha': 0.13179053242064392}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:10:44,376] Trial 54 finished with value: 0.6936743920438274 and parameters: {'max_depth': 3, 'learning_rate': 0.026596979600118524, 'n_estimators': 350, 'subsample': 0.7302184133380016, 'colsample_bytree': 0.8864635959323527, 'gamma': 3.7692966678475104, 'min_child_weight': 2, 'reg_lambda': 0.009613140169252557, 'reg_alpha': 0.2916995446669083}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:11:19,673] Trial 55 finished with value: 0.6950325886989317 and parameters: {'max_depth': 4, 'learning_rate': 0.01777801945951752, 'n_estimators': 350, 'subsample': 0.8081102252160288, 'colsample_bytree': 0.8573120268821597, 'gamma': 4.996049071573977, 'min_child_weight': 3, 'reg_lambda': 0.0018783515604325926, 'reg_alpha': 0.3963730263601071}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:11:52,036] Trial 56 finished with value: 0.6920244532447205 and parameters: {'max_depth': 10, 'learning_rate': 0.010882689747404015, 'n_estimators': 250, 'subsample': 0.7803770992479111, 'colsample_bytree': 0.9536330866168663, 'gamma': 4.2120005634503315, 'min_child_weight': 4, 'reg_lambda': 0.00573659208231081, 'reg_alpha': 0.05985648321536998}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:12:37,139] Trial 57 finished with value: 0.69512977018175 and parameters: {'max_depth': 3, 'learning_rate': 0.014593665323282266, 'n_estimators': 300, 'subsample': 0.7576341638013295, 'colsample_bytree': 0.870928305190799, 'gamma': 3.1012480407391685, 'min_child_weight': 3, 'reg_lambda': 0.013147630892006882, 'reg_alpha': 0.1558466601809659}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:13:01,869] Trial 58 finished with value: 0.6895023099312642 and parameters: {'max_depth': 5, 'learning_rate': 0.18320799251255496, 'n_estimators': 400, 'subsample': 0.6711380777443813, 'colsample_bytree': 0.9095417139708966, 'gamma': 3.502013984365999, 'min_child_weight': 4, 'reg_lambda': 0.021692455541600958, 'reg_alpha': 0.09229114717834123}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:14:57,122] Trial 59 finished with value: 0.6909570102558801 and parameters: {'max_depth': 11, 'learning_rate': 0.0216745437527341, 'n_estimators': 300, 'subsample': 0.6539457558752338, 'colsample_bytree': 0.8031999109093471, 'gamma': 0.08501690107660043, 'min_child_weight': 2, 'reg_lambda': 0.008597454937353458, 'reg_alpha': 0.0469753441736109}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:16:27,604] Trial 60 finished with value: 0.6944505165219818 and parameters: {'max_depth': 4, 'learning_rate': 0.011455222993680285, 'n_estimators': 400, 'subsample': 0.7113261572612187, 'colsample_bytree': 0.9867079308701256, 'gamma': 2.7971033367576243, 'min_child_weight': 4, 'reg_lambda': 0.026120452909892376, 'reg_alpha': 1.3722424088620742}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:17:01,791] Trial 61 finished with value: 0.695032927605585 and parameters: {'max_depth': 3, 'learning_rate': 0.01601824442270088, 'n_estimators': 450, 'subsample': 0.7522765142547344, 'colsample_bytree': 0.9307711428136276, 'gamma': 3.169507031518089, 'min_child_weight': 7, 'reg_lambda': 0.01618436370176609, 'reg_alpha': 0.00365648703026944}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:17:58,487] Trial 62 finished with value: 0.6950325886989317 and parameters: {'max_depth': 3, 'learning_rate': 0.019135272863239332, 'n_estimators': 300, 'subsample': 0.8218541812886022, 'colsample_bytree': 0.8913140551135527, 'gamma': 4.413899803873285, 'min_child_weight': 3, 'reg_lambda': 0.049427545577879387, 'reg_alpha': 0.014154335889539732}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:18:34,867] Trial 63 finished with value: 0.6950329840900271 and parameters: {'max_depth': 4, 'learning_rate': 0.014243284027124211, 'n_estimators': 350, 'subsample': 0.7927301464171749, 'colsample_bytree': 0.9526864690396036, 'gamma': 0.6152748014334848, 'min_child_weight': 5, 'reg_lambda': 0.004679652974521673, 'reg_alpha': 0.0018006939369277122}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:18:55,681] Trial 64 finished with value: 0.6938681901650418 and parameters: {'max_depth': 4, 'learning_rate': 0.016758420527282058, 'n_estimators': 250, 'subsample': 0.8408954998925641, 'colsample_bytree': 0.9183941241615916, 'gamma': 3.8646486083535088, 'min_child_weight': 6, 'reg_lambda': 4.477434595363765, 'reg_alpha': 4.7998376549446435}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:19:15,622] Trial 65 finished with value: 0.693868500829474 and parameters: {'max_depth': 3, 'learning_rate': 0.0230576008612342, 'n_estimators': 350, 'subsample': 0.7713059342233591, 'colsample_bytree': 0.7748234094271889, 'gamma': 3.6128849676175188, 'min_child_weight': 7, 'reg_lambda': 0.0031735148908613154, 'reg_alpha': 0.009077249698464428}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:20:08,927] Trial 66 finished with value: 0.6925099370254953 and parameters: {'max_depth': 9, 'learning_rate': 0.030724703809655127, 'n_estimators': 300, 'subsample': 0.689574217259832, 'colsample_bytree': 0.8502973110398949, 'gamma': 3.3601189430093332, 'min_child_weight': 1, 'reg_lambda': 0.07911046817521901, 'reg_alpha': 0.018698231653566946}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:20:24,523] Trial 67 finished with value: 0.6950327863944795 and parameters: {'max_depth': 3, 'learning_rate': 0.026781746395640384, 'n_estimators': 500, 'subsample': 0.7221900047357033, 'colsample_bytree': 0.904951317583076, 'gamma': 4.0781036802488595, 'min_child_weight': 4, 'reg_lambda': 0.034312553626532474, 'reg_alpha': 0.5710221301223237}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:20:59,540] Trial 68 finished with value: 0.6920243967602783 and parameters: {'max_depth': 8, 'learning_rate': 0.020112509768762964, 'n_estimators': 250, 'subsample': 0.6392371392713438, 'colsample_bytree': 0.8663950096803532, 'gamma': 1.821936954773522, 'min_child_weight': 8, 'reg_lambda': 0.01134931801234105, 'reg_alpha': 0.006336197518542302}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:21:15,991] Trial 69 finished with value: 0.6921218324230866 and parameters: {'max_depth': 6, 'learning_rate': 0.047989752242412434, 'n_estimators': 400, 'subsample': 0.677716032735341, 'colsample_bytree': 0.7170641933488251, 'gamma': 2.9456137143131285, 'min_child_weight': 3, 'reg_lambda': 0.0014522293571149528, 'reg_alpha': 0.03711532838349816}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:21:40,388] Trial 70 finished with value: 0.6956148303292083 and parameters: {'max_depth': 4, 'learning_rate': 0.014305512387224646, 'n_estimators': 350, 'subsample': 0.6161569017418463, 'colsample_bytree': 0.8426423837430176, 'gamma': 2.4544065791140373, 'min_child_weight': 5, 'reg_lambda': 0.1454550092630635, 'reg_alpha': 0.07862906487512068}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:22:32,888] Trial 71 finished with value: 0.6952268104534628 and parameters: {'max_depth': 4, 'learning_rate': 0.013878217123439165, 'n_estimators': 350, 'subsample': 0.6173307403143891, 'colsample_bytree': 0.8424210684247436, 'gamma': 2.4510580480751596, 'min_child_weight': 5, 'reg_lambda': 0.1680441303273122, 'reg_alpha': 0.12556041594265868}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:23:42,262] Trial 72 finished with value: 0.6953237942407333 and parameters: {'max_depth': 5, 'learning_rate': 0.012052965554200875, 'n_estimators': 350, 'subsample': 0.614631543867229, 'colsample_bytree': 0.795847385099259, 'gamma': 2.411116703930524, 'min_child_weight': 5, 'reg_lambda': 0.15267227221613688, 'reg_alpha': 0.07023366551443418}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:24:14,442] Trial 73 finished with value: 0.693674307317164 and parameters: {'max_depth': 5, 'learning_rate': 0.010208984385989483, 'n_estimators': 350, 'subsample': 0.6104368360646469, 'colsample_bytree': 0.7961072977577941, 'gamma': 2.417356928636477, 'min_child_weight': 5, 'reg_lambda': 0.3600661612129028, 'reg_alpha': 0.07129848046567996}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:24:30,910] Trial 74 finished with value: 0.6943535892191534 and parameters: {'max_depth': 4, 'learning_rate': 0.011800103991614293, 'n_estimators': 400, 'subsample': 0.6195977295576772, 'colsample_bytree': 0.8443983868559718, 'gamma': 2.567970827657787, 'min_child_weight': 5, 'reg_lambda': 0.13587842100547334, 'reg_alpha': 0.0712504515967444}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:24:48,592] Trial 75 finished with value: 0.69474189151711 and parameters: {'max_depth': 5, 'learning_rate': 0.014207496044174026, 'n_estimators': 350, 'subsample': 0.6466831829239016, 'colsample_bytree': 0.8194792330705789, 'gamma': 2.015480465852481, 'min_child_weight': 5, 'reg_lambda': 0.21661907326589377, 'reg_alpha': 0.028923465996507067}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:25:10,367] Trial 76 finished with value: 0.6946447382765127 and parameters: {'max_depth': 4, 'learning_rate': 0.012243569595593884, 'n_estimators': 350, 'subsample': 0.6103789772756558, 'colsample_bytree': 0.8271803261902267, 'gamma': 2.1831998128432426, 'min_child_weight': 6, 'reg_lambda': 0.8342845175831173, 'reg_alpha': 0.17571081729634927}. Best is trial 32 with value: 0.6958087414193072.\n",
      "[I 2024-11-29 20:25:32,761] Trial 77 finished with value: 0.6965854307418836 and parameters: {'max_depth': 4, 'learning_rate': 0.015713191321715846, 'n_estimators': 400, 'subsample': 0.6339631791059304, 'colsample_bytree': 0.7556927610372619, 'gamma': 2.729033112110066, 'min_child_weight': 4, 'reg_lambda': 0.1309235448664183, 'reg_alpha': 0.24192048329568183}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:25:43,342] Trial 78 finished with value: 0.6938684161028107 and parameters: {'max_depth': 6, 'learning_rate': 0.01408556560813437, 'n_estimators': 350, 'subsample': 0.6319102575583955, 'colsample_bytree': 0.7662494135355301, 'gamma': 2.2934774808376104, 'min_child_weight': 4, 'reg_lambda': 0.12830751636237925, 'reg_alpha': 0.10160306903056779}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:26:07,197] Trial 79 finished with value: 0.6949358590916511 and parameters: {'max_depth': 5, 'learning_rate': 0.015772010969923974, 'n_estimators': 400, 'subsample': 0.6634023766225695, 'colsample_bytree': 0.7440132450151167, 'gamma': 2.6744828194450054, 'min_child_weight': 4, 'reg_lambda': 0.19525522659180994, 'reg_alpha': 0.12272637164976335}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:26:20,588] Trial 80 finished with value: 0.6944507142175295 and parameters: {'max_depth': 4, 'learning_rate': 0.010884348465853198, 'n_estimators': 350, 'subsample': 0.6164532822403193, 'colsample_bytree': 0.784124518087797, 'gamma': 1.5724540629388606, 'min_child_weight': 5, 'reg_lambda': 0.2689334659424734, 'reg_alpha': 0.38250070332021635}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:26:40,224] Trial 81 finished with value: 0.6954209757235515 and parameters: {'max_depth': 4, 'learning_rate': 0.013021780035584159, 'n_estimators': 400, 'subsample': 0.6007375078140652, 'colsample_bytree': 0.757738455145453, 'gamma': 2.696916961177247, 'min_child_weight': 4, 'reg_lambda': 0.33194242404971747, 'reg_alpha': 0.25620277474671765}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:26:53,671] Trial 82 finished with value: 0.6958090520837392 and parameters: {'max_depth': 4, 'learning_rate': 0.013706257791623398, 'n_estimators': 400, 'subsample': 0.6029615039886115, 'colsample_bytree': 0.7557550009883491, 'gamma': 2.8136604113669197, 'min_child_weight': 4, 'reg_lambda': 0.3958373845751948, 'reg_alpha': 0.2193593644055874}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:27:09,011] Trial 83 finished with value: 0.6959061770821154 and parameters: {'max_depth': 5, 'learning_rate': 0.012770767902830276, 'n_estimators': 400, 'subsample': 0.6013730408280088, 'colsample_bytree': 0.7524886535009957, 'gamma': 2.8105672588024637, 'min_child_weight': 4, 'reg_lambda': 0.3180865259469949, 'reg_alpha': 0.23781407120215275}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:27:20,278] Trial 84 finished with value: 0.6942564642207772 and parameters: {'max_depth': 5, 'learning_rate': 0.015406813396720535, 'n_estimators': 450, 'subsample': 0.636060015106632, 'colsample_bytree': 0.6843503952211227, 'gamma': 2.8756949189700913, 'min_child_weight': 4, 'reg_lambda': 0.5682482567209087, 'reg_alpha': 0.25370365107995446}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:27:32,273] Trial 85 finished with value: 0.6942565489474406 and parameters: {'max_depth': 4, 'learning_rate': 0.013186511781484864, 'n_estimators': 400, 'subsample': 0.6051530018644402, 'colsample_bytree': 0.7280874600342921, 'gamma': 3.0370643658522605, 'min_child_weight': 4, 'reg_lambda': 0.46146823305139606, 'reg_alpha': 0.4952967850673697}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:27:43,878] Trial 86 finished with value: 0.6941597063712757 and parameters: {'max_depth': 4, 'learning_rate': 0.016895162907827912, 'n_estimators': 400, 'subsample': 0.6457134683448948, 'colsample_bytree': 0.7600342969274924, 'gamma': 2.716166238566772, 'min_child_weight': 4, 'reg_lambda': 1.2302316342652215, 'reg_alpha': 0.19433000344649068}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:27:59,114] Trial 87 finished with value: 0.6961001164144354 and parameters: {'max_depth': 3, 'learning_rate': 0.01001759760552429, 'n_estimators': 450, 'subsample': 0.6005278759752439, 'colsample_bytree': 0.7493660183799854, 'gamma': 2.8092175932853105, 'min_child_weight': 4, 'reg_lambda': 0.3106518390283381, 'reg_alpha': 0.30377394005709}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:28:12,741] Trial 88 finished with value: 0.695032701667816 and parameters: {'max_depth': 3, 'learning_rate': 0.01063652844300954, 'n_estimators': 450, 'subsample': 0.6250405928507681, 'colsample_bytree': 0.7445756145944351, 'gamma': 2.6102801483279308, 'min_child_weight': 3, 'reg_lambda': 0.32992863735633626, 'reg_alpha': 0.3534899901277778}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:28:32,533] Trial 89 finished with value: 0.6953239354518388 and parameters: {'max_depth': 5, 'learning_rate': 0.012907057591729245, 'n_estimators': 450, 'subsample': 0.60134697650123, 'colsample_bytree': 0.7102312183924655, 'gamma': 2.8647581131579694, 'min_child_weight': 4, 'reg_lambda': 0.45622855386594885, 'reg_alpha': 0.23310689829905584}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:28:44,162] Trial 90 finished with value: 0.6947417503060045 and parameters: {'max_depth': 6, 'learning_rate': 0.011456535419120117, 'n_estimators': 400, 'subsample': 0.6279774533148228, 'colsample_bytree': 0.752255292345905, 'gamma': 3.2168738207791057, 'min_child_weight': 3, 'reg_lambda': 0.27048045242911684, 'reg_alpha': 0.2953264331842697}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:28:53,635] Trial 91 finished with value: 0.6954211451768783 and parameters: {'max_depth': 3, 'learning_rate': 0.01862959827317543, 'n_estimators': 400, 'subsample': 0.6575082204640936, 'colsample_bytree': 0.7726304328309831, 'gamma': 2.7805848283733616, 'min_child_weight': 4, 'reg_lambda': 0.11642072853635184, 'reg_alpha': 0.7690827321225928}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:29:10,130] Trial 92 finished with value: 0.6945476132781367 and parameters: {'max_depth': 4, 'learning_rate': 0.018818995511657603, 'n_estimators': 450, 'subsample': 0.6608704069347044, 'colsample_bytree': 0.7716179066732213, 'gamma': 2.7400983534843597, 'min_child_weight': 4, 'reg_lambda': 0.10256278317793044, 'reg_alpha': 0.7792316758316088}. Best is trial 77 with value: 0.6965854307418836.\n",
      "[I 2024-11-29 20:29:20,821] Trial 93 finished with value: 0.696682386286933 and parameters: {'max_depth': 3, 'learning_rate': 0.014622126761423044, 'n_estimators': 400, 'subsample': 0.6011955245324696, 'colsample_bytree': 0.7577195728994964, 'gamma': 3.008563253857424, 'min_child_weight': 4, 'reg_lambda': 0.07168139363768657, 'reg_alpha': 0.17863019947679695}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:29:29,952] Trial 94 finished with value: 0.6959061770821154 and parameters: {'max_depth': 3, 'learning_rate': 0.014804295413290324, 'n_estimators': 400, 'subsample': 0.6430120691450293, 'colsample_bytree': 0.7838234674019434, 'gamma': 3.010586278041193, 'min_child_weight': 4, 'reg_lambda': 0.11334811088630066, 'reg_alpha': 0.6418896155345735}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:29:40,922] Trial 95 finished with value: 0.6954212016613205 and parameters: {'max_depth': 3, 'learning_rate': 0.01498192432478022, 'n_estimators': 450, 'subsample': 0.6487379894940757, 'colsample_bytree': 0.7862225567442546, 'gamma': 3.0222841331566426, 'min_child_weight': 3, 'reg_lambda': 0.07091924126786546, 'reg_alpha': 0.16635674831971098}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:29:49,972] Trial 96 finished with value: 0.6945476415203579 and parameters: {'max_depth': 3, 'learning_rate': 0.01018681145630711, 'n_estimators': 400, 'subsample': 0.643179140036613, 'colsample_bytree': 0.7292530994584406, 'gamma': 2.2932654685699467, 'min_child_weight': 4, 'reg_lambda': 0.19994090741712237, 'reg_alpha': 0.43001702811029174}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:30:06,886] Trial 97 finished with value: 0.6957119835698053 and parameters: {'max_depth': 3, 'learning_rate': 0.011228903321049232, 'n_estimators': 400, 'subsample': 0.6301881702933464, 'colsample_bytree': 0.7396941643020118, 'gamma': 2.522742602890354, 'min_child_weight': 2, 'reg_lambda': 0.05337886948393523, 'reg_alpha': 0.3175096365752334}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:30:17,820] Trial 98 finished with value: 0.6957119835698055 and parameters: {'max_depth': 3, 'learning_rate': 0.011222454414226242, 'n_estimators': 400, 'subsample': 0.6311812341104781, 'colsample_bytree': 0.7356991149392644, 'gamma': 2.5114552951701645, 'min_child_weight': 2, 'reg_lambda': 0.06602005687491522, 'reg_alpha': 0.33491467240950457}. Best is trial 93 with value: 0.696682386286933.\n",
      "[I 2024-11-29 20:30:26,913] Trial 99 finished with value: 0.6959061488398942 and parameters: {'max_depth': 3, 'learning_rate': 0.011204897271073265, 'n_estimators': 400, 'subsample': 0.6326081440879765, 'colsample_bytree': 0.6916248310881541, 'gamma': 2.5350727464692806, 'min_child_weight': 1, 'reg_lambda': 0.05837948244820471, 'reg_alpha': 0.340196742563206}. Best is trial 93 with value: 0.696682386286933.\n",
      "Number of finished trials:  100\n",
      "Best trial:\n",
      "  Value: 0.696682386286933\n",
      "  Params: \n",
      "    max_depth: 3\n",
      "    learning_rate: 0.014622126761423044\n",
      "    n_estimators: 400\n",
      "    subsample: 0.6011955245324696\n",
      "    colsample_bytree: 0.7577195728994964\n",
      "    gamma: 3.008563253857424\n",
      "    min_child_weight: 4\n",
      "    reg_lambda: 0.07168139363768657\n",
      "    reg_alpha: 0.17863019947679695\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": \"binary:logistic\",  # Adjust based on your problem\n",
    "        \"eval_metric\": \"logloss\",        # You can change this to other metrics\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500, step=50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    \n",
    "    n_splits = 3\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, val_index in skf.split(train_df[features], train_df['winner_index']):\n",
    "        X_train, X_val = train_df.iloc[train_index][features], train_df.iloc[val_index][features]\n",
    "        y_train, y_val = train_df.iloc[train_index]['winner_index'], train_df.iloc[val_index]['winner_index']\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "        )\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        results.append(acc)\n",
    "    \n",
    "    return np.mean(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=3600, show_progress_bar=True)  # Increased trials if feasible\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on test set:  70.2\n"
     ]
    }
   ],
   "source": [
    "# Plucked from the above hyperparameter tuning session.\n",
    "# Doesn't really seem to be getting much better.\n",
    "xgb_tuned = xgb.XGBClassifier(max_depth=13,\n",
    "                              learning_rate=0.013278022811244645,\n",
    "                              n_estimators=500,\n",
    "                              subsample=0.7451791331241274,\n",
    "                              colsample_bytree=0.7785615347277948,\n",
    "                              gamma=2.819394518381603,\n",
    "                              min_child_weight=6,\n",
    "                              reg_lambda=0.41270859938111326,\n",
    "                              reg_alpha=1.9859484482942584,\n",
    "                              eval_metric='logloss')\n",
    "\n",
    "# xgb_tuned = xgb.XGBClassifier(max_depth=3,\n",
    "#                               learning_rate=0.014622126761423044,\n",
    "#                               n_estimators=400,\n",
    "#                               subsample=0.6011955245324696,\n",
    "#                               colsample_bytree=0.7577195728994964,\n",
    "#                               gamma=3.008563253857424,\n",
    "#                               min_child_weight=4,\n",
    "#                               reg_lambda=0.07168139363768657,\n",
    "#                               reg_alpha=0.17863019947679695,\n",
    "#                               eval_metric='logloss')\n",
    "\n",
    "    \n",
    "xgb_tuned.fit(train_df[features], train_df['winner_index'])\n",
    "print(\"Accuracy of XGBoost on test set: \", round(100.0 * accuracy_score(test_df['winner_index'], xgb_tuned.predict(test_df[features])), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set baselines:\n",
      "\n",
      "Highest ELO out of top 8, accuracy:                67.5\n",
      "Highest ELO out of WSF, accuracy:                  70.1\n",
      "Computing all ways top 8 can play out, accuracy:   69.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set baselines:\")\n",
    "print()\n",
    "print(\"Highest ELO out of top 8, accuracy:               \", round(100.0 * (test_df['winner_index'] == test_df['elo_prediction']).astype(float).mean(), 1))\n",
    "print(\"Highest ELO out of WSF, accuracy:                 \", round(100.0 * (test_df['winner_index'] == test_df['elo_WSF_prediction']).astype(float).mean(), 1))\n",
    "print(\"Computing all ways top 8 can play out, accuracy:  \", round(100.0 * (test_df['winner_index'] == test_df['path_prediction']).astype(float).mean(), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no upsets = 3479\n",
      "upsets = 1482\n",
      "\n",
      "Accuracy on no upset 92.56%\n",
      "Accuracy on upset 15.45%\n",
      "\n",
      "The model predicted something different 12.11% of the time.\n",
      "The when the model predicted something different, it was right 38.10% of the time.\n"
     ]
    }
   ],
   "source": [
    "no_upset = test_df[test_df['winner_index'] == test_df['elo_WSF_prediction']]\n",
    "upset = test_df[test_df['winner_index'] != test_df['elo_WSF_prediction']]\n",
    "\n",
    "print(f\"no upsets = {no_upset.shape[0]}\")\n",
    "print(f\"upsets = {upset.shape[0]}\")\n",
    "print()\n",
    "print(f\"Accuracy on no upset {(no_upset['winner_index'] == no_upset['path_prediction']).sum()/no_upset.shape[0]:.2%}\")\n",
    "print(f\"Accuracy on upset {(upset['winner_index'] == upset['path_prediction']).sum()/upset.shape[0]:.2%}\")\n",
    "print()\n",
    "print(f\"The model predicted something different {(test_df['elo_WSF_prediction']!=test_df['path_prediction']).sum()/test_df.shape[0]:.2%} of the time.\")\n",
    "print(f\"The when the model predicted something different, it was right {((test_df['elo_WSF_prediction']!=test_df['path_prediction']) & (test_df['winner_index'] == test_df['path_prediction'])).sum()/(test_df['elo_WSF_prediction']!=test_df['path_prediction']).sum():.2%} of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2987300947389639"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upset.shape[0]/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
