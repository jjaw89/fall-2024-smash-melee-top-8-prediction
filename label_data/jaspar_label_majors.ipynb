{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Label Majors\n",
    "In this notebook we want to:\n",
    "- Label the major tournaments based on https://liquipedia.net/smash/Major_Tournaments/Melee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SQLite Database into Pandas DataFrames\n",
    "\n",
    "The following code connects to an SQLite database (`melee_player_database.db`) and converts each table within the database into a pandas DataFrame. The DataFrames will be stored in a dictionary, where each key corresponds to the table name with `_df` appended, and the values are the respective DataFrames.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Database Connection**: We use the `sqlite3` library to connect to the SQLite database file.\n",
    "2. **Retrieve Table Names**: A query retrieves all the table names in the database.\n",
    "3. **Convert Tables to DataFrames**: For each table:\n",
    "   - The table is loaded into a pandas DataFrame using `pd.read_sql()`.\n",
    "   - We check each column to see if any data is JSON-formatted (lists or dictionaries). If so, we convert these columns from strings into their corresponding Python objects using `json.loads()`.\n",
    "4. **Store DataFrames**: The DataFrames are stored in a dictionary, where the key is the table name with a `_df` suffix, and the value is the DataFrame.\n",
    "5. **Database Connection Closed**: Once all tables are loaded into DataFrames, the database connection is closed.\n",
    "\n",
    "### Example:\n",
    "If the database contains a table named `players`, the corresponding DataFrame will be stored in the dictionary with the key `players_df`, and can be accessed as:\n",
    "\n",
    "```python\n",
    "players_df = dfs['players_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "if os.path.exists(data_path + 'dfs_dict.pkl'):\n",
    "    cell_has_run = True\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    with open(data_path + 'dfs_dict.pkl', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = + data_path + \"melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we adjust the data types of the dataframes so that they are the correct type. (This will be updated as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sets_df']['best_of'] = dfs['sets_df']['best_of'].fillna(0).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the dictionary of DataFrames as a pickle\n",
    "# with open(data_path + 'dfs_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we make dataframes that we will use and print the head.\n",
    "\n",
    "The integers in 'characters' count the number of games the player has played that character. (We verify this for Zain below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs['players_df']\n",
    "players_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = dfs['ranking_df']\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "ranking_seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df = dfs['sets_df']\n",
    "print(f\"{sets_df[sets_df['game_data'].apply(lambda x: len(x) > 0)].shape[0] / sets_df.shape[0]:0.01%} percent of sets have some game data\")\n",
    "sets_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = dfs['tournament_info_df']\n",
    "print(tournament_info_df.shape)\n",
    "print(tournament_info_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df[tournament_info_df['cleaned_name']=='DreamHack Denver 2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copied the information from Liquipedia into a speadsheet and saved it as a CSV which we load as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors_df = pd.read_csv('melee_majors.csv')\n",
    "majors_df = majors_df.iloc[6:]\n",
    "majors_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up the Tournament Names in Your List\n",
    "First, let's clean the tournament names in your list to remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_list = list(majors_df['Tournament'])\n",
    "\n",
    "# Function to remove duplicate phrases\n",
    "def remove_duplicate_phrases(name):\n",
    "    # Split the name into words\n",
    "    words = name.split()\n",
    "    # Use a sliding window to find duplicates\n",
    "    for i in range(1, len(words)):\n",
    "        if words[:i] == words[i:2*i]:\n",
    "            return ' '.join(words[i:])\n",
    "    return name\n",
    "\n",
    "# Clean the tournament names\n",
    "cleaned_tournament_list = [remove_duplicate_phrases(name) for name in tournament_list]\n",
    "\n",
    "print(\"Cleaned Tournament Names:\")\n",
    "for original, cleaned in zip(tournament_list, cleaned_tournament_list):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean tournament names\n",
    "def clean_tournament_name(name):\n",
    "    # Remove special characters, convert to lowercase, remove extra spaces\n",
    "    # if ':' in name:\n",
    "    #     name = name.split(\":\")[0]\n",
    "    # if '-' in name:\n",
    "    #     name = name.split(\"-\")[0]\n",
    "    name = re.sub(r'[^a-zA-Z0-9\\s]', '', name)\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "# Clean the major tournament names\n",
    "major_tournaments_cleaned = [clean_tournament_name(t) for t in cleaned_tournament_list]\n",
    "\n",
    "# Clean the 'cleaned_name' column in your DataFrame\n",
    "tournament_info_df['cleaned_name_cleaned'] = tournament_info_df['cleaned_name'].apply(clean_tournament_name)\n",
    "\n",
    "# Create the 'major' column\n",
    "tournament_info_df['major'] = tournament_info_df['cleaned_name_cleaned'].isin(major_tournaments_cleaned)\n",
    "\n",
    "# Verify the results\n",
    "majors_in_df = tournament_info_df[tournament_info_df['major']]\n",
    "print(\"Number of majors found:\", majors_in_df.shape[0])\n",
    "print(\"Majors found:\")\n",
    "print(majors_in_df['cleaned_name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_majors = [major for major in major_tournaments_cleaned if not tournament_info_df['cleaned_name_cleaned'].isin([major]).any()]\n",
    "\n",
    "print(len(missing_majors))\n",
    "for major in missing_majors:\n",
    "    print(major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df  = tournament_info_df[tournament_info_df['major']==True].copy()\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for missing majors one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = tournament_info_df.copy()\n",
    "# # temp_df = tournament_info_df[tournament_info_df['city']=='Los Vagas']\n",
    "# year = 2015\n",
    "# temp_df = temp_df[temp_df['start']>=datetime(year,1,1)]\n",
    "# temp_df = temp_df[temp_df['start']<datetime(year,12,30)]\n",
    "# # temp_df = temp_df[temp_df['entrants']==16]\n",
    "# # temp_df.sort_values('entrants',inplace=True)\n",
    "# print(temp_df.shape)\n",
    "# temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add missing majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_majors_5=[\n",
    "39443, #Tipped off 15\n",
    "38456, #Get on my level X\n",
    "28389, #riptide 2023\n",
    "26646, #Get on my level 2023\n",
    "26137, # ludwig 2023 main event\n",
    "24918, #Tipped off 14,\n",
    "22595, # back in blood major upset\n",
    "17129,# smash summit 14\n",
    "15764, # lost tech city 2022\n",
    "12948, # double down 2022\n",
    "12779, # get on my level 2022\n",
    "11293, # smash summit 13\n",
    "7532, #smash_world tour\n",
    "6377, #SWT 2021 NA east regional finals\n",
    "5168, #riptide 2021\n",
    "1233, #Galint Melee Open: Spring Edition\n",
    "2, #Slippi Champions League Week 1\n",
    "3,#Slippi Champions League Week 2\n",
    "4,#Slippi Champions League Week 3\n",
    "5,#Slippi Champions League Week 4\n",
    "667, #Get on my line 2020\n",
    "167, #GameTyrant Expo 2018\n",
    "30, #EVO 2018\t\n",
    "41, #Enthusiast Gaming Live Expo 2018\n",
    "51, #GameTyrant Expo 2017\n",
    "# genesis fuse doubles circuit finals\n",
    "58, #EVO 2017\n",
    "#Shine 2016\n",
    "26, #EVO 2016\n",
    "141, # Supe Smash con\n",
    "25, #EVO 2015\n",
    "# WTFox\n",
    "165, #FC Smash 15XR: Return\n",
    "14 #paragon 2015\n",
    "]\n",
    "\n",
    "tournament_info_df.loc[missing_majors_5, 'major'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_tournament_info_df = tournament_info_df[tournament_info_df['major']==True]\n",
    "major_tournament_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove not majors\n",
    "Going through the list on the website and comparing to the majors we found, remove the ones that were miss labelled. That completes the list of majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_actually_majors = [\n",
    "36389,  #battle-of-bc-6-7__lowtier-bracket-melee\n",
    "16526, #ludwig-smash-invitational__melee-singles-lcq\n",
    "]\n",
    "tournament_info_df.loc[not_actually_majors, 'major'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to be missing 2 majors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_tournament_info_df = tournament_info_df[tournament_info_df['major']==True]\n",
    "major_tournament_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_tournament_info_df.to_pickle(data_path + 'major_tournament_info_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
