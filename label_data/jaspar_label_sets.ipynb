{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionl columns to sets_df\n",
    "We already have run jaspar_label_majors.ipynb, jaspar_top_8_tournamen_path.ipynb, and jaspar_top_8.ipynb\n",
    "resulting in \n",
    "- (data_path + 'top_8_tournament_previous_sets_and_results_df') \n",
    "- (data_path + 'sets_top_8_labeled_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split  # Correct import\n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SQLite Database into Pandas DataFrames\n",
    "\n",
    "The following code connects to an SQLite database (`melee_player_database.db`) and converts each table within the database into a pandas DataFrame. The DataFrames will be stored in a dictionary, where each key corresponds to the table name with `_df` appended, and the values are the respective DataFrames.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Database Connection**: We use the `sqlite3` library to connect to the SQLite database file.\n",
    "2. **Retrieve Table Names**: A query retrieves all the table names in the database.\n",
    "3. **Convert Tables to DataFrames**: For each table:\n",
    "   - The table is loaded into a pandas DataFrame using `pd.read_sql()`.\n",
    "   - We check each column to see if any data is JSON-formatted (lists or dictionaries). If so, we convert these columns from strings into their corresponding Python objects using `json.loads()`.\n",
    "4. **Store DataFrames**: The DataFrames are stored in a dictionary, where the key is the table name with a `_df` suffix, and the value is the DataFrame.\n",
    "5. **Database Connection Closed**: Once all tables are loaded into DataFrames, the database connection is closed.\n",
    "\n",
    "### Example:\n",
    "If the database contains a table named `players`, the corresponding DataFrame will be stored in the dictionary with the key `players_df`, and can be accessed as:\n",
    "\n",
    "```python\n",
    "players_df = dfs['players_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "if os.path.exists(data_path + 'dfs_dict.pkl'):\n",
    "    cell_has_run = True\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    with open(data_path + 'dfs_dict.pkl', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = + data_path + \"melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_df = pd.read_pickle(data_path + '/labelled_data/players_df.pkl')\n",
    "# players_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df = pd.read_pickle(data_path + '/sets_top_8_labeled_df.pkl')\n",
    "# sets_df = dfs['sets_df']\n",
    "print(f\"{sets_df[sets_df['game_data'].apply(lambda x: len(x) > 0)].shape[0] / sets_df.shape[0]:0.01%} percent of sets have some game data\")\n",
    "print(sets_df.shape)\n",
    "sets_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = pd.read_pickle(data_path + '/top_8_tournament_previous_sets_and_results_df')\n",
    "print(tournament_info_df.shape)\n",
    "tournament_info_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add loser_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df['loser_id'] = sets_df['p1_id']\n",
    "p2_lose= (sets_df['winner_id'] == sets_df['p1_id'])\n",
    "sets_df.loc[p2_lose, 'loser_id'] = sets_df['p2_id']\n",
    "\n",
    "sets_df = sets_df[['key', 'game', 'tournament_key', 'winner_id', 'loser_id', 'p1_id', 'p2_id',\n",
    "       'p1_score', 'p2_score', 'location_names', 'bracket_name',\n",
    "       'bracket_order', 'set_order', 'best_of', 'game_data', 'top_8',\n",
    "       'top_8_location_names', 'valid_top_8_bracket',\n",
    "       'top_8_bracket_location_names', 'major']]\n",
    "sets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add valid_score column\n",
    "This column will be true if the match was a best of 3 or best of 5 with one player getting the score needed to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Best of 3 sets\n",
    "best_of_3s = sets_df[sets_df['best_of'] == 3]\n",
    "\n",
    "# Valid Best of 3: Player 1 wins\n",
    "best_of_3s_p1_win = best_of_3s[(best_of_3s['p1_score'] == 2) & (best_of_3s['winner_id'] == best_of_3s['p1_id'])]\n",
    "best_of_3s_valid_p1 = best_of_3s_p1_win[best_of_3s_p1_win['p2_score'].isin([0, 1])]\n",
    "\n",
    "# Valid Best of 3: Player 2 wins\n",
    "best_of_3s_p2_win = best_of_3s[(best_of_3s['p2_score'] == 2) & (best_of_3s['winner_id'] == best_of_3s['p2_id'])]\n",
    "best_of_3s_valid_p2 = best_of_3s_p2_win[best_of_3s_p2_win['p1_score'].isin([0, 1])]\n",
    "\n",
    "# Combine valid Best of 3 sets\n",
    "best_of_3s_valid = pd.concat([best_of_3s_valid_p1, best_of_3s_valid_p2])\n",
    "\n",
    "# Filter Best of 5 sets\n",
    "best_of_5s = sets_df[sets_df['best_of'] == 5]\n",
    "\n",
    "# Valid Best of 5: Player 1 wins\n",
    "best_of_5s_p1_win = best_of_5s[(best_of_5s['p1_score'] == 3) & (best_of_5s['winner_id'] == best_of_5s['p1_id'])]\n",
    "best_of_5s_valid_p1 = best_of_5s_p1_win[best_of_5s_p1_win['p2_score'].isin([0, 1, 2])]\n",
    "\n",
    "# Valid Best of 5: Player 2 wins\n",
    "best_of_5s_p2_win = best_of_5s[(best_of_5s['p2_score'] == 3) & (best_of_5s['winner_id'] == best_of_5s['p2_id'])]\n",
    "best_of_5s_valid_p2 = best_of_5s_p2_win[best_of_5s_p2_win['p1_score'].isin([0, 1, 2])]\n",
    "\n",
    "# Combine valid Best of 5 sets\n",
    "best_of_5s_valid = pd.concat([best_of_5s_valid_p1, best_of_5s_valid_p2])\n",
    "\n",
    "# Combine all valid sets and create the 'valid_score' column\n",
    "valid_score_index = pd.concat([best_of_3s_valid, best_of_5s_valid]).index\n",
    "sets_df['valid_score'] = False\n",
    "sets_df.loc[valid_score_index, 'valid_score'] = True\n",
    "\n",
    "sets_df = sets_df[['key', 'game', 'tournament_key', 'winner_id', 'loser_id', 'p1_id',\n",
    "       'p2_id', 'p1_score', 'p2_score', 'valid_score', 'best_of', 'location_names', 'bracket_name',\n",
    "       'bracket_order', 'set_order',  'game_data', 'top_8',\n",
    "       'top_8_location_names', 'valid_top_8_bracket',\n",
    "       'top_8_bracket_location_names', 'major']]\n",
    "\n",
    "print(f\"Sets with a valid score make up {sets_df['valid_score'].sum() / sets_df.shape[0]:.2%} of the dataset.\")\n",
    "print(f\"Best of 3s with a valid score make up {sets_df[sets_df['best_of']==3]['valid_score'].sum() / sets_df.shape[0]:.2%} of the dataset.\")\n",
    "print(f\"Best of 5s with a valid score make up {sets_df[sets_df['best_of']==5]['valid_score'].sum() / sets_df.shape[0]:.2%} of the dataset.\")\n",
    "\n",
    "sets_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo3_results = sets_df[(sets_df['best_of']==3) & (sets_df['valid_score']==True)][['p1_score','p2_score']]\n",
    "bo3_result_ordered_labels = ['(2, 0)', '(2, 1)', '(1, 2)', '(0, 2)']\n",
    "\n",
    "bo5_results = sets_df[(sets_df['best_of']==5) & (sets_df['valid_score']==True)][['p1_score','p2_score']]\n",
    "bo5_result_ordered_labels = ['(3, 0)', '(3, 1)', '(3, 2)', '(2, 3)', '(1, 3)', '(0, 3)']\n",
    "\n",
    "# Calculate counts and percentages for Best of 3\n",
    "bo3_counts = bo3_results.value_counts(subset=['p1_score', 'p2_score']).reindex(\n",
    "    [(2, 0), (2, 1), (1, 2), (0, 2)], fill_value=0\n",
    ")\n",
    "bo3_percentages = (bo3_counts / bo3_counts.sum()) * 100\n",
    "\n",
    "# Calculate counts and percentages for Best of 5\n",
    "bo5_counts = bo5_results.value_counts(subset=['p1_score', 'p2_score']).reindex(\n",
    "    [(3, 0), (3, 1), (3, 2), (2, 3), (1, 3), (0, 3)], fill_value=0\n",
    ")\n",
    "bo5_percentages = (bo5_counts / bo5_counts.sum()) * 100\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot Best of 3 histogram\n",
    "axes[0].bar(bo3_result_ordered_labels, bo3_percentages, color='blue', alpha=0.7)\n",
    "axes[0].set_title('Best of 3 Results')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_xlabel('Results')\n",
    "axes[0].set_ylim(0, 100)\n",
    "for i, pct in enumerate(bo3_percentages):\n",
    "    axes[0].text(i, pct + 1, f'{int(pct)}%', ha='center')\n",
    "\n",
    "# Plot Best of 5 histogram\n",
    "axes[1].bar(bo5_result_ordered_labels, bo5_percentages, color='green', alpha=0.7)\n",
    "axes[1].set_title('Best of 5 Results')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xlabel('Results')\n",
    "axes[1].set_ylim(0, 100)\n",
    "for i, pct in enumerate(bo5_percentages):\n",
    "    axes[1].text(i, pct + 1, f'{int(pct)}%', ha='center')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try some more advanced plots, but they did not quite work. Maybe I'll revisit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo3_results = sets_df[(sets_df['best_of']==3) & (sets_df['valid_score']==True)][['p1_score','p2_score']]\n",
    "bo3_result_ordered_labels = ['(2, 0)', '(2, 1)', '(1, 2)', '(0, 2)']\n",
    "\n",
    "bo5_results = sets_df[(sets_df['best_of']==5) & (sets_df['valid_score']==True)][['p1_score','p2_score']]\n",
    "bo5_result_ordered_labels = ['(3, 0)', '(3, 1)', '(3, 2)', '(2, 3)', '(1, 3)', '(0, 3)']\n",
    "\n",
    "\n",
    "# Calculate counts and percentages for Best of 3\n",
    "bo3_counts = bo3_results.value_counts(subset=['p1_score', 'p2_score']).reindex(\n",
    "    [(2, 0), (2, 1), (1, 2), (0, 2)], fill_value=0\n",
    ")\n",
    "bo3_percentages = (bo3_counts / bo3_counts.sum()) * 100\n",
    "\n",
    "# Calculate aggregate percentages for Player 1 and Player 2 wins in Best of 3\n",
    "bo3_p1_wins_percent = bo3_percentages.loc[(2, 0)] + bo3_percentages.loc[(2, 1)]\n",
    "bo3_p2_wins_percent = bo3_percentages.loc[(1, 2)] + bo3_percentages.loc[(0, 2)]\n",
    "\n",
    "# Calculate counts and percentages for Best of 5\n",
    "bo5_counts = bo5_results.value_counts(subset=['p1_score', 'p2_score']).reindex(\n",
    "    [(3, 0), (3, 1), (3, 2), (2, 3), (1, 3), (0, 3)], fill_value=0\n",
    ")\n",
    "bo5_percentages = (bo5_counts / bo5_counts.sum()) * 100\n",
    "\n",
    "# Calculate aggregate percentages for Player 1 and Player 2 wins in Best of 5\n",
    "bo5_p1_wins_percent = bo5_percentages.loc[(3, 0)] + bo5_percentages.loc[(3, 1)] + bo5_percentages.loc[(3, 2)]\n",
    "bo5_p2_wins_percent = bo5_percentages.loc[(2, 3)] + bo5_percentages.loc[(1, 3)] + bo5_percentages.loc[(0, 3)]\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot Best of 3 histogram with aggregate win bars\n",
    "axes[0].bar(bo3_result_ordered_labels, bo3_percentages, color='blue', alpha=0.7, label='Individual Result')\n",
    "axes[0].bar(\n",
    "    ['(2, 0)', '(2, 1)'],\n",
    "    [bo3_p1_wins_percent, bo3_p1_wins_percent],\n",
    "    color='lightblue',\n",
    "    alpha=0.5,\n",
    "    width=1.8,\n",
    "    align='center',\n",
    "    zorder=0,\n",
    "    label='Player 1 Wins'\n",
    ")\n",
    "axes[0].bar(\n",
    "    ['(1, 2)', '(0, 2)'],\n",
    "    [bo3_p2_wins_percent, bo3_p2_wins_percent],\n",
    "    color='lightcoral',\n",
    "    alpha=0.5,\n",
    "    width=1.8,\n",
    "    align='center',\n",
    "    zorder=0,\n",
    "    label='Player 2 Wins'\n",
    ")\n",
    "axes[0].set_title('Best of 3 Results')\n",
    "axes[0].set_ylabel('Percentage (%)')\n",
    "axes[0].set_xlabel('Results')\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[0].legend(loc=\"upper left\")\n",
    "\n",
    "# Label percentages for aggregate bars in Best of 3\n",
    "axes[0].text(0.5, bo3_p1_wins_percent + 2, f'{int(bo3_p1_wins_percent)}%', ha='center', color='blue')\n",
    "axes[0].text(2.5, bo3_p2_wins_percent + 2, f'{int(bo3_p2_wins_percent)}%', ha='center', color='red')\n",
    "\n",
    "# Label individual percentages in Best of 3\n",
    "for i, pct in enumerate(bo3_percentages):\n",
    "    axes[0].text(i, pct + 1, f'{int(pct)}%', ha='center')\n",
    "\n",
    "# Plot Best of 5 histogram with aggregate win bars\n",
    "axes[1].bar(bo5_result_ordered_labels, bo5_percentages, color='green', alpha=0.7, label='Individual Result')\n",
    "axes[1].bar(\n",
    "    ['(3, 0)', '(3, 1)', '(3, 2)'],\n",
    "    [bo5_p1_wins_percent, bo5_p1_wins_percent, bo5_p1_wins_percent],\n",
    "    color='lightgreen',\n",
    "    alpha=0.5,\n",
    "    width=3.5,\n",
    "    align='center',\n",
    "    zorder=0,\n",
    "    label='Player 1 Wins'\n",
    ")\n",
    "axes[1].bar(\n",
    "    ['(2, 3)', '(1, 3)', '(0, 3)'],\n",
    "    [bo5_p2_wins_percent, bo5_p2_wins_percent, bo5_p2_wins_percent],\n",
    "    color='orange',\n",
    "    alpha=0.5,\n",
    "    width=3.5,\n",
    "    align='center',\n",
    "    zorder=0,\n",
    "    label='Player 2 Wins'\n",
    ")\n",
    "axes[1].set_title('Best of 5 Results')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xlabel('Results')\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].legend(loc=\"upper left\")\n",
    "\n",
    "# Label percentages for aggregate bars in Best of 5\n",
    "axes[1].text(1.5, bo5_p1_wins_percent + 2, f'{int(bo5_p1_wins_percent)}%', ha='center', color='green')\n",
    "axes[1].text(4.5, bo5_p2_wins_percent + 2, f'{int(bo5_p2_wins_percent)}%', ha='center', color='orange')\n",
    "\n",
    "# Label individual percentages in Best of 5\n",
    "for i, pct in enumerate(bo5_percentages):\n",
    "    axes[1].text(i, pct + 1, f'{int(pct)}%', ha='center')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract character data\n",
    "First restrict to sets with game data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_with_game_data_df = sets_df[sets_df['game_data'].apply(lambda x: x != [])].copy()\n",
    "sets_with_game_data_df = sets_with_game_data_df[sets_with_game_data_df['valid_score'] == True]\n",
    "sets_with_game_data_df['length_gamedata'] = sets_with_game_data_df['game_data'].apply(len)\n",
    "sets_with_game_data_df = sets_with_game_data_df[sets_with_game_data_df['length_gamedata'].isin([2,3,4,5])]\n",
    "sets_with_game_data_df.shape\n",
    "print(f\"Sets with game data comprise {sets_with_game_data_df.shape[0]/sets_df.shape[0]:.2%} of the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Updated function to extract character and matchup data as strings\n",
    "def extract_character_data(game_data, p1_id, p2_id):\n",
    "    p1_characters = set()\n",
    "    p2_characters = set()\n",
    "    matchup_strings = []\n",
    "    p1_initial_char = None\n",
    "    p2_initial_char = None\n",
    "    p1_changed = False\n",
    "    p2_changed = False\n",
    "\n",
    "    for game in game_data:\n",
    "        # Extract winner and loser IDs\n",
    "        winner_id = str(game['winner_id'])\n",
    "        loser_id = str(game['loser_id'])\n",
    "\n",
    "        # Extract characters\n",
    "        winner_char = game['winner_char'].split('/')[1] if game['winner_char'] else None\n",
    "        loser_char = game['loser_char'].split('/')[1] if game['loser_char'] else None\n",
    "\n",
    "        # Skip if either character is missing\n",
    "        if not winner_char or not loser_char:\n",
    "            continue\n",
    "\n",
    "        # Track unique characters for Player 1\n",
    "        if winner_id == p1_id:\n",
    "            p1_characters.add(winner_char)\n",
    "            if p1_initial_char is None:\n",
    "                p1_initial_char = winner_char\n",
    "            elif winner_char != p1_initial_char:\n",
    "                p1_changed = True\n",
    "        elif loser_id == p1_id:\n",
    "            p1_characters.add(loser_char)\n",
    "            if p1_initial_char is None:\n",
    "                p1_initial_char = loser_char\n",
    "            elif loser_char != p1_initial_char:\n",
    "                p1_changed = True\n",
    "\n",
    "        # Track unique characters for Player 2\n",
    "        if winner_id == p2_id:\n",
    "            p2_characters.add(winner_char)\n",
    "            if p2_initial_char is None:\n",
    "                p2_initial_char = winner_char\n",
    "            elif winner_char != p2_initial_char:\n",
    "                p2_changed = True\n",
    "        elif loser_id == p2_id:\n",
    "            p2_characters.add(loser_char)\n",
    "            if p2_initial_char is None:\n",
    "                p2_initial_char = loser_char\n",
    "            elif loser_char != p2_initial_char:\n",
    "                p2_changed = True\n",
    "\n",
    "        # Create matchup string\n",
    "        p1_char = winner_char if winner_id == p1_id else loser_char\n",
    "        p2_char = winner_char if winner_id == p2_id else loser_char\n",
    "        winner = '0' if winner_id == p1_id else '1'\n",
    "        matchup_strings.append(f\"{p1_char}/{p2_char}/{winner}\")\n",
    "\n",
    "    return (\n",
    "        sorted(p1_characters),  # Unique characters played by Player 1\n",
    "        sorted(p2_characters),  # Unique characters played by Player 2\n",
    "        p1_changed,             # True if Player 1 changed characters\n",
    "        p2_changed,             # True if Player 2 changed characters\n",
    "        matchup_strings         # List of matchup strings\n",
    "    )\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "sets_with_game_data_df[['p1_characters', 'p2_characters', 'p1_changed', 'p2_changed', 'matchup_strings']] = sets_with_game_data_df.progress_apply(\n",
    "    lambda row: pd.Series(extract_character_data(row['game_data'], str(row['p1_id']), str(row['p2_id']))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Add columns to indicate if players did not change characters\n",
    "sets_with_game_data_df['p1_consistent'] = ~sets_with_game_data_df['p1_changed']\n",
    "sets_with_game_data_df['p2_consistent'] = ~sets_with_game_data_df['p2_changed']\n",
    "\n",
    "# Display the structure of the updated DataFrame\n",
    "sets_with_game_data_df[['p1_characters', 'p2_characters', 'p1_consistent', 'p2_consistent', 'matchup_strings']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Combine all matchup strings into a single list\n",
    "# all_matchup_strings = [matchup for matchup_list in sets_with_game_data_df['matchup_strings'] for matchup in matchup_list]\n",
    "\n",
    "# # Count occurrences of each matchup string\n",
    "# matchup_string_counts = Counter(all_matchup_strings)\n",
    "\n",
    "# # Convert the results to a DataFrame for analysis\n",
    "# matchup_string_df = pd.DataFrame.from_records(\n",
    "#     list(matchup_string_counts.items()),  # Convert dict_items to a list\n",
    "#     columns=['matchup_string', 'count']\n",
    "# )\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(matchup_string_df)\n",
    "\n",
    "# # Optional: Visualize the top 10 matchups by count\n",
    "# top_matchups = matchup_string_df.sort_values('count', ascending=False).head(10)\n",
    "# top_matchups.plot(\n",
    "#     x='matchup_string', y='count', kind='bar', figsize=(12, 6), legend=False\n",
    "# )\n",
    "# plt.title('Top 10 Matchup Strings')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xlabel('Matchup String')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all matchup strings into a single list\n",
    "all_matchup_strings = [matchup for matchup_list in sets_with_game_data_df['matchup_strings'] for matchup in matchup_list]\n",
    "\n",
    "# Count occurrences of each matchup string\n",
    "matchup_string_counts = Counter(all_matchup_strings)\n",
    "\n",
    "# Prepare data for heatmaps\n",
    "matchup_data = []\n",
    "for matchup, count in matchup_string_counts.items():\n",
    "    p1_char, p2_char, winner = matchup.split('/')\n",
    "    p1_wins = int(winner == '0') * count  # Count wins for Player 1\n",
    "    p2_wins = int(winner == '1') * count  # Count wins for Player 2\n",
    "    matchup_data.append((p1_char, p2_char, count, p1_wins, p2_wins))\n",
    "\n",
    "# Convert to DataFrame\n",
    "matchup_df = pd.DataFrame(matchup_data, columns=['p1_char', 'p2_char', 'count', 'p1_wins', 'p2_wins'])\n",
    "\n",
    "# Group by characters to calculate total counts and win rates\n",
    "grouped = matchup_df.groupby(['p1_char', 'p2_char']).agg(\n",
    "    total_sets=('count', 'sum'),\n",
    "    p1_wins=('p1_wins', 'sum'),\n",
    "    p2_wins=('p2_wins', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate win rate for Player 1\n",
    "grouped['p1_win_rate'] = grouped['p1_wins'] / grouped['total_sets'] * 100\n",
    "\n",
    "# Pivot tables for heatmaps\n",
    "heatmap_data_counts = grouped.pivot(index='p1_char', columns='p2_char', values='total_sets').fillna(0)\n",
    "heatmap_data_win_rate = grouped.pivot(index='p1_char', columns='p2_char', values='p1_win_rate').fillna(0)\n",
    "\n",
    "# Order characters by frequency\n",
    "char_order = heatmap_data_counts.sum(axis=1).sort_values(ascending=False).index\n",
    "heatmap_data_counts = heatmap_data_counts.loc[char_order, char_order]\n",
    "heatmap_data_win_rate = heatmap_data_win_rate.loc[char_order, char_order]\n",
    "\n",
    "# Plot first heatmap (counts)\n",
    "plt.figure(figsize=(20, 15), dpi=150)\n",
    "sns.heatmap(heatmap_data_counts, annot=True, fmt='.0f', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "plt.title('Counts of Sets by Character Matchup')\n",
    "plt.ylabel('Player 1 Character')\n",
    "plt.xlabel('Player 2 Character')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot second heatmap (win percentage)\n",
    "plt.figure(figsize=(20, 15), dpi=150)\n",
    "# Set midpoint for 50% winrate\n",
    "norm = TwoSlopeNorm(vmin=0, vcenter=50, vmax=100)\n",
    "sns.heatmap(\n",
    "    heatmap_data_win_rate, \n",
    "    annot=True, \n",
    "    fmt='.1f', \n",
    "    cmap='coolwarm', \n",
    "    norm=norm, \n",
    "    cbar_kws={'label': 'Win %'}\n",
    ")\n",
    "plt.title('Player 1 Win Percentage by Character Matchup')\n",
    "plt.ylabel('Player 1 Character')\n",
    "plt.xlabel('Player 2 Character')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from collections import Counter\n",
    "\n",
    "# Combine all matchup strings into a single list\n",
    "all_matchup_strings = [matchup for matchup_list in sets_with_game_data_df['matchup_strings'] for matchup in matchup_list]\n",
    "\n",
    "# Count occurrences of each matchup string\n",
    "matchup_string_counts = Counter(all_matchup_strings)\n",
    "\n",
    "# Prepare data for heatmaps\n",
    "matchup_data = []\n",
    "for matchup, count in matchup_string_counts.items():\n",
    "    p1_char, p2_char, winner = matchup.split('/')\n",
    "    p1_wins = int(winner == '0') * count  # Count wins for Player 1\n",
    "    p2_wins = int(winner == '1') * count  # Count wins for Player 2\n",
    "    matchup_data.append((p1_char, p2_char, count, p1_wins, p2_wins))\n",
    "\n",
    "# Convert to DataFrame\n",
    "matchup_df = pd.DataFrame(matchup_data, columns=['p1_char', 'p2_char', 'count', 'p1_wins', 'p2_wins'])\n",
    "\n",
    "# Group by characters to calculate total counts and win rates\n",
    "grouped = matchup_df.groupby(['p1_char', 'p2_char']).agg(\n",
    "    total_sets=('count', 'sum'),\n",
    "    p1_wins=('p1_wins', 'sum'),\n",
    "    p2_wins=('p2_wins', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate win rate for Player 1\n",
    "grouped['p1_win_rate'] = grouped['p1_wins'] / grouped['total_sets'] * 100\n",
    "\n",
    "# Pivot tables for heatmaps\n",
    "heatmap_data_counts = grouped.pivot(index='p1_char', columns='p2_char', values='total_sets').fillna(0)\n",
    "heatmap_data_win_rate = grouped.pivot(index='p1_char', columns='p2_char', values='p1_win_rate').fillna(0)\n",
    "heatmap_data_win_rate = heatmap_data_win_rate - heatmap_data_win_rate.T\n",
    "# Order characters by frequency\n",
    "char_order = heatmap_data_counts.sum(axis=1).sort_values(ascending=False).index\n",
    "heatmap_data_counts = heatmap_data_counts.loc[char_order, char_order]\n",
    "heatmap_data_win_rate = heatmap_data_win_rate.loc[char_order, char_order]\n",
    "\n",
    "# # Plot first heatmap (counts)\n",
    "# plt.figure(figsize=(20, 15), dpi=150)\n",
    "# sns.heatmap(heatmap_data_counts, annot=True, fmt='.0f', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "# plt.title('Counts of Sets by Character Matchup')\n",
    "# plt.ylabel('Player 1 Character')\n",
    "# plt.xlabel('Player 2 Character')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Plot second heatmap (win percentage)\n",
    "plt.figure(figsize=(20, 15), dpi=150)\n",
    "# Set midpoint for 50% winrate\n",
    "norm = TwoSlopeNorm(vmin=-50, vcenter=0, vmax=50)\n",
    "sns.heatmap(\n",
    "    heatmap_data_win_rate, \n",
    "    annot=True, \n",
    "    fmt='.1f', \n",
    "    cmap='coolwarm', \n",
    "    norm=norm, \n",
    "    cbar_kws={'label': 'Win %'}\n",
    ")\n",
    "plt.title('Win Rate Asymmetry Between Player 1 and Player 2 Matchups')\n",
    "plt.ylabel('Player 1 Character')\n",
    "plt.xlabel('Player 2 Character')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the specified columns to sets_df with default values\n",
    "for col in ['p1_characters', 'p2_characters', 'p1_consistent', 'p2_consistent', 'matchup_strings']:\n",
    "    sets_df[col] = None  # Default value is None; you can replace with np.nan if needed\n",
    "\n",
    "# Update values in sets_df for sets present in sets_with_game_data_df\n",
    "sets_df.update(sets_with_game_data_df[['p1_characters', 'p2_characters', 'p1_consistent', 'p2_consistent', 'matchup_strings']])\n",
    "\n",
    "# Display the updated sets_df to verify\n",
    "sets_df[['p1_characters', 'p2_characters', 'p1_consistent', 'p2_consistent', 'matchup_strings']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
