{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Trials For Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPU is detected.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import datetime\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n",
    "    \n",
    "if torch.cuda.is_available() == False:\n",
    "    RuntimeError(\"GPU detected: False\")\n",
    "    print(\"GPU detected: False\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"The GPU is detected.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "We make a basic NN for binary classification that takes as input a list of integers that correspond to the out_features of each linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, out_features, input_dropout=.2, hidden_dropout=.3):\n",
    "        \"\"\"Initializes the model layers.\n",
    "\n",
    "        Args:\n",
    "            in_features (int): The number of input features of the dataset.\n",
    "            out_features (list): The number of units in each linear layer.\n",
    "        \"\"\"\n",
    "        # Call the parent class (nn.Module) initializer first\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        # Input dropout layer\n",
    "        layers.append(nn.Dropout(input_dropout))\n",
    "    \n",
    "        # Build layers dynamically\n",
    "        for out_feature in out_features:\n",
    "            layers.append(nn.Linear(in_features, out_feature))\n",
    "            layers.append(nn.BatchNorm1d(out_feature))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(hidden_dropout))\n",
    "            in_features = out_feature\n",
    "        \n",
    "        # Final output layer for binary classification (with 1 output node)\n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        \n",
    "        # Store the sequence of layers\n",
    "        self.sequential = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        return self.sequential(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "We create the dataset we are going to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_x</th>\n",
       "      <th>game</th>\n",
       "      <th>tournament_key</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p2_id</th>\n",
       "      <th>p1_score</th>\n",
       "      <th>p2_score</th>\n",
       "      <th>location_names</th>\n",
       "      <th>bracket_name</th>\n",
       "      <th>...</th>\n",
       "      <th>start</th>\n",
       "      <th>p1_rating</th>\n",
       "      <th>p2_rating</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>top_8</th>\n",
       "      <th>rating_difference</th>\n",
       "      <th>higher_rated_won</th>\n",
       "      <th>more_updates_won</th>\n",
       "      <th>p1_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>90101028</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Fija</td>\n",
       "      <td>Fija</td>\n",
       "      <td>Sasha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1667.529088</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>167.529088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>90101030</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Empty Spirits</td>\n",
       "      <td>Bird</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1622.33761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>122.337610</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>90101031</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Stitchface</td>\n",
       "      <td>3551</td>\n",
       "      <td>Stitchface</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1523.497940</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.497940</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>90101033</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>rodohk</td>\n",
       "      <td>phlops</td>\n",
       "      <td>rodohk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1252.681917</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>247.318083</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>90101038</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Psythr</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1400.124736</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>99.875264</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_x   game tournament_key   winner_id          p1_id       p2_id  \\\n",
       "45  90101028  melee          s@sh7        Fija           Fija       Sasha   \n",
       "47  90101030  melee          s@sh7        Bird  Empty Spirits        Bird   \n",
       "48  90101031  melee          s@sh7  Stitchface           3551  Stitchface   \n",
       "50  90101033  melee          s@sh7      rodohk         phlops      rodohk   \n",
       "55  90101038  melee          s@sh7       Sorry         Psythr       Sorry   \n",
       "\n",
       "    p1_score  p2_score                    location_names bracket_name  ...  \\\n",
       "45         1         0  [W1, Winners 1, Winners Round 1]               ...   \n",
       "47         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "48         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "50         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "55         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "\n",
       "                 start    p1_rating   p2_rating p1_updates p2_updates  top_8  \\\n",
       "45 2017-06-13 10:27:01  1667.529088  1500.00000        1.0        0.0  False   \n",
       "47 2017-06-13 10:27:01  1500.000000  1622.33761        0.0        2.0  False   \n",
       "48 2017-06-13 10:27:01  1523.497940  1500.00000        3.0        0.0  False   \n",
       "50 2017-06-13 10:27:01  1252.681917  1500.00000        1.0        0.0  False   \n",
       "55 2017-06-13 10:27:01  1400.124736  1500.00000        1.0        0.0  False   \n",
       "\n",
       "    rating_difference  higher_rated_won  more_updates_won  p1_won  \n",
       "45         167.529088              True              True    True  \n",
       "47         122.337610              True              True   False  \n",
       "48          23.497940             False             False   False  \n",
       "50         247.318083              True             False   False  \n",
       "55          99.875264              True             False   False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + 'tournament_sets_with_top_8_df.pkl')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.657512e+06\n",
       "mean     2.326724e+02\n",
       "std      1.907185e+02\n",
       "min      1.000414e+00\n",
       "25%      8.711195e+01\n",
       "50%      1.864828e+02\n",
       "75%      3.289625e+02\n",
       "max      1.953188e+03\n",
       "Name: rating_difference, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating_difference'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1412738, 25)\n",
      "Index(['key_x', 'game', 'tournament_key', 'winner_id', 'p1_id', 'p2_id',\n",
      "       'p1_score', 'p2_score', 'location_names', 'bracket_name',\n",
      "       'bracket_order', 'set_order', 'best_of', 'game_data', 'key_y', 'start',\n",
      "       'p1_rating', 'p2_rating', 'p1_updates', 'p2_updates', 'top_8',\n",
      "       'rating_difference', 'higher_rated_won', 'more_updates_won', 'p1_won'],\n",
      "      dtype='object')\n",
      "       key_x   game tournament_key   winner_id          p1_id       p2_id  \\\n",
      "45  90101028  melee          s@sh7        Fija           Fija       Sasha   \n",
      "47  90101030  melee          s@sh7        Bird  Empty Spirits        Bird   \n",
      "48  90101031  melee          s@sh7  Stitchface           3551  Stitchface   \n",
      "50  90101033  melee          s@sh7      rodohk         phlops      rodohk   \n",
      "55  90101038  melee          s@sh7       Sorry         Psythr       Sorry   \n",
      "\n",
      "    p1_score  p2_score                    location_names bracket_name  ...  \\\n",
      "45         1         0  [W1, Winners 1, Winners Round 1]               ...   \n",
      "47         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "48         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "50         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "55         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "\n",
      "                 start    p1_rating   p2_rating p1_updates p2_updates  top_8  \\\n",
      "45 2017-06-13 10:27:01  1667.529088  1500.00000        1.0        0.0  False   \n",
      "47 2017-06-13 10:27:01  1500.000000  1622.33761        0.0        2.0  False   \n",
      "48 2017-06-13 10:27:01  1523.497940  1500.00000        3.0        0.0  False   \n",
      "50 2017-06-13 10:27:01  1252.681917  1500.00000        1.0        0.0  False   \n",
      "55 2017-06-13 10:27:01  1400.124736  1500.00000        1.0        0.0  False   \n",
      "\n",
      "    rating_difference  higher_rated_won  more_updates_won  p1_won  \n",
      "45         167.529088              True              True    True  \n",
      "47         122.337610              True              True   False  \n",
      "48          23.497940             False             False   False  \n",
      "50         247.318083              True             False   False  \n",
      "55          99.875264              True             False   False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(1412738, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_rating</th>\n",
       "      <th>p2_rating</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1667.529088</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1622.33761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1523.497940</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1252.681917</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1400.124736</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p1_rating   p2_rating  p1_updates  p2_updates\n",
       "45  1667.529088  1500.00000         1.0         0.0\n",
       "47  1500.000000  1622.33761         0.0         2.0\n",
       "48  1523.497940  1500.00000         3.0         0.0\n",
       "50  1252.681917  1500.00000         1.0         0.0\n",
       "55  1400.124736  1500.00000         1.0         0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['top_8'] == False]\n",
    "# df = df[df['rating_difference'] > 1]\n",
    "# df = df[df['rating_difference'] < 10]\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "features = ['p1_rating', 'p2_rating', 'p1_updates', 'p2_updates']\n",
    "# features = ['p1_updates', 'p2_updates']\n",
    "# features = ['p1_rating', 'p2_rating']\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# # features = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "X = df[features].astype(float).values  # Convert to numpy array\n",
    "y = df['p1_won'].astype(float).values  # Convert to numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=103)\n",
    "\n",
    "# # Convert the splits to PyTorch tensors and reshape y to be 2D\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 12:53:27,378] A new study created in memory with name: no-name-e2d851ca-4d41-455c-a2fa-59a3510b72da\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfa4135912a47e8a4254e9741cbd627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 12:53:30,598] Trial 0 finished with value: 0.7817857496779308 and parameters: {'eta': 0.16561955172465323, 'max_depth': 9, 'subsample': 0.6518281976063982, 'colsample_bytree': 0.8608520075606874, 'lambda': 1.3614759051104233, 'alpha': 2.6362623910635756}. Best is trial 0 with value: 0.7817857496779308.\n",
      "[I 2024-10-25 12:53:49,763] Trial 1 finished with value: 0.7830551505112996 and parameters: {'eta': 0.08285493986590198, 'max_depth': 4, 'subsample': 0.6965593327786426, 'colsample_bytree': 0.5068150167688776, 'lambda': 0.02399128660824026, 'alpha': 0.05589972133905354}. Best is trial 1 with value: 0.7830551505112996.\n",
      "[I 2024-10-25 12:54:19,923] Trial 2 finished with value: 0.7827295421190972 and parameters: {'eta': 0.014670356937623407, 'max_depth': 7, 'subsample': 0.546457739821126, 'colsample_bytree': 0.7038554717476486, 'lambda': 0.005173976178914417, 'alpha': 0.004646786274592077}. Best is trial 1 with value: 0.7830551505112996.\n",
      "[I 2024-10-25 12:54:46,995] Trial 3 finished with value: 0.7830268367380646 and parameters: {'eta': 0.05041441794726773, 'max_depth': 3, 'subsample': 0.838913468619561, 'colsample_bytree': 0.6407145532956018, 'lambda': 0.010188413776326073, 'alpha': 0.013119169784862071}. Best is trial 1 with value: 0.7830551505112996.\n",
      "[I 2024-10-25 12:55:15,437] Trial 4 finished with value: 0.7832439089995328 and parameters: {'eta': 0.013443857090497368, 'max_depth': 5, 'subsample': 0.8649564036573447, 'colsample_bytree': 0.9222998394946262, 'lambda': 0.007164934864523536, 'alpha': 1.392942915133237}. Best is trial 4 with value: 0.7832439089995328.\n",
      "Best trial:\n",
      "  Accuracy: 0.7832439089995328\n",
      "  Best hyperparameters:  {'eta': 0.013443857090497368, 'max_depth': 5, 'subsample': 0.8649564036573447, 'colsample_bytree': 0.9222998394946262, 'lambda': 0.007164934864523536, 'alpha': 1.392942915133237}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters using the new `suggest_float` method\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3, log=True),  # learning rate\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),        # max depth of trees\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), # subsample ratio\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # colsample by tree\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),  # L2 regularization\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),    # L1 regularization\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Train the model\n",
    "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    model = xgb.train(params, dtrain, num_boost_round=1000, evals=evallist, early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(dval)\n",
    "    y_val_pred_binary = [1 if p > 0.5 else 0 for p in y_val_pred]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=5, show_progress_bar=True)  # You can set n_trials higher for more iterations\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Accuracy: {trial.value}')\n",
    "print('  Best hyperparameters: ', trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=8, num_workers=16):\n",
    "    # Convert datasets to TensorDataset (pairs features and labels)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    # Create DataLoader objects for train, test, and validation datasets\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "    }\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Functions\n",
    "Here we have basic train and test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_progress(model, loaders, criterion, optimizer, num_epochs, epoch, device):\n",
    "    model.train()\n",
    "    \n",
    "    # Use tqdm to display progress bar for the training loop\n",
    "    leave = True\n",
    "    train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch', leave=leave)\n",
    "    \n",
    "    # Our training dataset is has well over a million examples.\n",
    "    # We expect the loss to change a lot over a single epoch,\n",
    "    # so we only show the loss of the 10_000 most recent batches.\n",
    "    running_loss = deque(maxlen=10000)\n",
    "    \n",
    "    # Train epoch\n",
    "    for X_train, y_train in train_loader_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_train_gpu = X_train.to(device)\n",
    "        y_train_gpu = y_train.to(device)\n",
    "        \n",
    "        output_gpu = model(X_train_gpu)\n",
    "        \n",
    "        loss = criterion(output_gpu, y_train_gpu)\n",
    "        running_loss.append(loss.item())  # Store loss for averaging\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate and set the average loss for the tqdm progress bar\n",
    "        avg_loss = sum(running_loss) / len(running_loss) if len(running_loss) > 0 else 0\n",
    "        \n",
    "        train_loader_tqdm.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "    return\n",
    "\n",
    "def test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='test'):\n",
    "    # Validate epoch:\n",
    "    model.eval()\n",
    "    leave = True\n",
    "    test_loader_tqdm = tqdm(loaders[loader], desc=f'Test {epoch+1}/{num_epochs}', unit='batch', leave=leave)\n",
    "    test_loss = []\n",
    "    num_tested = []\n",
    "    correct_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader_tqdm:\n",
    "            X_test_gpu = X_test.to(device)\n",
    "            y_test_gpu = y_test.to(device)\n",
    "            \n",
    "            output_gpu = model(X_test_gpu)\n",
    "            \n",
    "            # Accumulate test loss\n",
    "            test_loss.append(criterion(output_gpu, y_test_gpu).item() * X_test.shape[0])\n",
    "            num_tested.append(X_test.shape[0])\n",
    "            \n",
    "            # Calculate number of correct predictions for binary classification\n",
    "            correct_pred += torch.sum(((nn.Sigmoid()(output_gpu) > 0.5) == y_test_gpu).float()).item()\n",
    "            \n",
    "            test_loader_tqdm.set_postfix(loss=f\"{sum(test_loss) / sum(num_tested):.4f}\", acc=f\"{correct_pred / sum(num_tested):.1%}\")\n",
    "        \n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = sum(test_loss) / sum(num_tested)\n",
    "        accuracy = correct_pred / sum(num_tested)\n",
    "        \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the same train and test functions as above, but without the progress bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loaders, criterion, optimizer, num_epochs, epoch, device):\n",
    "    model.train()\n",
    "    \n",
    "    # Train epoch\n",
    "    for X_train, y_train in loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_train_gpu = X_train.to(device)\n",
    "        y_train_gpu = y_train.to(device)\n",
    "        \n",
    "        output_gpu = model(X_train_gpu)\n",
    "        \n",
    "        loss = criterion(output_gpu, y_train_gpu)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return \n",
    "\n",
    "def test_model(model, loaders, criterion, device, num_epochs, epoch, loader='test'):\n",
    "    # Validate epoch:\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    num_tested = []\n",
    "    correct_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in loaders[loader]:\n",
    "            X_test_gpu = X_test.to(device)\n",
    "            y_test_gpu = y_test.to(device)\n",
    "            \n",
    "            output_gpu = model(X_test_gpu)\n",
    "            \n",
    "            # Accumulate test loss.\n",
    "            test_loss.append(criterion(output_gpu, y_test_gpu).item() * X_test.shape[0])\n",
    "            num_tested.append(X_test.shape[0])\n",
    "            \n",
    "            # Calculate number of correct predictions for binary classification.\n",
    "            correct_pred += torch.sum(((nn.Sigmoid()(output_gpu) > 0.5) == y_test_gpu).float()).item()\n",
    "        \n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = sum(test_loss) / sum(num_tested)\n",
    "        accuracy = correct_pred / sum(num_tested)\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Study\n",
    "We create a simple optuna study to find a good model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, num_layers, min_out, max_out, in_features, loaders, study_name):\n",
    "    input_dropout = 0\n",
    "    hidden_dropout = .2\n",
    "    # input_dropout = trial.suggest_float(\"input_dropout\", 0, .9)\n",
    "    hidden_dropout = trial.suggest_float(\"hidden_dropout\", 0, .9)\n",
    "    \n",
    "    # Generate the output features for each layer using trial suggestions\n",
    "    out_features = []\n",
    "    for i in range(num_layers):\n",
    "        out_features.append(trial.suggest_int(f\"out_features_layer_{i}\", min_out, max_out))\n",
    "    \n",
    "    # Create model and move to device\n",
    "    model = Model(in_features, out_features, input_dropout, hidden_dropout).to(device)\n",
    "    \n",
    "    # Compile the model (not always worth it)\n",
    "    # model.compile()\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    num_epochs = 1\n",
    "    \n",
    "    # Training loop for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch(model, loaders, criterion, optimizer, num_epochs, epoch, device)\n",
    "    \n",
    "    test_loss, test_accuracy = test_model(model, loaders, criterion, device, num_epochs, epoch, loader='test')\n",
    "    print(f\"Accuracy = {test_accuracy:.1%}\")\n",
    "    ## Print results if we want \n",
    "    # print(f\"Loss={test_loss:0.5f}, Accuracy={test_accuracy:0.1%}\")\n",
    "    \n",
    "    # Return the test loss to be minimized\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 12:55:39,420] A new study created in memory with name: Baseline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eda0df9dbf5445097408d4a0cd62c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 76.9%\n",
      "[I 2024-10-25 12:56:33,341] Trial 0 finished with value: 0.484858636805921 and parameters: {'hidden_dropout': 0.4551257720910502, 'out_features_layer_0': 733}. Best is trial 0 with value: 0.484858636805921.\n",
      "Accuracy = 77.0%\n",
      "[I 2024-10-25 12:57:26,383] Trial 1 finished with value: 0.4842496221967782 and parameters: {'hidden_dropout': 0.15102174464731258, 'out_features_layer_0': 1822}. Best is trial 1 with value: 0.4842496221967782.\n",
      "Accuracy = 76.9%\n",
      "[I 2024-10-25 12:58:19,744] Trial 2 finished with value: 0.48603013375443804 and parameters: {'hidden_dropout': 0.7494735926768032, 'out_features_layer_0': 1113}. Best is trial 1 with value: 0.4842496221967782.\n",
      "Accuracy = 76.9%\n",
      "[I 2024-10-25 12:59:12,676] Trial 3 finished with value: 0.48374388928600254 and parameters: {'hidden_dropout': 0.40419362176543794, 'out_features_layer_0': 1374}. Best is trial 3 with value: 0.48374388928600254.\n",
      "Accuracy = 76.9%\n",
      "[I 2024-10-25 13:00:06,546] Trial 4 finished with value: 0.4851260386594146 and parameters: {'hidden_dropout': 0.6433681536400809, 'out_features_layer_0': 1041}. Best is trial 3 with value: 0.48374388928600254.\n",
      "Accuracy = 77.2%\n",
      "[I 2024-10-25 13:01:01,686] Trial 5 finished with value: 0.4808905005693544 and parameters: {'hidden_dropout': 0.18511156956697336, 'out_features_layer_0': 1882}. Best is trial 5 with value: 0.4808905005693544.\n",
      "Accuracy = 77.1%\n",
      "[I 2024-10-25 13:01:54,894] Trial 6 finished with value: 0.48422755252505784 and parameters: {'hidden_dropout': 0.5360097037558642, 'out_features_layer_0': 1975}. Best is trial 5 with value: 0.4808905005693544.\n",
      "Accuracy = 77.1%\n",
      "[I 2024-10-25 13:02:46,190] Trial 7 finished with value: 0.48233249211614676 and parameters: {'hidden_dropout': 0.3465491964835481, 'out_features_layer_0': 1699}. Best is trial 5 with value: 0.4808905005693544.\n",
      "Accuracy = 77.1%\n",
      "[I 2024-10-25 13:03:37,955] Trial 8 finished with value: 0.48531305136924713 and parameters: {'hidden_dropout': 0.7003646760279224, 'out_features_layer_0': 1932}. Best is trial 5 with value: 0.4808905005693544.\n",
      "Accuracy = 77.4%\n",
      "[I 2024-10-25 13:04:28,551] Trial 9 finished with value: 0.4809337888982983 and parameters: {'hidden_dropout': 0.15652939435492338, 'out_features_layer_0': 2023}. Best is trial 5 with value: 0.4808905005693544.\n",
      "\n",
      "Best parameters: {'hidden_dropout': 0.18511156956697336, 'out_features_layer_0': 1882}\n",
      "Best trial: FrozenTrial(number=5, state=TrialState.COMPLETE, values=[0.4808905005693544], datetime_start=datetime.datetime(2024, 10, 25, 13, 0, 6, 547493), datetime_complete=datetime.datetime(2024, 10, 25, 13, 1, 1, 685982), params={'hidden_dropout': 0.18511156956697336, 'out_features_layer_0': 1882}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'hidden_dropout': FloatDistribution(high=0.9, log=False, low=0.0, step=None), 'out_features_layer_0': IntDistribution(high=2048, log=False, low=16, step=1)}, trial_id=5, value=None)\n"
     ]
    }
   ],
   "source": [
    "loaders = prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=16, num_workers=1)\n",
    "\n",
    "# Define the parameters for the study\n",
    "study_name = \"Baseline\"\n",
    "num_layers = 1\n",
    "min_out = 16\n",
    "max_out = 1024 * 2\n",
    "in_features = X_train.shape[1]\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(study_name=study_name, direction='minimize')\n",
    "\n",
    "# Define the objective function and run the optimization\n",
    "study.optimize(lambda trial: objective(trial, num_layers, min_out, max_out, in_features, loaders, study_name), \n",
    "               n_trials=10, show_progress_bar=True)  # You can specify how many trials you want\n",
    "\n",
    "# Print the best parameters found by the study\n",
    "print()\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best trial: {study.best_trial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get parameters of the best study\u001b[39;00m\n\u001b[1;32m      2\u001b[0m out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Adjust indexing as needed\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m input_dropout \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_dropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m   \u001b[38;5;66;03m# Example key name\u001b[39;00m\n\u001b[1;32m      4\u001b[0m hidden_dropout \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dropout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# Example key name\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_dropout'"
     ]
    }
   ],
   "source": [
    "# Get parameters of the best study\n",
    "out_features = list(study.best_params.values())[2:]  # Adjust indexing as needed\n",
    "input_dropout = study.best_params['input_dropout']   # Example key name\n",
    "hidden_dropout = study.best_params['hidden_dropout'] # Example key name\n",
    "\n",
    "# Build the model\n",
    "model = Model(in_features, out_features, input_dropout, hidden_dropout)\n",
    "# model = Model(X.shape[1], [128, 64, 32], 0, .25)\n",
    "# model = Model(X.shape[1], [64, 32, 16], 0, .25)\n",
    "# model = Model(X.shape[1], [64, 16], 0, .25)\n",
    "# model = Model(X.shape[1], [128*4], 0, .5)\n",
    "# model = Model(X.shape[1], [128*8], 0, .75)\n",
    "\n",
    "loaders = prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=8, num_workers=1)\n",
    "\n",
    "## Compiling might not be worth it (Cannot save the model if we do.)\n",
    "# model = torch.compile(model)#, mode = 'max-autotune')\n",
    "\n",
    "# Move model to the GPU\n",
    "model.to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 1\n",
    "# Training loop for num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    train_epoch_progress(model, loaders, criterion, optimizer, num_epochs, epoch, device)\n",
    "    test_loss, test_accuracy = test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='test')\n",
    "\n",
    "test_loss, test_accuracy = test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='val')\n",
    "print(f\"Val: Loss={test_loss:0.5f}, Accuracy={test_accuracy:0.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
