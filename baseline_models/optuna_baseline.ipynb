{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Trials For Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPU is detected.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import datetime\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n",
    "    \n",
    "if torch.cuda.is_available() == False:\n",
    "    RuntimeError(\"GPU detected: False\")\n",
    "    print(\"GPU detected: False\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"The GPU is detected.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "We make a basic NN for binary classification that takes as input a list of integers that correspond to the out_features of each linear layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, out_features, input_dropout=.2, hidden_dropout=.3):\n",
    "        \"\"\"Initializes the model layers.\n",
    "\n",
    "        Args:\n",
    "            in_features (int): The number of input features of the dataset.\n",
    "            out_features (list): The number of units in each linear layer.\n",
    "        \"\"\"\n",
    "        # Call the parent class (nn.Module) initializer first\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        # Input dropout layer\n",
    "        layers.append(nn.Dropout(input_dropout))\n",
    "    \n",
    "        # Build layers dynamically\n",
    "        for out_feature in out_features:\n",
    "            layers.append(nn.Linear(in_features, out_feature))\n",
    "            layers.append(nn.BatchNorm1d(out_feature))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(hidden_dropout))\n",
    "            in_features = out_feature\n",
    "        \n",
    "        # Final output layer for binary classification (with 1 output node)\n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        \n",
    "        # Store the sequence of layers\n",
    "        self.sequential = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        return self.sequential(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "We create the dataset we are going to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_x</th>\n",
       "      <th>game</th>\n",
       "      <th>tournament_key</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p2_id</th>\n",
       "      <th>p1_score</th>\n",
       "      <th>p2_score</th>\n",
       "      <th>location_names</th>\n",
       "      <th>bracket_name</th>\n",
       "      <th>...</th>\n",
       "      <th>start</th>\n",
       "      <th>p1_rating</th>\n",
       "      <th>p2_rating</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>top_8</th>\n",
       "      <th>rating_difference</th>\n",
       "      <th>higher_rated_won</th>\n",
       "      <th>more_updates_won</th>\n",
       "      <th>p1_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>90101028</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Fija</td>\n",
       "      <td>Fija</td>\n",
       "      <td>Sasha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1667.529088</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>167.529088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>90101030</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Empty Spirits</td>\n",
       "      <td>Bird</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1622.33761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>122.337610</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>90101031</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Stitchface</td>\n",
       "      <td>3551</td>\n",
       "      <td>Stitchface</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1523.497940</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.497940</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>90101033</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>rodohk</td>\n",
       "      <td>phlops</td>\n",
       "      <td>rodohk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1252.681917</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>247.318083</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>90101038</td>\n",
       "      <td>melee</td>\n",
       "      <td>s@sh7</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Psythr</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[W1, Winners 1, Winners Round 1]</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2017-06-13 10:27:01</td>\n",
       "      <td>1400.124736</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>99.875264</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_x   game tournament_key   winner_id          p1_id       p2_id  \\\n",
       "45  90101028  melee          s@sh7        Fija           Fija       Sasha   \n",
       "47  90101030  melee          s@sh7        Bird  Empty Spirits        Bird   \n",
       "48  90101031  melee          s@sh7  Stitchface           3551  Stitchface   \n",
       "50  90101033  melee          s@sh7      rodohk         phlops      rodohk   \n",
       "55  90101038  melee          s@sh7       Sorry         Psythr       Sorry   \n",
       "\n",
       "    p1_score  p2_score                    location_names bracket_name  ...  \\\n",
       "45         1         0  [W1, Winners 1, Winners Round 1]               ...   \n",
       "47         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "48         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "50         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "55         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
       "\n",
       "                 start    p1_rating   p2_rating p1_updates p2_updates  top_8  \\\n",
       "45 2017-06-13 10:27:01  1667.529088  1500.00000        1.0        0.0  False   \n",
       "47 2017-06-13 10:27:01  1500.000000  1622.33761        0.0        2.0  False   \n",
       "48 2017-06-13 10:27:01  1523.497940  1500.00000        3.0        0.0  False   \n",
       "50 2017-06-13 10:27:01  1252.681917  1500.00000        1.0        0.0  False   \n",
       "55 2017-06-13 10:27:01  1400.124736  1500.00000        1.0        0.0  False   \n",
       "\n",
       "    rating_difference  higher_rated_won  more_updates_won  p1_won  \n",
       "45         167.529088              True              True    True  \n",
       "47         122.337610              True              True   False  \n",
       "48          23.497940             False             False   False  \n",
       "50         247.318083              True             False   False  \n",
       "55          99.875264              True             False   False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + 'tournament_sets_with_top_8_df.pkl')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.676628e+06\n",
       "mean     2.322831e+02\n",
       "std      1.905061e+02\n",
       "min      1.000414e+00\n",
       "25%      8.691484e+01\n",
       "50%      1.861117e+02\n",
       "75%      3.284191e+02\n",
       "max      1.953188e+03\n",
       "Name: rating_difference, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating_difference'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182459, 25)\n",
      "Index(['key_x', 'game', 'tournament_key', 'winner_id', 'p1_id', 'p2_id',\n",
      "       'p1_score', 'p2_score', 'location_names', 'bracket_name',\n",
      "       'bracket_order', 'set_order', 'best_of', 'game_data', 'key_y', 'start',\n",
      "       'p1_rating', 'p2_rating', 'p1_updates', 'p2_updates', 'top_8',\n",
      "       'rating_difference', 'higher_rated_won', 'more_updates_won', 'p1_won'],\n",
      "      dtype='object')\n",
      "       key_x   game tournament_key   winner_id          p1_id       p2_id  \\\n",
      "45  90101028  melee          s@sh7        Fija           Fija       Sasha   \n",
      "47  90101030  melee          s@sh7        Bird  Empty Spirits        Bird   \n",
      "48  90101031  melee          s@sh7  Stitchface           3551  Stitchface   \n",
      "50  90101033  melee          s@sh7      rodohk         phlops      rodohk   \n",
      "55  90101038  melee          s@sh7       Sorry         Psythr       Sorry   \n",
      "\n",
      "    p1_score  p2_score                    location_names bracket_name  ...  \\\n",
      "45         1         0  [W1, Winners 1, Winners Round 1]               ...   \n",
      "47         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "48         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "50         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "55         0         1  [W1, Winners 1, Winners Round 1]               ...   \n",
      "\n",
      "                 start    p1_rating   p2_rating p1_updates p2_updates  top_8  \\\n",
      "45 2017-06-13 10:27:01  1667.529088  1500.00000        1.0        0.0  False   \n",
      "47 2017-06-13 10:27:01  1500.000000  1622.33761        0.0        2.0  False   \n",
      "48 2017-06-13 10:27:01  1523.497940  1500.00000        3.0        0.0  False   \n",
      "50 2017-06-13 10:27:01  1252.681917  1500.00000        1.0        0.0  False   \n",
      "55 2017-06-13 10:27:01  1400.124736  1500.00000        1.0        0.0  False   \n",
      "\n",
      "    rating_difference  higher_rated_won  more_updates_won  p1_won  \n",
      "45         167.529088              True              True    True  \n",
      "47         122.337610              True              True   False  \n",
      "48          23.497940             False             False   False  \n",
      "50         247.318083              True             False   False  \n",
      "55          99.875264              True             False   False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(1182459, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_rating</th>\n",
       "      <th>p2_rating</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1667.529088</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1622.33761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1523.497940</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1252.681917</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1400.124736</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p1_rating   p2_rating  p1_updates  p2_updates\n",
       "45  1667.529088  1500.00000         1.0         0.0\n",
       "47  1500.000000  1622.33761         0.0         2.0\n",
       "48  1523.497940  1500.00000         3.0         0.0\n",
       "50  1252.681917  1500.00000         1.0         0.0\n",
       "55  1400.124736  1500.00000         1.0         0.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['top_8'] == False]\n",
    "# df = df[df['rating_difference'] > 1]\n",
    "# df = df[df['rating_difference'] < 10]\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "features = ['p1_rating', 'p2_rating', 'p1_updates', 'p2_updates']\n",
    "# features = ['p1_updates', 'p2_updates']\n",
    "# features = ['p1_rating', 'p2_rating']\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "# # features = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "X = df[features].astype(float).values  # Convert to numpy array\n",
    "y = df['p1_won'].astype(float).values  # Convert to numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=103)\n",
    "\n",
    "# # Convert the splits to PyTorch tensors and reshape y to be 2D\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p1_elo', 'p2_elo', 'p1_rd', 'p2_rd', 'p1_updates', 'p2_updates', 'p1_m1_usage', 'p1_m2_usage', 'p1_m3_usage', 'p2_m1_usage', 'p2_m2_usage', 'p2_m3_usage', 'p1/m1/m1_elo', 'p1/m1/m1_updates', 'p1/m1/m2_elo', 'p1/m1/m2_updates', 'p1/m1/m3_elo', 'p1/m1/m3_updates', 'p1/m2/m1_elo', 'p1/m2/m1_updates', 'p1/m2/m2_elo', 'p1/m2/m2_updates', 'p1/m2/m3_elo', 'p1/m2/m3_updates', 'p1/m3/m1_elo', 'p1/m3/m1_updates', 'p1/m3/m2_elo', 'p1/m3/m2_updates', 'p1/m3/m3_elo', 'p1/m3/m3_updates', 'p2/m1/m1_elo', 'p2/m1/m1_updates', 'p2/m1/m2_elo', 'p2/m1/m2_updates', 'p2/m1/m3_elo', 'p2/m1/m3_updates', 'p2/m2/m1_elo', 'p2/m2/m1_updates', 'p2/m2/m2_elo', 'p2/m2/m2_updates', 'p2/m2/m3_elo', 'p2/m2/m3_updates', 'p2/m3/m1_elo', 'p2/m3/m1_updates', 'p2/m3/m2_elo', 'p2/m3/m2_updates', 'p2/m3/m3_elo', 'p2/m3/m3_updates']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>p2_elo</th>\n",
       "      <th>p1_rd</th>\n",
       "      <th>p2_rd</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>p1_m1_usage</th>\n",
       "      <th>p1_m2_usage</th>\n",
       "      <th>p1_m3_usage</th>\n",
       "      <th>p2_m1_usage</th>\n",
       "      <th>...</th>\n",
       "      <th>p2/m2/m2_elo</th>\n",
       "      <th>p2/m2/m2_updates</th>\n",
       "      <th>p2/m2/m3_elo</th>\n",
       "      <th>p2/m2/m3_updates</th>\n",
       "      <th>p2/m3/m1_elo</th>\n",
       "      <th>p2/m3/m1_updates</th>\n",
       "      <th>p2/m3/m2_elo</th>\n",
       "      <th>p2/m3/m2_updates</th>\n",
       "      <th>p2/m3/m3_elo</th>\n",
       "      <th>p2/m3/m3_updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1_elo  p2_elo  p1_rd  p2_rd  p1_updates  p2_updates  p1_m1_usage  \\\n",
       "681  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "682  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "683  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "684  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "685  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "\n",
       "     p1_m2_usage  p1_m3_usage  p2_m1_usage  ...  p2/m2/m2_elo  \\\n",
       "681          0.0          0.0          0.0  ...        1500.0   \n",
       "682          0.0          0.0          0.0  ...        1500.0   \n",
       "683          0.0          0.0          0.0  ...        1500.0   \n",
       "684          0.0          0.0          0.0  ...        1500.0   \n",
       "685          0.0          0.0          0.0  ...        1500.0   \n",
       "\n",
       "     p2/m2/m2_updates  p2/m2/m3_elo  p2/m2/m3_updates  p2/m3/m1_elo  \\\n",
       "681               0.0        1500.0               0.0        1500.0   \n",
       "682               0.0        1500.0               0.0        1500.0   \n",
       "683               0.0        1500.0               0.0        1500.0   \n",
       "684               0.0        1500.0               0.0        1500.0   \n",
       "685               0.0        1500.0               0.0        1500.0   \n",
       "\n",
       "     p2/m3/m1_updates  p2/m3/m2_elo  p2/m3/m2_updates  p2/m3/m3_elo  \\\n",
       "681               0.0        1500.0               0.0        1500.0   \n",
       "682               0.0        1500.0               0.0        1500.0   \n",
       "683               0.0        1500.0               0.0        1500.0   \n",
       "684               0.0        1500.0               0.0        1500.0   \n",
       "685               0.0        1500.0               0.0        1500.0   \n",
       "\n",
       "     p2/m3/m3_updates  \n",
       "681               0.0  \n",
       "682               0.0  \n",
       "683               0.0  \n",
       "684               0.0  \n",
       "685               0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + 'dataset_mini.pkl')\n",
    "\n",
    "features = list(df.columns)[:-1]\n",
    "print(features)\n",
    "\n",
    "X = df[features].astype(float).values  # Convert to numpy array\n",
    "y = df['winner'].astype(float).values  # Convert to numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=103)\n",
    "\n",
    "# # Convert the splits to PyTorch tensors and reshape y to be 2D\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall ELO and match count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['p1_elo', 'p2_elo', 'p1_rd', 'p2_rd', 'p1_updates', 'p2_updates',\n",
      "       'p1_melee/fox_count', 'p1_melee/falco_count', 'p1_melee/marth_count',\n",
      "       'p1_melee/sheik_count', 'p1_melee/captainfalcon_count',\n",
      "       'p1_melee/jigglypuff_count', 'p1_melee/peach_count',\n",
      "       'p1_melee/luigi_count', 'p1_melee/samus_count',\n",
      "       'p1_melee/ganondorf_count', 'p1_melee/iceclimbers_count',\n",
      "       'p1_melee/drmario_count', 'p1_melee/yoshi_count',\n",
      "       'p1_melee/pikachu_count', 'p1_melee/link_count',\n",
      "       'p1_melee/mrgameandwatch_count', 'p1_melee/donkeykong_count',\n",
      "       'p1_melee/mario_count', 'p1_melee/zelda_count', 'p1_melee/roy_count',\n",
      "       'p1_melee/younglink_count', 'p1_melee/kirby_count',\n",
      "       'p1_melee/ness_count', 'p1_melee/bowser_count', 'p1_melee/pichu_count',\n",
      "       'p1_melee/random_count', 'p1_melee/mewtwo_count', 'p2_melee/fox_count',\n",
      "       'p2_melee/falco_count', 'p2_melee/marth_count', 'p2_melee/sheik_count',\n",
      "       'p2_melee/captainfalcon_count', 'p2_melee/jigglypuff_count',\n",
      "       'p2_melee/peach_count', 'p2_melee/luigi_count', 'p2_melee/samus_count',\n",
      "       'p2_melee/ganondorf_count', 'p2_melee/iceclimbers_count',\n",
      "       'p2_melee/drmario_count', 'p2_melee/yoshi_count',\n",
      "       'p2_melee/pikachu_count', 'p2_melee/link_count',\n",
      "       'p2_melee/mrgameandwatch_count', 'p2_melee/donkeykong_count',\n",
      "       'p2_melee/mario_count', 'p2_melee/zelda_count', 'p2_melee/roy_count',\n",
      "       'p2_melee/younglink_count', 'p2_melee/kirby_count',\n",
      "       'p2_melee/ness_count', 'p2_melee/bowser_count', 'p2_melee/pichu_count',\n",
      "       'p2_melee/random_count', 'p2_melee/mewtwo_count', 'winner'],\n",
      "      dtype='object')\n",
      "(775155, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>p2_elo</th>\n",
       "      <th>p1_rd</th>\n",
       "      <th>p2_rd</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>p1_melee/fox_count</th>\n",
       "      <th>p1_melee/falco_count</th>\n",
       "      <th>p1_melee/marth_count</th>\n",
       "      <th>p1_melee/sheik_count</th>\n",
       "      <th>...</th>\n",
       "      <th>p2_melee/zelda_count</th>\n",
       "      <th>p2_melee/roy_count</th>\n",
       "      <th>p2_melee/younglink_count</th>\n",
       "      <th>p2_melee/kirby_count</th>\n",
       "      <th>p2_melee/ness_count</th>\n",
       "      <th>p2_melee/bowser_count</th>\n",
       "      <th>p2_melee/pichu_count</th>\n",
       "      <th>p2_melee/random_count</th>\n",
       "      <th>p2_melee/mewtwo_count</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116151</th>\n",
       "      <td>1912.996025</td>\n",
       "      <td>1861.525794</td>\n",
       "      <td>56.212927</td>\n",
       "      <td>56.672353</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113514</th>\n",
       "      <td>2141.731610</td>\n",
       "      <td>1979.768284</td>\n",
       "      <td>64.188421</td>\n",
       "      <td>57.640754</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113434</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1888.483601</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>59.798796</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113436</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1979.185560</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>60.960886</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113437</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1979.185560</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>60.960886</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             p1_elo       p2_elo      p1_rd      p2_rd  p1_updates  \\\n",
       "116151  1912.996025  1861.525794  56.212927  56.672353        11.0   \n",
       "113514  2141.731610  1979.768284  64.188421  57.640754        11.0   \n",
       "113434  2166.802439  1888.483601  61.638662  59.798796        12.0   \n",
       "113436  2166.802439  1979.185560  61.638662  60.960886        12.0   \n",
       "113437  2166.802439  1979.185560  61.638662  60.960886        12.0   \n",
       "\n",
       "        p2_updates  p1_melee/fox_count  p1_melee/falco_count  \\\n",
       "116151        12.0                 7.0                  25.0   \n",
       "113514        11.0                43.0                   0.0   \n",
       "113434        11.0                48.0                   0.0   \n",
       "113436        15.0                48.0                   0.0   \n",
       "113437        15.0                48.0                   0.0   \n",
       "\n",
       "        p1_melee/marth_count  p1_melee/sheik_count  ...  p2_melee/zelda_count  \\\n",
       "116151                   0.0                   0.0  ...                   0.0   \n",
       "113514                   0.0                   0.0  ...                   0.0   \n",
       "113434                   0.0                   0.0  ...                   0.0   \n",
       "113436                   0.0                   0.0  ...                   0.0   \n",
       "113437                   0.0                   0.0  ...                   0.0   \n",
       "\n",
       "        p2_melee/roy_count  p2_melee/younglink_count  p2_melee/kirby_count  \\\n",
       "116151                 0.0                       0.0                   0.0   \n",
       "113514                 0.0                       0.0                   0.0   \n",
       "113434                 0.0                       2.0                   0.0   \n",
       "113436                 0.0                       0.0                   0.0   \n",
       "113437                 0.0                       0.0                   0.0   \n",
       "\n",
       "        p2_melee/ness_count  p2_melee/bowser_count  p2_melee/pichu_count  \\\n",
       "116151                  0.0                    0.0                   0.0   \n",
       "113514                  0.0                    0.0                   0.0   \n",
       "113434                  0.0                    0.0                   0.0   \n",
       "113436                  0.0                    0.0                   0.0   \n",
       "113437                  0.0                    0.0                   0.0   \n",
       "\n",
       "        p2_melee/random_count  p2_melee/mewtwo_count  winner  \n",
       "116151                    0.0                    0.0     1.0  \n",
       "113514                    0.0                    0.0     1.0  \n",
       "113434                    0.0                    0.0     1.0  \n",
       "113436                    0.0                    0.0     1.0  \n",
       "113437                    0.0                    0.0     1.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + 'dataset.pkl')\n",
    "df = df[df['p1_updates'] > 10]\n",
    "df = df[df['p2_updates'] > 10]\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['p1_elo', 'p2_elo', 'p1_rd', 'p2_rd', 'p1_updates', 'p2_updates',\n",
      "       'p1_melee/fox_count', 'p1_melee/falco_count', 'p1_melee/marth_count',\n",
      "       'p1_melee/sheik_count', 'p1_melee/captainfalcon_count',\n",
      "       'p1_melee/jigglypuff_count', 'p1_melee/peach_count',\n",
      "       'p1_melee/luigi_count', 'p1_melee/samus_count',\n",
      "       'p1_melee/ganondorf_count', 'p1_melee/iceclimbers_count',\n",
      "       'p1_melee/drmario_count', 'p1_melee/yoshi_count',\n",
      "       'p1_melee/pikachu_count', 'p1_melee/link_count',\n",
      "       'p1_melee/mrgameandwatch_count', 'p1_melee/donkeykong_count',\n",
      "       'p1_melee/mario_count', 'p1_melee/zelda_count', 'p1_melee/roy_count',\n",
      "       'p1_melee/younglink_count', 'p1_melee/kirby_count',\n",
      "       'p1_melee/ness_count', 'p1_melee/bowser_count', 'p1_melee/pichu_count',\n",
      "       'p1_melee/random_count', 'p1_melee/mewtwo_count', 'p2_melee/fox_count',\n",
      "       'p2_melee/falco_count', 'p2_melee/marth_count', 'p2_melee/sheik_count',\n",
      "       'p2_melee/captainfalcon_count', 'p2_melee/jigglypuff_count',\n",
      "       'p2_melee/peach_count', 'p2_melee/luigi_count', 'p2_melee/samus_count',\n",
      "       'p2_melee/ganondorf_count', 'p2_melee/iceclimbers_count',\n",
      "       'p2_melee/drmario_count', 'p2_melee/yoshi_count',\n",
      "       'p2_melee/pikachu_count', 'p2_melee/link_count',\n",
      "       'p2_melee/mrgameandwatch_count', 'p2_melee/donkeykong_count',\n",
      "       'p2_melee/mario_count', 'p2_melee/zelda_count', 'p2_melee/roy_count',\n",
      "       'p2_melee/younglink_count', 'p2_melee/kirby_count',\n",
      "       'p2_melee/ness_count', 'p2_melee/bowser_count', 'p2_melee/pichu_count',\n",
      "       'p2_melee/random_count', 'p2_melee/mewtwo_count'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>p2_elo</th>\n",
       "      <th>p1_rd</th>\n",
       "      <th>p2_rd</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>p1_melee/fox_count</th>\n",
       "      <th>p1_melee/falco_count</th>\n",
       "      <th>p1_melee/marth_count</th>\n",
       "      <th>p1_melee/sheik_count</th>\n",
       "      <th>...</th>\n",
       "      <th>p2_melee/mario_count</th>\n",
       "      <th>p2_melee/zelda_count</th>\n",
       "      <th>p2_melee/roy_count</th>\n",
       "      <th>p2_melee/younglink_count</th>\n",
       "      <th>p2_melee/kirby_count</th>\n",
       "      <th>p2_melee/ness_count</th>\n",
       "      <th>p2_melee/bowser_count</th>\n",
       "      <th>p2_melee/pichu_count</th>\n",
       "      <th>p2_melee/random_count</th>\n",
       "      <th>p2_melee/mewtwo_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116151</th>\n",
       "      <td>1912.996025</td>\n",
       "      <td>1861.525794</td>\n",
       "      <td>56.212927</td>\n",
       "      <td>56.672353</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113514</th>\n",
       "      <td>2141.731610</td>\n",
       "      <td>1979.768284</td>\n",
       "      <td>64.188421</td>\n",
       "      <td>57.640754</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113434</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1888.483601</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>59.798796</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113436</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1979.185560</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>60.960886</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113437</th>\n",
       "      <td>2166.802439</td>\n",
       "      <td>1979.185560</td>\n",
       "      <td>61.638662</td>\n",
       "      <td>60.960886</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             p1_elo       p2_elo      p1_rd      p2_rd  p1_updates  \\\n",
       "116151  1912.996025  1861.525794  56.212927  56.672353        11.0   \n",
       "113514  2141.731610  1979.768284  64.188421  57.640754        11.0   \n",
       "113434  2166.802439  1888.483601  61.638662  59.798796        12.0   \n",
       "113436  2166.802439  1979.185560  61.638662  60.960886        12.0   \n",
       "113437  2166.802439  1979.185560  61.638662  60.960886        12.0   \n",
       "\n",
       "        p2_updates  p1_melee/fox_count  p1_melee/falco_count  \\\n",
       "116151        12.0                 7.0                  25.0   \n",
       "113514        11.0                43.0                   0.0   \n",
       "113434        11.0                48.0                   0.0   \n",
       "113436        15.0                48.0                   0.0   \n",
       "113437        15.0                48.0                   0.0   \n",
       "\n",
       "        p1_melee/marth_count  p1_melee/sheik_count  ...  p2_melee/mario_count  \\\n",
       "116151                   0.0                   0.0  ...                   0.0   \n",
       "113514                   0.0                   0.0  ...                   0.0   \n",
       "113434                   0.0                   0.0  ...                   0.0   \n",
       "113436                   0.0                   0.0  ...                   0.0   \n",
       "113437                   0.0                   0.0  ...                   0.0   \n",
       "\n",
       "        p2_melee/zelda_count  p2_melee/roy_count  p2_melee/younglink_count  \\\n",
       "116151                   0.0                 0.0                       0.0   \n",
       "113514                   0.0                 0.0                       0.0   \n",
       "113434                   0.0                 0.0                       2.0   \n",
       "113436                   0.0                 0.0                       0.0   \n",
       "113437                   0.0                 0.0                       0.0   \n",
       "\n",
       "        p2_melee/kirby_count  p2_melee/ness_count  p2_melee/bowser_count  \\\n",
       "116151                   0.0                  0.0                    0.0   \n",
       "113514                   0.0                  0.0                    0.0   \n",
       "113434                   0.0                  0.0                    0.0   \n",
       "113436                   0.0                  0.0                    0.0   \n",
       "113437                   0.0                  0.0                    0.0   \n",
       "\n",
       "        p2_melee/pichu_count  p2_melee/random_count  p2_melee/mewtwo_count  \n",
       "116151                   0.0                    0.0                    0.0  \n",
       "113514                   0.0                    0.0                    0.0  \n",
       "113434                   0.0                    0.0                    0.0  \n",
       "113436                   0.0                    0.0                    0.0  \n",
       "113437                   0.0                    0.0                    0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.columns[0:-1]\n",
    "print(features)\n",
    "\n",
    "X = df[features].astype(float).values  # Convert to numpy array\n",
    "y = df['winner'].astype(float).values  # Convert to numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=103)\n",
    "\n",
    "# # Convert the splits to PyTorch tensors and reshape y to be 2D\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p1_elo', 'p2_elo', 'p1_rd', 'p2_rd', 'p1_updates', 'p2_updates', 'p1_m1_usage', 'p1_m2_usage', 'p1_m3_usage', 'p2_m1_usage', 'p2_m2_usage', 'p2_m3_usage', 'p1/m1/m1_elo', 'p1/m1/m1_updates', 'p1/m1/m2_elo', 'p1/m1/m2_updates', 'p1/m1/m3_elo', 'p1/m1/m3_updates', 'p1/m2/m1_elo', 'p1/m2/m1_updates', 'p1/m2/m2_elo', 'p1/m2/m2_updates', 'p1/m2/m3_elo', 'p1/m2/m3_updates', 'p1/m3/m1_elo', 'p1/m3/m1_updates', 'p1/m3/m2_elo', 'p1/m3/m2_updates', 'p1/m3/m3_elo', 'p1/m3/m3_updates', 'p2/m1/m1_elo', 'p2/m1/m1_updates', 'p2/m1/m2_elo', 'p2/m1/m2_updates', 'p2/m1/m3_elo', 'p2/m1/m3_updates', 'p2/m2/m1_elo', 'p2/m2/m1_updates', 'p2/m2/m2_elo', 'p2/m2/m2_updates', 'p2/m2/m3_elo', 'p2/m2/m3_updates', 'p2/m3/m1_elo', 'p2/m3/m1_updates', 'p2/m3/m2_elo', 'p2/m3/m2_updates', 'p2/m3/m3_elo', 'p2/m3/m3_updates']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>p2_elo</th>\n",
       "      <th>p1_rd</th>\n",
       "      <th>p2_rd</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>p1_m1_usage</th>\n",
       "      <th>p1_m2_usage</th>\n",
       "      <th>p1_m3_usage</th>\n",
       "      <th>p2_m1_usage</th>\n",
       "      <th>...</th>\n",
       "      <th>p2/m2/m2_elo</th>\n",
       "      <th>p2/m2/m2_updates</th>\n",
       "      <th>p2/m2/m3_elo</th>\n",
       "      <th>p2/m2/m3_updates</th>\n",
       "      <th>p2/m3/m1_elo</th>\n",
       "      <th>p2/m3/m1_updates</th>\n",
       "      <th>p2/m3/m2_elo</th>\n",
       "      <th>p2/m3/m2_updates</th>\n",
       "      <th>p2/m3/m3_elo</th>\n",
       "      <th>p2/m3/m3_updates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1_elo  p2_elo  p1_rd  p2_rd  p1_updates  p2_updates  p1_m1_usage  \\\n",
       "681  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "682  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "683  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "684  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "685  1500.0  1500.0  350.0  350.0         0.0         0.0          0.0   \n",
       "\n",
       "     p1_m2_usage  p1_m3_usage  p2_m1_usage  ...  p2/m2/m2_elo  \\\n",
       "681          0.0          0.0          0.0  ...        1500.0   \n",
       "682          0.0          0.0          0.0  ...        1500.0   \n",
       "683          0.0          0.0          0.0  ...        1500.0   \n",
       "684          0.0          0.0          0.0  ...        1500.0   \n",
       "685          0.0          0.0          0.0  ...        1500.0   \n",
       "\n",
       "     p2/m2/m2_updates  p2/m2/m3_elo  p2/m2/m3_updates  p2/m3/m1_elo  \\\n",
       "681               0.0        1500.0               0.0        1500.0   \n",
       "682               0.0        1500.0               0.0        1500.0   \n",
       "683               0.0        1500.0               0.0        1500.0   \n",
       "684               0.0        1500.0               0.0        1500.0   \n",
       "685               0.0        1500.0               0.0        1500.0   \n",
       "\n",
       "     p2/m3/m1_updates  p2/m3/m2_elo  p2/m3/m2_updates  p2/m3/m3_elo  \\\n",
       "681               0.0        1500.0               0.0        1500.0   \n",
       "682               0.0        1500.0               0.0        1500.0   \n",
       "683               0.0        1500.0               0.0        1500.0   \n",
       "684               0.0        1500.0               0.0        1500.0   \n",
       "685               0.0        1500.0               0.0        1500.0   \n",
       "\n",
       "     p2/m3/m3_updates  \n",
       "681               0.0  \n",
       "682               0.0  \n",
       "683               0.0  \n",
       "684               0.0  \n",
       "685               0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(data_path + 'dataset_mini.pkl')\n",
    "\n",
    "features = list(df.columns)[0:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(features)\n",
    "\n",
    "X = df[features].astype(float).values  # Convert to numpy array\n",
    "y = df['winner'].astype(float).values  # Convert to numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=.5, random_state=103)\n",
    "\n",
    "# # Convert the splits to PyTorch tensors and reshape y to be 2D\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_elo</th>\n",
       "      <th>p2_elo</th>\n",
       "      <th>p1_rd</th>\n",
       "      <th>p2_rd</th>\n",
       "      <th>p1_updates</th>\n",
       "      <th>p2_updates</th>\n",
       "      <th>p1_m1_usage</th>\n",
       "      <th>p1_m2_usage</th>\n",
       "      <th>p1_m3_usage</th>\n",
       "      <th>p2_m1_usage</th>\n",
       "      <th>...</th>\n",
       "      <th>p2/m2/m2_updates</th>\n",
       "      <th>p2/m2/m3_elo</th>\n",
       "      <th>p2/m2/m3_updates</th>\n",
       "      <th>p2/m3/m1_elo</th>\n",
       "      <th>p2/m3/m1_updates</th>\n",
       "      <th>p2/m3/m2_elo</th>\n",
       "      <th>p2/m3/m2_updates</th>\n",
       "      <th>p2/m3/m3_elo</th>\n",
       "      <th>p2/m3/m3_updates</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489901</th>\n",
       "      <td>1770.163715</td>\n",
       "      <td>1386.695651</td>\n",
       "      <td>72.805474</td>\n",
       "      <td>65.897981</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489902</th>\n",
       "      <td>1625.192442</td>\n",
       "      <td>1485.997649</td>\n",
       "      <td>56.094492</td>\n",
       "      <td>81.581109</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489903</th>\n",
       "      <td>1784.559717</td>\n",
       "      <td>1770.163715</td>\n",
       "      <td>64.115340</td>\n",
       "      <td>72.805474</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1654.006739</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489904</th>\n",
       "      <td>1625.192442</td>\n",
       "      <td>1770.163715</td>\n",
       "      <td>56.094492</td>\n",
       "      <td>72.805474</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489905</th>\n",
       "      <td>1922.314756</td>\n",
       "      <td>1770.163715</td>\n",
       "      <td>44.802728</td>\n",
       "      <td>72.805474</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1654.006739</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795215 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              p1_elo       p2_elo       p1_rd       p2_rd  p1_updates  \\\n",
       "681      1500.000000  1500.000000  350.000000  350.000000         0.0   \n",
       "682      1500.000000  1500.000000  350.000000  350.000000         0.0   \n",
       "683      1500.000000  1500.000000  350.000000  350.000000         0.0   \n",
       "684      1500.000000  1500.000000  350.000000  350.000000         0.0   \n",
       "685      1500.000000  1500.000000  350.000000  350.000000         0.0   \n",
       "...              ...          ...         ...         ...         ...   \n",
       "1489901  1770.163715  1386.695651   72.805474   65.897981         9.0   \n",
       "1489902  1625.192442  1485.997649   56.094492   81.581109        45.0   \n",
       "1489903  1784.559717  1770.163715   64.115340   72.805474        18.0   \n",
       "1489904  1625.192442  1770.163715   56.094492   72.805474        45.0   \n",
       "1489905  1922.314756  1770.163715   44.802728   72.805474        47.0   \n",
       "\n",
       "         p2_updates  p1_m1_usage  p1_m2_usage  p1_m3_usage  p2_m1_usage  ...  \\\n",
       "681             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "682             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "683             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "684             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "685             0.0          0.0          0.0          0.0          0.0  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "1489901        43.0         21.0         20.0          0.0        136.0  ...   \n",
       "1489902        11.0        296.0         20.0          2.0         22.0  ...   \n",
       "1489903         9.0         96.0         17.0          7.0         21.0  ...   \n",
       "1489904         9.0        296.0         20.0          2.0         21.0  ...   \n",
       "1489905         9.0        403.0        155.0         52.0         21.0  ...   \n",
       "\n",
       "         p2/m2/m2_updates  p2/m2/m3_elo  p2/m2/m3_updates  p2/m3/m1_elo  \\\n",
       "681                   0.0   1500.000000               0.0        1500.0   \n",
       "682                   0.0   1500.000000               0.0        1500.0   \n",
       "683                   0.0   1500.000000               0.0        1500.0   \n",
       "684                   0.0   1500.000000               0.0        1500.0   \n",
       "685                   0.0   1500.000000               0.0        1500.0   \n",
       "...                   ...           ...               ...           ...   \n",
       "1489901               0.0   1500.000000               0.0        1500.0   \n",
       "1489902               0.0   1500.000000               0.0        1500.0   \n",
       "1489903               2.0   1654.006739               3.0        1500.0   \n",
       "1489904               1.0   1500.000000               0.0        1500.0   \n",
       "1489905               2.0   1654.006739               3.0        1500.0   \n",
       "\n",
       "         p2/m3/m1_updates  p2/m3/m2_elo  p2/m3/m2_updates  p2/m3/m3_elo  \\\n",
       "681                   0.0        1500.0               0.0        1500.0   \n",
       "682                   0.0        1500.0               0.0        1500.0   \n",
       "683                   0.0        1500.0               0.0        1500.0   \n",
       "684                   0.0        1500.0               0.0        1500.0   \n",
       "685                   0.0        1500.0               0.0        1500.0   \n",
       "...                   ...           ...               ...           ...   \n",
       "1489901               0.0        1500.0               0.0        1500.0   \n",
       "1489902               0.0        1500.0               0.0        1500.0   \n",
       "1489903               0.0        1500.0               0.0        1500.0   \n",
       "1489904               0.0        1500.0               0.0        1500.0   \n",
       "1489905               0.0        1500.0               0.0        1500.0   \n",
       "\n",
       "         p2/m3/m3_updates  winner  \n",
       "681                   0.0     1.0  \n",
       "682                   0.0     0.0  \n",
       "683                   0.0     1.0  \n",
       "684                   0.0     1.0  \n",
       "685                   0.0     1.0  \n",
       "...                   ...     ...  \n",
       "1489901               0.0     1.0  \n",
       "1489902               0.0     1.0  \n",
       "1489903               0.0     0.0  \n",
       "1489904               0.0     0.0  \n",
       "1489905               0.0     0.0  \n",
       "\n",
       "[1795215 rows x 49 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=17, n_jobs=-1)\n",
    "# knn.fit(X_train, y_train)\n",
    "# predictions = knn.predict(X_test)\n",
    "# print('Acc =', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.7723056127034112\n",
      "LogLoss 8.206937574365645\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=3, n_estimators=100, tree_method='hist')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('Acc', accuracy_score(y_test, predictions))\n",
    "print('LogLoss', log_loss(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7590427887467518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base estimator and AdaBoost parameters\n",
    "# Define the base estimator and AdaBoost parameters\n",
    "# base_estimator =  DecisionTreeClassifier(max_depth=1)\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Train AdaBoost\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 12:30:18,656] A new study created in memory with name: no-name-735863f1-c33a-4b49-b33f-89bea9eeee25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dae58d766a24313a18df90a1bbef61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2024-10-31 12:30:47,884] Trial 0 failed with parameters: {'eta': 0.021779213173376277, 'max_depth': 7, 'subsample': 0.7786862764529311, 'colsample_bytree': 0.8437810658175637, 'lambda': 0.0011553578016208121, 'alpha': 0.008071252456471213} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_377542/1980045240.py\", line 25, in objective\n",
      "    model = xgb.train(params, dtrain, num_boost_round=1000, evals=evallist, early_stopping_rounds=200, verbose_eval=False)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 182, in train\n",
      "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/callback.py\", line 258, in after_iteration\n",
      "    score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2212, in eval_set\n",
      "    _LIB.XGBoosterEvalOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-31 12:30:47,885] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create a study object and optimize the objective function\u001b[39;00m\n\u001b[1;32m     39\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# We want to maximize accuracy\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You can set n_trials higher for more iterations\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[72], line 25\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m evallist \u001b[38;5;241m=\u001b[39m [(dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dval, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevallist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[1;32m     28\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dval)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/callback.py:258\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 258\u001b[0m score: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py:2212\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2209\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   2210\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[1;32m   2211\u001b[0m _check_call(\n\u001b[0;32m-> 2212\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2220\u001b[0m )\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2222\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters using the new `suggest_float` method\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3, log=True),  # learning rate\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),        # max depth of trees\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), # subsample ratio\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # colsample by tree\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),  # L2 regularization\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),    # L1 regularization\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # Train the model\n",
    "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "    model = xgb.train(params, dtrain, num_boost_round=1000, evals=evallist, early_stopping_rounds=200, verbose_eval=False)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(dval)\n",
    "    y_val_pred_binary = [1 if p > 0.5 else 0 for p in y_val_pred]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_val_pred_binary)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=5, show_progress_bar=True)  # You can set n_trials higher for more iterations\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Accuracy: {trial.value}')\n",
    "print('  Best hyperparameters: ', trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=8, num_workers=16):\n",
    "    # Convert datasets to TensorDataset (pairs features and labels)\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    # Create DataLoader objects for train, test, and validation datasets\n",
    "    loaders = {\n",
    "        \"train\": DataLoader(train_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "        \"test\": DataLoader(test_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "        \"val\": DataLoader(val_dataset, batch_size=batch_size, drop_last=True, num_workers=num_workers, shuffle=True, pin_memory=True, persistent_workers=True),\n",
    "    }\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Functions\n",
    "Here we have basic train and test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_progress(model, loaders, criterion, optimizer, num_epochs, epoch, device):\n",
    "    model.train()\n",
    "    \n",
    "    # Use tqdm to display progress bar for the training loop\n",
    "    leave = True\n",
    "    train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch', leave=leave)\n",
    "    \n",
    "    # Our training dataset is has well over a million examples.\n",
    "    # We expect the loss to change a lot over a single epoch,\n",
    "    # so we only show the loss of the 10_000 most recent batches.\n",
    "    running_loss = deque(maxlen=10000)\n",
    "    \n",
    "    # Train epoch\n",
    "    for X_train, y_train in train_loader_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_train_gpu = X_train.to(device)\n",
    "        y_train_gpu = y_train.to(device)\n",
    "        \n",
    "        output_gpu = model(X_train_gpu)\n",
    "        \n",
    "        loss = criterion(output_gpu, y_train_gpu)\n",
    "        running_loss.append(loss.item())  # Store loss for averaging\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate and set the average loss for the tqdm progress bar\n",
    "        avg_loss = sum(running_loss) / len(running_loss) if len(running_loss) > 0 else 0\n",
    "        \n",
    "        train_loader_tqdm.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "    return\n",
    "\n",
    "def test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='test'):\n",
    "    # Validate epoch:\n",
    "    model.eval()\n",
    "    leave = True\n",
    "    test_loader_tqdm = tqdm(loaders[loader], desc=f'Test {epoch+1}/{num_epochs}', unit='batch', leave=leave)\n",
    "    test_loss = []\n",
    "    num_tested = []\n",
    "    correct_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader_tqdm:\n",
    "            X_test_gpu = X_test.to(device)\n",
    "            y_test_gpu = y_test.to(device)\n",
    "            \n",
    "            output_gpu = model(X_test_gpu)\n",
    "            \n",
    "            # Accumulate test loss\n",
    "            test_loss.append(criterion(output_gpu, y_test_gpu).item() * X_test.shape[0])\n",
    "            num_tested.append(X_test.shape[0])\n",
    "            \n",
    "            # Calculate number of correct predictions for binary classification\n",
    "            correct_pred += torch.sum(((nn.Sigmoid()(output_gpu) > 0.5) == y_test_gpu).float()).item()\n",
    "            \n",
    "            test_loader_tqdm.set_postfix(loss=f\"{sum(test_loss) / sum(num_tested):.4f}\", acc=f\"{correct_pred / sum(num_tested):.1%}\")\n",
    "        \n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = sum(test_loss) / sum(num_tested)\n",
    "        accuracy = correct_pred / sum(num_tested)\n",
    "        \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the same train and test functions as above, but without the progress bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loaders, criterion, optimizer, num_epochs, epoch, device):\n",
    "    model.train()\n",
    "    \n",
    "    # Train epoch\n",
    "    for X_train, y_train in loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X_train_gpu = X_train.to(device)\n",
    "        y_train_gpu = y_train.to(device)\n",
    "        \n",
    "        output_gpu = model(X_train_gpu)\n",
    "        \n",
    "        loss = criterion(output_gpu, y_train_gpu)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return \n",
    "\n",
    "def test_model(model, loaders, criterion, device, num_epochs, epoch, loader='test'):\n",
    "    # Validate epoch:\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    num_tested = []\n",
    "    correct_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in loaders[loader]:\n",
    "            X_test_gpu = X_test.to(device)\n",
    "            y_test_gpu = y_test.to(device)\n",
    "            \n",
    "            output_gpu = model(X_test_gpu)\n",
    "            \n",
    "            # Accumulate test loss.\n",
    "            test_loss.append(criterion(output_gpu, y_test_gpu).item() * X_test.shape[0])\n",
    "            num_tested.append(X_test.shape[0])\n",
    "            \n",
    "            # Calculate number of correct predictions for binary classification.\n",
    "            correct_pred += torch.sum(((nn.Sigmoid()(output_gpu) > 0.5) == y_test_gpu).float()).item()\n",
    "        \n",
    "        # Calculate average loss and accuracy\n",
    "        avg_loss = sum(test_loss) / sum(num_tested)\n",
    "        accuracy = correct_pred / sum(num_tested)\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Study\n",
    "We create a simple optuna study to find a good model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, num_layers, min_out, max_out, in_features, loaders, study_name):\n",
    "    input_dropout = 0\n",
    "    hidden_dropout = .2\n",
    "    # input_dropout = trial.suggest_float(\"input_dropout\", 0, .5)\n",
    "    hidden_dropout = trial.suggest_float(\"hidden_dropout\", 0, .5)\n",
    "    \n",
    "    # Generate the output features for each layer using trial suggestions\n",
    "    out_features = []\n",
    "    for i in range(num_layers):\n",
    "        out_features.append(trial.suggest_int(f\"out_features_layer_{i}\", min_out, max_out))\n",
    "    \n",
    "    # Create model and move to device\n",
    "    model = Model(in_features, out_features, input_dropout, hidden_dropout).to(device)\n",
    "    \n",
    "    # Compile the model (not always worth it)\n",
    "    # model.compile()\n",
    "    \n",
    "    # Initialize optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    num_epochs = 1\n",
    "    \n",
    "    # Training loop for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        train_epoch(model, loaders, criterion, optimizer, num_epochs, epoch, device)\n",
    "    \n",
    "    test_loss, test_accuracy = test_model(model, loaders, criterion, device, num_epochs, epoch, loader='test')\n",
    "    print(f\"Accuracy = {test_accuracy:.1%}\")\n",
    "    ## Print results if we want \n",
    "    # print(f\"Loss={test_loss:0.5f}, Accuracy={test_accuracy:0.1%}\")\n",
    "    \n",
    "    # Return the test loss to be minimized\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 12:02:55,543] A new study created in memory with name: Baseline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b76688e58504cf59cb650c8fdb89b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 76.6%\n",
      "[I 2024-10-31 12:04:24,327] Trial 0 finished with value: 0.4872140946651383 and parameters: {'hidden_dropout': 0.39654711497366557, 'out_features_layer_0': 292, 'out_features_layer_1': 572, 'out_features_layer_2': 23}. Best is trial 0 with value: 0.4872140946651383.\n",
      "[W 2024-10-31 12:05:07,257] Trial 1 failed with parameters: {'hidden_dropout': 0.36177104390061604, 'out_features_layer_0': 247, 'out_features_layer_1': 706, 'out_features_layer_2': 121} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_377542/2175656236.py\", line 14, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, num_layers, min_out, max_out, in_features, loaders, study_name),\n",
      "  File \"/tmp/ipykernel_377542/3303981478.py\", line 26, in objective\n",
      "    train_epoch(model, loaders, criterion, optimizer, num_epochs, epoch, device)\n",
      "  File \"/tmp/ipykernel_377542/52647914.py\", line 15, in train_epoch\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 812, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-31 12:05:07,258] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define the objective function and run the optimization\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You can specify how many trials you want\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Print the best parameters found by the study\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     11\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define the objective function and run the optimization\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudy_name\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m     15\u001b[0m                n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# You can specify how many trials you want\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Print the best parameters found by the study\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[31], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, num_layers, min_out, max_out, in_features, loaders, study_name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Training loop for num_epochs\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m test_model(model, loaders, criterion, device, num_epochs, epoch, loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loaders, criterion, optimizer, num_epochs, epoch, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m     output_gpu \u001b[38;5;241m=\u001b[39m model(X_train_gpu)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output_gpu, y_train_gpu)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:812\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaders = prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=16, num_workers=1)\n",
    "\n",
    "# Define the parameters for the study\n",
    "study_name = \"Baseline\"\n",
    "num_layers = 3\n",
    "min_out = 16\n",
    "max_out = 1024 * 2\n",
    "in_features = X_train.shape[1]\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(study_name=study_name, direction='minimize')\n",
    "\n",
    "# Define the objective function and run the optimization\n",
    "study.optimize(lambda trial: objective(trial, num_layers, min_out, max_out, in_features, loaders, study_name), \n",
    "               n_trials=10, show_progress_bar=True)  # You can specify how many trials you want\n",
    "\n",
    "# Print the best parameters found by the study\n",
    "print()\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "print(f\"Best trial: {study.best_trial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get parameters of the best study\u001b[39;00m\n\u001b[1;32m      2\u001b[0m out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Adjust indexing as needed\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m input_dropout \u001b[38;5;241m=\u001b[39m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_dropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m   \u001b[38;5;66;03m# Example key name\u001b[39;00m\n\u001b[1;32m      4\u001b[0m hidden_dropout \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dropout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# Example key name\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_dropout'"
     ]
    }
   ],
   "source": [
    "# Get parameters of the best study\n",
    "out_features = list(study.best_params.values())[2:]  # Adjust indexing as needed\n",
    "input_dropout = study.best_params['input_dropout']   # Example key name\n",
    "hidden_dropout = study.best_params['hidden_dropout'] # Example key name\n",
    "\n",
    "# Build the model\n",
    "model = Model(in_features, out_features, input_dropout, hidden_dropout)\n",
    "# model = Model(X.shape[1], [128, 64, 32], 0, .25)\n",
    "# model = Model(X.shape[1], [64, 32, 16], 0, .25)\n",
    "# model = Model(X.shape[1], [64, 16], 0, .25)\n",
    "# model = Model(X.shape[1], [128*4], 0, .5)\n",
    "# model = Model(X.shape[1], [128*8], 0, .75)\n",
    "\n",
    "loaders = prepare_data_loaders(X_train, y_train, X_test, y_test, X_val, y_val, batch_size=8, num_workers=1)\n",
    "\n",
    "## Compiling might not be worth it (Cannot save the model if we do.)\n",
    "# model = torch.compile(model)#, mode = 'max-autotune')\n",
    "\n",
    "# Move model to the GPU\n",
    "model.to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 1\n",
    "# Training loop for num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    train_epoch_progress(model, loaders, criterion, optimizer, num_epochs, epoch, device)\n",
    "    test_loss, test_accuracy = test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='test')\n",
    "\n",
    "test_loss, test_accuracy = test_model_progress(model, loaders, criterion, device, num_epochs, epoch, loader='val')\n",
    "print(f\"Val: Loss={test_loss:0.5f}, Accuracy={test_accuracy:0.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
