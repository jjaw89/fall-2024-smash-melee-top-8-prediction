{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Top 8\n",
    "In this notebook we want to:\n",
    "- Filter out tournaments that do not have the canonical sets_df['location_names']\n",
    "- Label the top 8 sets of a tournament.\n",
    "- Determine the bracket, i.e. which of the losers of the winners set plays which of the winners of the losers sets.\n",
    "\n",
    "We are also interested in:\n",
    "- How often does a grand finals reset occur?\n",
    "- How often does the winner of the loser's finals win the tournament?\n",
    "- How often does a player coming into the top 8 from losers win the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SQLite Database into Pandas DataFrames\n",
    "\n",
    "The following code connects to an SQLite database (`melee_player_database.db`) and converts each table within the database into a pandas DataFrame. The DataFrames will be stored in a dictionary, where each key corresponds to the table name with `_df` appended, and the values are the respective DataFrames.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Database Connection**: We use the `sqlite3` library to connect to the SQLite database file.\n",
    "2. **Retrieve Table Names**: A query retrieves all the table names in the database.\n",
    "3. **Convert Tables to DataFrames**: For each table:\n",
    "   - The table is loaded into a pandas DataFrame using `pd.read_sql()`.\n",
    "   - We check each column to see if any data is JSON-formatted (lists or dictionaries). If so, we convert these columns from strings into their corresponding Python objects using `json.loads()`.\n",
    "4. **Store DataFrames**: The DataFrames are stored in a dictionary, where the key is the table name with a `_df` suffix, and the value is the DataFrame.\n",
    "5. **Database Connection Closed**: Once all tables are loaded into DataFrames, the database connection is closed.\n",
    "\n",
    "### Example:\n",
    "If the database contains a table named `players`, the corresponding DataFrame will be stored in the dictionary with the key `players_df`, and can be accessed as:\n",
    "\n",
    "```python\n",
    "players_df = dfs['players_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "if os.path.exists(data_path + 'dfs_dict.pkl'):\n",
    "    cell_has_run = True\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    with open(data_path + 'dfs_dict.pkl', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = + data_path + \"melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we adjust the data types of the dataframes so that they are the correct type. (This will be updated as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sets_df']['best_of'] = dfs['sets_df']['best_of'].fillna(0).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the dictionary of DataFrames as a pickle\n",
    "# with open(data_path + 'dfs_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we make dataframes that we will use and print the head.\n",
    "\n",
    "The integers in 'characters' count the number of games the player has played that character. (We verify this for Zain below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs['players_df']\n",
    "players_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = dfs['ranking_df']\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "ranking_seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df = dfs['sets_df']\n",
    "print(f\"{sets_df[sets_df['game_data'].apply(lambda x: len(x) > 0)].shape[0] / sets_df.shape[0]:0.01%} percent of sets have some game data\")\n",
    "sets_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = dfs['tournament_info_df']\n",
    "print(tournament_info_df.shape)\n",
    "tournament_info_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out some touraments\n",
    "We start by looking for sets_df['location_names'] are the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use .to_string() so that we print out all the values.\n",
    "print(sets_df['location_names'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the value counts we see that there are several sets_df['location_names'] that correspond to the finals of the tournament:\n",
    "- ['GF', 'Grand Final',' Grand Final']              35523\n",
    "- ['F', 'Final', 'Final']                           615\n",
    "- ['Grand Finals', 'Grand Finals', 'Grand Finals']  7\n",
    "- [Grand Final, Grand Final, Grand Final]           1\n",
    "\n",
    "We will filter out the tournaments that do not have a set with ['GF', 'Grand Final',' Grand Final'] in their location names. That way the location names of all the sets in the tournament should be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where 'location_names' exactly matches ['GF', 'Grand Final', 'Grand Final']\n",
    "gf_sets_df = sets_df[sets_df['location_names'].apply(lambda x: x == ['GF', 'Grand Final', 'Grand Final'])]\n",
    "\n",
    "# Extract the tournament keys for the Grand Finals\n",
    "gf_tournament_keys = list(gf_sets_df['tournament_key'])\n",
    "\n",
    "# Filter the sets_df to include only the sets from tournaments that had Grand Finals\n",
    "valid_tournament_sets_df = sets_df[sets_df['tournament_key'].isin(gf_tournament_keys)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the structure of a typical top 8 bracket.\n",
    "![alt text](top_8.png \"Top 8 Bracket\")\n",
    "We need to figure out what location names correspond to which positions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect that the location names of the top 8 games are the following:\n",
    "- [f\"L{n}\", f\"Losers {n}\", f\"Losers Round {n}], # Where n is the maximum n in all such location of the  tournament.  \n",
    "- ['WSF', 'Winners Semis', 'Winners Semi-Final'],\n",
    "- ['LQF', 'Losers Quarters', 'Losers Quarter-Final'],\n",
    "- ['WF', 'Winners Final', 'Winners Final'],\n",
    "- ['LSF', 'Losers Semis', 'Losers Semi-Final'],\n",
    "- ['LF', 'Losers Final', 'Losers Final'],\n",
    "- ['GF', 'Grand Final', 'Grand Final'],'\n",
    "- ['GFR', 'GF Reset', 'Grand Final Reset']\n",
    "\n",
    "We will test that hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we ignore the L{n} location name.\n",
    "top_8_locations = [                                   \n",
    "        ['WSF', 'Winners Semis', 'Winners Semi-Final'],\n",
    "        ['LQF', 'Losers Quarters', 'Losers Quarter-Final'],\n",
    "        ['WF', 'Winners Final', 'Winners Final'],\n",
    "        ['LSF', 'Losers Semis', 'Losers Semi-Final'],\n",
    "        ['LF', 'Losers Final', 'Losers Final'],\n",
    "        ['GF', 'Grand Final', 'Grand Final'],\n",
    "        ['GFR', 'GF Reset', 'Grand Final Reset']\n",
    "    ] \n",
    "\n",
    "valid_tournament_sets_df[valid_tournament_sets_df['location_names'].isin(top_8_locations)]['location_names'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our hypothesis was correct, the there should be the same number of sets with location_names WF, LF, and GF, because the grand finals consisit of the winner from the losers final and the winners of the winners final. But the counts of those in our filtered data set do not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of tourmanets in our filtered dataset is', len(gf_tournament_keys))\n",
    "print()\n",
    "# Display the value counts of the remaining location names.\n",
    "print(valid_tournament_sets_df['location_names'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tournament_sets_df['location_names'] = valid_tournament_sets_df['location_names'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to process the tournaments with empty bracket_name seperately from the tournaments with non-empty bracket names. We start with tournaments with nothing in the bracket_name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the sets from tournaments with empty bracket_name\n",
    "valid_tournament_sets_no_bracket_df = valid_tournament_sets_df[valid_tournament_sets_df['bracket_name'] == \"\"]\n",
    "\n",
    "# These are the top_8 locations, not including L{n}\n",
    "top_8_locations = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']                        \n",
    "\n",
    "# Filter the sets with those location_names\n",
    "top_8_no_bracket_name_df = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'].isin(top_8_locations)]\n",
    "\n",
    "# Check that the number of games matches up.\n",
    "top_8_no_bracket_name_df['location_names'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect the same number of WF, LSF, and LF as there are GF and there should be double that for the LQF and WSF. I hypothesise that some of these are labelled as W{n} and L{n}. Lets check if any of the tournaments do not have a set labelled WF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = valid_tournament_sets_no_bracket_df.groupby('tournament_key')\n",
    "\n",
    "all_tournaments_have_wf = True\n",
    "for key, frame in groups:\n",
    "    if not frame['location_names'].isin([\"WF\"]).any():\n",
    "        print(key, \"has no WF sets.\")\n",
    "        all_tournaments_have_wf = False\n",
    "\n",
    "if all_tournaments_have_wf:\n",
    "    print(\"All tournaments have a WF set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tournaments have a WF. Lets check to see how if there are tournaments with two GF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournaments_with_gfr = []\n",
    "\n",
    "for key, frame in groups:\n",
    "    if frame['location_names'].isin([\"GF\"]).sum()==2:\n",
    "        print(key, \"has two gf sets.\")\n",
    "        tournaments_with_gfr.append(key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in all these tournaments, a grand finals reset is has location name GF. Lets print out the GF sets in tournaments with a GF reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfr_sets_df = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['tournament_key'].isin(tournaments_with_gfr)]\n",
    "gfr_sets_df = gfr_sets_df[gfr_sets_df['location_names']=='GF']\n",
    "gfr_sets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">To Do: We need to figure out a way to determine which is the GF and which is the GF reset.</span>\n",
    "\n",
    "From here, we need to get the top 8 tournaments sets with L{n} where n is maximal for that tournament.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'location_names' before grouping\n",
    "losers_sets_df = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'].apply(lambda x: x[0]=='L')]\n",
    "losers_sets_df = losers_sets_df.sort_values(['tournament_key','location_names'])\n",
    "groups = losers_sets_df.groupby('tournament_key')\n",
    "\n",
    "last_l_sets = []\n",
    "\n",
    "for _, frame in groups:\n",
    "    last_l_sets.append(frame.iloc[-6:-4]) # I want to append the index that that appears in losers_sets_df\n",
    "\n",
    "all_top_8_no_bracket_name_df = pd.concat([top_8_no_bracket_name_df, pd.concat(last_l_sets)])\n",
    "all_top_8_no_bracket_name_df.sort_values(['tournament_key','location_names'], inplace=True)\n",
    "all_top_8_no_bracket_name_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``all_top_8_no_bracket_name_df`` should be all the top 8 sets without a bracket_name. Looping over groups is slow, lets avoid that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for tournaments with empty 'bracket_name'\n",
    "valid_tournament_sets_no_bracket_df = valid_tournament_sets_df[valid_tournament_sets_df['bracket_name'] == \"\"]\n",
    "\n",
    "# Define top_8 locations (excluding L{n})\n",
    "top_8_locations = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']\n",
    "\n",
    "# Filter sets with those location_names for top_8\n",
    "top_8_no_bracket_name_df = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'].isin(top_8_locations)]\n",
    "\n",
    "# Filter for rows where location_names start with 'L'\n",
    "losers_sets_df = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'].str.startswith('L')]\n",
    "\n",
    "# Sort by 'tournament_key' and 'location_names'\n",
    "losers_sets_df = losers_sets_df.sort_values(['tournament_key', 'location_names'])\n",
    "\n",
    "# Select the 5th and 6th last rows from each group in one go\n",
    "last_l_sets = losers_sets_df.groupby('tournament_key').nth([-6, -5])\n",
    "\n",
    "# Combine the filtered top_8 sets with the last sets in losers bracket\n",
    "all_top_8_no_bracket_name_df_2 = pd.concat([top_8_no_bracket_name_df, last_l_sets]).sort_index()\n",
    "all_top_8_no_bracket_name_df_2.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_8_no_bracket_name_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_8_no_bracket_name_df.equals(all_top_8_no_bracket_name_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now handle the tournaments with a bracket name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for tournaments with a non-empty 'bracket_name'\n",
    "valid_tournament_sets_with_bracket_df = valid_tournament_sets_df[valid_tournament_sets_df['bracket_name'] != \"\"]\n",
    "\n",
    "gf_rows = valid_tournament_sets_with_bracket_df[valid_tournament_sets_with_bracket_df['location_names'] == 'GF']\n",
    "\n",
    "gf_bracket_names = gf_rows[['tournament_key', 'bracket_name']]\n",
    "\n",
    "# Merge to get the final bracket sets\n",
    "tournament_sets_final_bracket_df = valid_tournament_sets_with_bracket_df.reset_index().merge(\n",
    "    gf_bracket_names,\n",
    "    on=['tournament_key', 'bracket_name'],\n",
    "    how='inner',\n",
    "    # indicatorbool=True\n",
    ").set_index('index')\n",
    "\n",
    "# Define top_8 locations (excluding L{n})\n",
    "top_8_locations = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']\n",
    "\n",
    "# Filter sets with those location_names for top_8\n",
    "top_8_with_bracket_name_df = tournament_sets_final_bracket_df[tournament_sets_final_bracket_df['location_names'].isin(top_8_locations)]\n",
    "\n",
    "# Filter for rows where location_names start with 'L'\n",
    "losers_sets_df = tournament_sets_final_bracket_df[tournament_sets_final_bracket_df['location_names'].str.startswith('L')]\n",
    "\n",
    "# Sort by 'tournament_key' and 'location_names'\n",
    "losers_sets_df = losers_sets_df.sort_values(['tournament_key', 'location_names'])\n",
    "\n",
    "# Select the 5th and 6th last rows from each group in one go\n",
    "last_l_sets = losers_sets_df.groupby('tournament_key').nth([-6, -5])\n",
    "\n",
    "# Combine the filtered top_8 sets with the last sets in losers bracket\n",
    "all_top_8_with_bracket_name_df = pd.concat([top_8_with_bracket_name_df, last_l_sets]).sort_index()\n",
    "\n",
    "all_top_8_with_bracket_name_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the WF, LF, and LSF to have the same value counts. We expect LQF and WSF to have the same value count which should be double that of the previous three. We see that this is not the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_8_with_bracket_name_df['location_names'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check to see if any location names are missing in each tournament. As we see, all looks good here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']\n",
    "\n",
    "for location in locations:\n",
    "    # Check if each tournament has at least one \"WF\" in the location_names\n",
    "    tournaments_with_wf = valid_tournament_sets_no_bracket_df[\n",
    "        valid_tournament_sets_no_bracket_df['location_names'] == location\n",
    "    ]['tournament_key'].unique()\n",
    "\n",
    "    # Check if all tournament_keys are represented in tournaments_with_wf\n",
    "    all_tournaments_have_wf = set(valid_tournament_sets_no_bracket_df['tournament_key'].unique()) <= set(tournaments_with_wf)\n",
    "\n",
    "    if all_tournaments_have_wf:\n",
    "        print(f\"All tournaments have at least one {location} set.\")\n",
    "    else:\n",
    "        print(f\"At least one tournaments is missing a {location} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['WF', 'LSF', 'LF', 'GF']\n",
    "for location in locations:\n",
    "    # Count the occurrences of \"GF\" in location_names for each tournament\n",
    "    gf_counts = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'] == \"GF\"].groupby('tournament_key').size()\n",
    "\n",
    "    # Identify tournaments with exactly two \"GF\" sets\n",
    "    tournaments_with_gfr = gf_counts[gf_counts > 1].index.tolist()\n",
    "\n",
    "    print(f'There are {len(tournaments_with_gfr)} tournaments with more than one {location} sets.')\n",
    "    \n",
    "print()\n",
    "\n",
    "locations = ['WSF']\n",
    "for location in locations:\n",
    "    # Count the occurrences of \"GF\" in location_names for each tournament\n",
    "    gf_counts = valid_tournament_sets_no_bracket_df[valid_tournament_sets_no_bracket_df['location_names'] == \"GF\"].groupby('tournament_key').size()\n",
    "\n",
    "    # Identify tournaments with exactly two \"GF\" sets\n",
    "    tournaments_with_gfr = gf_counts[gf_counts != 2].index.tolist()\n",
    "\n",
    "    print(f'There are {len(tournaments_with_gfr)} tournaments without two {location} sets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do: Figure out why we don't always get the right number of location_names in a tournament.\n",
    "\n",
    "<span style=\"color:red\">To Do: For some reason, at least one tournament in the dataframe only has one Ln game. I don't know what that is about and need to investigate it. I lost which tournament it was.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put both dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8_sets = pd.concat([all_top_8_with_bracket_name_df, all_top_8_no_bracket_name_df])\n",
    "top_8_sets.sort_index(inplace=True)\n",
    "top_8_sets.head(20)\n",
    "# These are all the top 8 sets, including the ones without the bracket structure we are looking for\n",
    "top_8_sets.to_pickle(data_path + 'top_8_sets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad tournaments\n",
    "Check for tournaments without the right number of sets in each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tournament_keys = []\n",
    "\n",
    "# These location_names should only occur once in the top 8 of each tournament\n",
    "locations = ['WF', 'LSF', 'LF', 'GF']\n",
    "\n",
    "for location in locations:\n",
    "    # Count the occurrences of location in location_names for each tournament\n",
    "    location_counts = top_8_sets[top_8_sets['location_names'] == location].groupby('tournament_key').size()\n",
    "\n",
    "    # Identify tournaments without exactly two location sets\n",
    "    bad_tournaments_wrt_location = location_counts[location_counts != 1].index.tolist()\n",
    "    \n",
    "    print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly one {location} sets.')\n",
    "    print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "    \n",
    "    bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "print()\n",
    "\n",
    "\n",
    "# This location_names should only occur exactly twice in the top 8 of each tournament\n",
    "locations = ['WSF', 'LQF']\n",
    "for location in locations:\n",
    "    # Count the occurrences of location in location_names for each tournament\n",
    "    location_counts = top_8_sets[top_8_sets['location_names'] == location].groupby('tournament_key').size()\n",
    "\n",
    "    # Identify tournaments without exactly two location sets\n",
    "    bad_tournaments_wrt_location = location_counts[location_counts != 2].index.tolist()\n",
    "\n",
    "    print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly two {location} sets.')\n",
    "    print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "    \n",
    "    bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "print()\n",
    "\n",
    "# There should be exactly two sets with different location_name than these\n",
    "locations = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']\n",
    "\n",
    "for location in locations:\n",
    "    # Count the occurrences of location in location_names for each tournament\n",
    "    location_counts = top_8_sets[~ top_8_sets['location_names'].isin(locations)].groupby('tournament_key').size()\n",
    "\n",
    "    # Identify tournaments without exactly two location sets\n",
    "    bad_tournaments_wrt_location = location_counts[location_counts != 2].index.tolist()\n",
    "\n",
    "    print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly two Ln sets.')\n",
    "    print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "    \n",
    "    bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "\n",
    "# Delete duplicates\n",
    "bad_tournament_keys = list(dict.fromkeys(bad_tournament_keys))\n",
    "print(bad_tournament_keys)\n",
    "\n",
    "print(f\"There are {top_8_sets['tournament_key'].unique().shape[0]} - {len(bad_tournament_keys)} = {top_8_sets['tournament_key'].unique().shape[0] - len(bad_tournament_keys)} tournaments remaininng.\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what is going on with one of the bad tournaments. https://www.start.gg/tournament/-1340/events\n",
    "\n",
    "As we can see, the tournament structure is not what we are looking for.\n",
    "\n",
    "![alt text](top_8_1340.png \"Top 8 Bracket of 1340\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the tournaments from top_8_sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of tournament keys we are going to keep.\n",
    "good_tournament_keys = [key for key in top_8_sets['tournament_key'].unique() if key not in bad_tournament_keys]\n",
    "print(f\"There are {len(good_tournament_keys)} good tournament keys and {len(bad_tournament_keys)} bad tournament keys.\")\n",
    "\n",
    "good_top_8_sets = top_8_sets[top_8_sets['tournament_key'].isin(good_tournament_keys)].copy()\n",
    "print(f\"We had {top_8_sets.shape[0]} top 8 sets and are left with {good_top_8_sets.shape[0]} good top 8 sets.\")\n",
    "print()\n",
    "\n",
    "print(good_top_8_sets['location_names'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_tournament_keys = []\n",
    "\n",
    "# Get all tournament keys\n",
    "tournament_keys = top_8_sets['tournament_key'].unique()\n",
    "\n",
    "# These location_names should occur exactly once in the top 8 of each tournament\n",
    "locations_single = ['WF', 'LSF', 'LF', 'GF']\n",
    "\n",
    "for location in locations_single:\n",
    "    # Count the occurrences of location in location_names for each tournament\n",
    "    location_counts = top_8_sets[top_8_sets['location_names'] == location].groupby('tournament_key').size()\n",
    "\n",
    "    # Reindex to include all tournaments, filling missing counts with zero\n",
    "    location_counts = location_counts.reindex(tournament_keys, fill_value=0)\n",
    "    \n",
    "    # Identify tournaments without exactly one occurrence\n",
    "    bad_tournaments_wrt_location = location_counts[location_counts != 1].index.tolist()\n",
    "    \n",
    "    # print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly one {location} set.')\n",
    "    # print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "    \n",
    "    bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "\n",
    "# For 'GFR', the total per tournament should be either 0 or 1\n",
    "gfr_counts = top_8_sets[top_8_sets['location_names'].isin(['GFR'])].groupby('tournament_key').size()\n",
    "\n",
    "# Reindex and fill missing counts with zero\n",
    "gfr_counts = gfr_counts.reindex(tournament_keys, fill_value=0)\n",
    "\n",
    "# Identify tournaments where total GF + GFR is not 1 or 2\n",
    "bad_tournaments_wrt_gfr = gfr_counts[~gfr_counts.isin([0, 1])].index.tolist()\n",
    "\n",
    "# print(f'There are {len(bad_tournaments_wrt_gf)} tournaments without exactly 1 or 2 GF/GFR sets.')\n",
    "# print(f'The bad tournaments are {bad_tournaments_wrt_gf[:3]}')\n",
    "\n",
    "bad_tournament_keys.extend(bad_tournaments_wrt_gfr)\n",
    "\n",
    "# These location_names should only occur exactly twice in the top 8 of each tournament\n",
    "locations_double = ['WSF', 'LQF']\n",
    "\n",
    "for location in locations_double:\n",
    "    location_counts = top_8_sets[top_8_sets['location_names'] == location].groupby('tournament_key').size()\n",
    "    location_counts = location_counts.reindex(tournament_keys, fill_value=0)\n",
    "    bad_tournaments_wrt_location = location_counts[location_counts != 2].index.tolist()\n",
    "    # print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly two {location} sets.')\n",
    "    # print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "    bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "\n",
    "# For the remaining location names, there should be exactly two such sets per tournament\n",
    "locations_exclude = ['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR']\n",
    "\n",
    "location_counts = top_8_sets[~top_8_sets['location_names'].isin(locations_exclude)].groupby('tournament_key').size()\n",
    "location_counts = location_counts.reindex(tournament_keys, fill_value=0)\n",
    "bad_tournaments_wrt_location = location_counts[location_counts != 2].index.tolist()\n",
    "\n",
    "# print(f'There are {len(bad_tournaments_wrt_location)} tournaments without exactly two Ln sets.')\n",
    "# print(f'The bad tournaments are {bad_tournaments_wrt_location[:3]}')\n",
    "\n",
    "bad_tournament_keys.extend(bad_tournaments_wrt_location)\n",
    "\n",
    "# Remove duplicates\n",
    "bad_tournament_keys = list(set(bad_tournament_keys))\n",
    "\n",
    "print(f\"There are {len(bad_tournament_keys)} bad tournament keys.\")\n",
    "\n",
    "# Filter out bad tournaments\n",
    "good_tournament_keys = [key for key in tournament_keys if key not in bad_tournament_keys]\n",
    "good_top_8_sets = top_8_sets[top_8_sets['tournament_key'].isin(good_tournament_keys)].copy()\n",
    "\n",
    "print(f\"We had {top_8_sets.shape[0]} top 8 sets and are left with {good_top_8_sets.shape[0]} good top 8 sets.\")\n",
    "print()\n",
    "print(good_top_8_sets['location_names'].value_counts())\n",
    "ln_set_count = (~good_top_8_sets['location_names'].isin(['WSF', 'LQF', 'WF', 'LSF', 'LF', 'GF', 'GFR'])).sum()\n",
    "print(f\"Ln   {ln_set_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the top 8 sets from tournaments with the correct bracket stricture\n",
    "good_top_8_sets.to_pickle(data_path + 'good_top_8_sets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the top 8 sets we will use for training.\n",
    "This is how you would use the saved data frames to add the column to the data. You cannot have reset the original index of sets_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_top_8_sets = pd.read_pickle(data_path + 'good_top_8_sets.pkl')\n",
    "\n",
    "# Get the indices as a list\n",
    "indices = list(good_top_8_sets.index)\n",
    "\n",
    "# Copy the dataframe you wish to label\n",
    "labelled_sets_df = sets_df.copy()\n",
    "\n",
    "# Initialize the 'top_8' column with False\n",
    "labelled_sets_df['good_top_8'] = False\n",
    "\n",
    "# Set 'top_8' to True at the specified indices\n",
    "labelled_sets_df.loc[indices, 'good_top_8'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
