{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "if os.path.exists('/workspace/data'):\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    data_path = '/workspace/data/'\n",
    "else:\n",
    "    data_path = '../data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SQLite Database into Pandas DataFrames\n",
    "\n",
    "The following code connects to an SQLite database (`melee_player_database.db`) and converts each table within the database into a pandas DataFrame. The DataFrames will be stored in a dictionary, where each key corresponds to the table name with `_df` appended, and the values are the respective DataFrames.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Database Connection**: We use the `sqlite3` library to connect to the SQLite database file.\n",
    "2. **Retrieve Table Names**: A query retrieves all the table names in the database.\n",
    "3. **Convert Tables to DataFrames**: For each table:\n",
    "   - The table is loaded into a pandas DataFrame using `pd.read_sql()`.\n",
    "   - We check each column to see if any data is JSON-formatted (lists or dictionaries). If so, we convert these columns from strings into their corresponding Python objects using `json.loads()`.\n",
    "4. **Store DataFrames**: The DataFrames are stored in a dictionary, where the key is the table name with a `_df` suffix, and the value is the DataFrame.\n",
    "5. **Database Connection Closed**: Once all tables are loaded into DataFrames, the database connection is closed.\n",
    "\n",
    "### Example:\n",
    "If the database contains a table named `players`, the corresponding DataFrame will be stored in the dictionary with the key `players_df`, and can be accessed as:\n",
    "\n",
    "```python\n",
    "players_df = dfs['players_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "if os.path.exists(data_path + 'dfs_dict.pkl'):\n",
    "    cell_has_run = True\n",
    "    # Load the dictionary of DataFrames from the pickle\n",
    "    with open(data_path + 'dfs_dict.pkl', 'rb') as f:\n",
    "        dfs = pickle.load(f)\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = + data_path + \"melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we adjust the data types of the dataframes so that they are the correct type. (This will be updated as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sets_df']['best_of'] = dfs['sets_df']['best_of'].fillna(0).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the dictionary of DataFrames as a pickle\n",
    "# with open(data_path + 'dfs_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we make dataframes that we will use and print the head.\n",
    "\n",
    "The integers in 'characters' count the number of games the player has played that character. (We verify this for Zain below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs['players_df']\n",
    "players_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = dfs['ranking_df']\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "ranking_seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df = dfs['sets_df']\n",
    "print(f\"{sets_df[sets_df['game_data'].apply(lambda x: len(x) > 0)].shape[0] / sets_df.shape[0]:0.01%} percent of sets have some game data\")\n",
    "sets_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = dfs['tournament_info_df']\n",
    "print(tournament_info_df.shape)\n",
    "tournament_info_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Glicko-2 Exploration ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import weekly updated Glicko-2 rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ratings_df = pd.read_pickle(data_path + 'overall_players_ranking_new_weekly.pkl')\n",
    "print(player_ratings_df.shape)\n",
    "player_ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Glicko-2 updates\n",
    "Running total of number of updates to each players glicko-2 rating. We use numba njit and prange to speed up the loops in the function. We save the results so that we only need to run the calculation once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "@njit(parallel=True)\n",
    "def previous_updates(array):\n",
    "    \"\"\" This funcion returns an array like array with the number of times the value above i,j entry of array has changed.\n",
    "    Args:\n",
    "        array (np): the array\n",
    "\n",
    "    Returns:\n",
    "        np: the number of times array has changed above the i,j entry\n",
    "    \"\"\"\n",
    "    previous_updates = np.zeros_like(array, dtype=np.int32)\n",
    "    \n",
    "    for i in prange(1, array.shape[0]-1): # row i\n",
    "        previous_row = array[i-1,:]\n",
    "        # print(previous_row)\n",
    "        current_row = array[i,:]\n",
    "        # print(current_row)\n",
    "        change = (previous_row != current_row).astype(np.int32)\n",
    "        change\n",
    "\n",
    "        previous_updates[i+1,:] = previous_updates[i,:] + change\n",
    "\n",
    "    return previous_updates\n",
    "\n",
    "## Testing array\n",
    "# array = np.array([\n",
    "#     [1, 1, 1],\n",
    "#     [1, 1, 2],\n",
    "#     [1, 2, 3],\n",
    "#     [1, 3, 4]])\n",
    "\n",
    "# print(array)\n",
    "# previous_updates(array)\n",
    "# print(previous_updates(array))\n",
    "\n",
    "# # Do the calculation once.\n",
    "# player_ratings_np = player_ratings_df.to_numpy()\n",
    "# start = time.time()\n",
    "# number_of_rating_updates_df = pd.DataFrame(columns=player_ratings_df.columns, index=player_ratings_df.index, data=previous_updates(player_ratings_np))\n",
    "# end = time.time()\n",
    "# print(f'time = {end-start:.2f}')\n",
    "# number_of_rating_updates_df.head()\n",
    "\n",
    "# # Save the results\n",
    "# number_of_rating_updates_df.to_pickle(data_path + 'number_of_rating_updates_df.pkl')\n",
    "\n",
    "## Load the results\n",
    "number_of_rating_updates_df = pd.read_pickle(data_path + 'number_of_rating_updates_df.pkl')\n",
    "number_of_rating_updates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some columns to sets_df\n",
    "We add the start of the tournament, the player ratings at the start of the tournament, and the number of times the player's rating has been updated before the start of the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a merge on 'key' and 'tournament_key' to bring 'start' dates into sets_df\n",
    "merged_df = sets_df.merge(tournament_info_df[['key', 'start']], left_on='tournament_key', right_on='key', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "import swifter\n",
    "\n",
    "# Function to get both Player 1 and Player 2 ratings and the number of rating updates\n",
    "def get_ratings_and_updates(row, player_ratings_df, number_of_rating_updates_df):\n",
    "    # Find the closest date in player_ratings_df that is <= 'start' date\n",
    "    closest_date = player_ratings_df.index[player_ratings_df.index <= row['start']].max()\n",
    "    \n",
    "    # If there's no valid date, return None for ratings and updates\n",
    "    if pd.isnull(closest_date):\n",
    "        return pd.Series([None, None, None, None], index=['p1_rating', 'p2_rating', 'p1_updates', 'p2_updates'])\n",
    "    \n",
    "    # Fetch Player 1's and Player 2's ratings on the closest date\n",
    "    p1_rating = player_ratings_df.loc[closest_date, row['p1_id']] if row['p1_id'] in player_ratings_df.columns else None\n",
    "    p2_rating = player_ratings_df.loc[closest_date, row['p2_id']] if row['p2_id'] in player_ratings_df.columns else None\n",
    "    \n",
    "    # Fetch Player 1's and Player 2's number of rating updates on the closest date\n",
    "    p1_updates = number_of_rating_updates_df.loc[closest_date, row['p1_id']] if row['p1_id'] in number_of_rating_updates_df.columns else None\n",
    "    p2_updates = number_of_rating_updates_df.loc[closest_date, row['p2_id']] if row['p2_id'] in number_of_rating_updates_df.columns else None\n",
    "    \n",
    "    # Return all values as a pandas Series\n",
    "    return pd.Series([p1_rating, p2_rating, p1_updates, p2_updates], \n",
    "                     index=['p1_rating', 'p2_rating', 'p1_updates', 'p2_updates'])\n",
    "\n",
    "# Apply the function to each row in merged_df\n",
    "# merged_df[['p1_rating', 'p2_rating', 'p1_updates', 'p2_updates']] = merged_df.progress_apply(\n",
    "#     get_ratings_and_updates, axis=1, \n",
    "#     player_ratings_df=player_ratings_df, \n",
    "#     number_of_rating_updates_df=number_of_rating_updates_df,\n",
    "# )\n",
    "\n",
    "# Save\n",
    "# merged_df.to_pickle(data_path + 'augmented_sets_df.pkl')\n",
    "\n",
    "# # Load\n",
    "augmented_sets_df = pd.read_pickle(data_path + 'augmented_sets_df.pkl')\n",
    "augmented_sets_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 8 Locations\n",
    "Here we look for what the sets corresponding to the top 8 of a tournament are labeled as in the column 'location_names'. We do this by inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where 'location_names' exactly matches ['GF', 'Grand Final', 'Grand Final']\n",
    "gf_sets_df = sets_df[sets_df['location_names'].apply(lambda x: x == ['GF', 'Grand Final', 'Grand Final'])]\n",
    "\n",
    "# Extract the tournament keys for the Grand Finals\n",
    "gf_tournament_keys = list(gf_sets_df['tournament_key'])\n",
    "\n",
    "# Filter the sets_df to include only the sets from tournaments that had Grand Finals\n",
    "valid_tournament_sets_df = sets_df[sets_df['tournament_key'].isin(gf_tournament_keys)]\n",
    "\n",
    "# Display the result\n",
    "print(valid_tournament_sets_df['location_names'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sets_df['location_names'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all top 8 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vast majority of the top 8 games have these \"location_names\"\n",
    "top_8_locations = [\n",
    "        ['WQF', 'Winners Quarters', 'Winners Quarter-Final'],                                   \n",
    "        ['WSF', 'Winners Semis', 'Winners Semi-Final'],\n",
    "        ['LQF', 'Losers Quarters', 'Losers Quarter-Final'],\n",
    "        ['WF', 'Winners Final', 'Winners Final'],\n",
    "        ['LSF', 'Losers Semis', 'Losers Semi-Final'],\n",
    "        ['LF', 'Losers Final', 'Losers Final'],\n",
    "        ['GF', 'Grand Final', 'Grand Final'],\n",
    "        ['GFR', 'GF Reset', 'Grand Final Reset']\n",
    "    ] \n",
    "\n",
    "top_8_sets_df = augmented_sets_df[augmented_sets_df[\"location_names\"].isin(top_8_locations)]\n",
    "top_8_tournament_keys = top_8_sets_df['tournament_key'].unique()\n",
    "print(f\"There are {len(top_8_tournament_keys)} tournaments with double elimination finals.\")\n",
    "top_8_sets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict our data set to tournaments that have the double elimination format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df = augmented_sets_df[augmented_sets_df['tournament_key'].isin(top_8_tournament_keys)]\n",
    "non_top_8_sets_df = tournament_sets_with_top_8_df[~ tournament_sets_with_top_8_df['location_names'].isin(top_8_locations)]\n",
    "non_top_8_sets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the top_8_locations to a single list of all location name variations\n",
    "top_8_flat_list = [location for sublist in top_8_locations for location in sublist]\n",
    "\n",
    "# Add a 'top_8' column based on whether 'location_names' matches any entry in the top_8_flat_list\n",
    "tournament_sets_with_top_8_df.loc[:,'top_8'] = tournament_sets_with_top_8_df['location_names'].apply(\n",
    "    lambda locations: any(location in top_8_flat_list for location in locations)\n",
    ")\n",
    "\n",
    "tournament_sets_with_top_8_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df.groupby('top_8')['p1_rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df.groupby('top_8')['p2_rating'].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df.groupby('top_8')['p1_updates'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df.groupby('top_8')['p2_updates'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column with the absolute rating difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_sets_with_top_8_df['rating_difference'] = np.abs(tournament_sets_with_top_8_df['p1_rating'] - tournament_sets_with_top_8_df['p2_rating'])\n",
    "tournament_sets_with_top_8_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['rating_difference'] > 0], x='rating_difference', col='top_8', kind='violin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a deep copy of the dataframe to avoid the warning\n",
    "tournament_sets_with_top_8_df = tournament_sets_with_top_8_df.copy()\n",
    "tournament_sets_with_top_8_df = tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['rating_difference'] > 1]\n",
    "\n",
    "# Now safely create the 'higher_rated_won' column\n",
    "tournament_sets_with_top_8_df['higher_rated_won'] = (\n",
    "    ((tournament_sets_with_top_8_df['winner_id'] == tournament_sets_with_top_8_df['p1_id']) & \n",
    "     (tournament_sets_with_top_8_df['p1_rating'] > tournament_sets_with_top_8_df['p2_rating'])) |\n",
    "    ((tournament_sets_with_top_8_df['winner_id'] == tournament_sets_with_top_8_df['p2_id']) & \n",
    "     (tournament_sets_with_top_8_df['p2_rating'] > tournament_sets_with_top_8_df['p1_rating']))\n",
    ")\n",
    "print(tournament_sets_with_top_8_df.shape)\n",
    "# tournament_sets_with_top_8_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall rating baseline: {tournament_sets_with_top_8_df['higher_rated_won'].sum() / tournament_sets_with_top_8_df.shape[0]:.2%}\")\n",
    "\n",
    "top_8_df = tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['top_8'] == True]\n",
    "print(f\"Top 8 rating baseline: {top_8_df['higher_rated_won'].sum() / top_8_df.shape[0]:.2%}\")\n",
    "non_top_8_df = tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['top_8'] == False]\n",
    "print(f\"Non top 8 rating baseline: {non_top_8_df['higher_rated_won'].sum() / non_top_8_df.shape[0]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now safely create the 'higher_rated_won' column\n",
    "tournament_sets_with_top_8_df['more_updates_won'] = (\n",
    "    ((tournament_sets_with_top_8_df['winner_id'] == tournament_sets_with_top_8_df['p1_id']) & \n",
    "     (tournament_sets_with_top_8_df['p1_updates'] > tournament_sets_with_top_8_df['p2_updates'])) |\n",
    "    ((tournament_sets_with_top_8_df['winner_id'] == tournament_sets_with_top_8_df['p2_id']) & \n",
    "     (tournament_sets_with_top_8_df['p2_updates'] > tournament_sets_with_top_8_df['p1_updates']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8_df = tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['top_8'] == True]\n",
    "print(f\"Top 8 updates baseline: {top_8_df['more_updates_won'].sum() / top_8_df.shape[0]:.0%}\")\n",
    "non_top_8_df = tournament_sets_with_top_8_df[tournament_sets_with_top_8_df['top_8'] == False]\n",
    "print(f\"Non top 8 updates baseline: {non_top_8_df['more_updates_won'].sum() / non_top_8_df.shape[0]:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now safely create the 'higher_rated_won' column\n",
    "tournament_sets_with_top_8_df['p1_won'] = (tournament_sets_with_top_8_df['winner_id'] == tournament_sets_with_top_8_df['p1_id']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Player 1 won {tournament_sets_with_top_8_df['p1_won'].sum() / tournament_sets_with_top_8_df.shape[0]:.1%} of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tournament_sets_with_top_8_df.to_pickle(data_path + 'tournament_sets_with_top_8_df.pkl')="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.minimum(top_8_df['p2_updates'], top_8_df['p1_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask]['higher_rated_won'].sum() / masked_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) >= updates) & (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask]['higher_rated_won'].sum() / masked_non_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Accuracy of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Accuracy of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Min Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 500, 50))  # Matches your `rating_difference` range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.minimum(top_8_df['p1_updates'], top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask]['higher_rated_won'].sum() / masked_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) >= updates) & (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask]['higher_rated_won'].sum() / masked_non_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Accuracy of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Accuracy of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Min Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 100, 10))  # Matches your `rating_difference` range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask]['higher_rated_won'].sum() / masked_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) >= updates) & (np.maximum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask]['higher_rated_won'].sum() / masked_non_top_8[difference_mask].shape[0] * 100)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Accuracy of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Accuracy of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}%', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Max Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 100, 10))  # Matches your `rating_difference` range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.minimum(top_8_df['p1_updates'], top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask].shape[0])\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) >= updates) & (np.minimum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask].shape[0])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Set Count of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Set Count of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Min Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 500, 50))  # Matches your `rating_difference` range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask].shape[0])\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) >= updates) & (np.maximum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,500, 50)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 50)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask].shape[0])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Set Count of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Set Count of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Max Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 500, 50))  # Matches your `rating_difference` range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_of_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) >= updates) & (np.maximum(top_8_df['p1_updates'], top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_top_8 = top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_top_8['rating_difference'] >= difference) & (masked_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_top_8[j,i] = int(masked_top_8[difference_mask].shape[0])\n",
    "\n",
    "accuracy_of_non_top_8 = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "for i, updates in enumerate(range(0, 50, 5)):\n",
    "    updates_mask = (np.maximum(non_top_8_df['p2_updates'], non_top_8_df['p2_updates']) >= updates) & (np.maximum(non_top_8_df['p1_updates'], non_top_8_df['p2_updates']) < updates + 5)\n",
    "    masked_non_top_8 = non_top_8_df[updates_mask]\n",
    "    for j, difference in enumerate(range(0,100, 10)):\n",
    "        difference_mask = (masked_non_top_8['rating_difference'] >= difference) & (masked_non_top_8['rating_difference'] < difference + 10)\n",
    "        accuracy_of_non_top_8[j,i] = int(masked_non_top_8[difference_mask].shape[0])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Heatmap for top 8\n",
    "cax1 = axs[0].imshow(accuracy_of_top_8, cmap='Blues', aspect='auto')\n",
    "axs[0].set_title('Set Count of Top 8')\n",
    "\n",
    "# Annotating values in the cells for top 8\n",
    "for i in range(accuracy_of_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_top_8.shape[1]):\n",
    "        axs[0].text(j, i, f'{accuracy_of_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap for non-top 8\n",
    "cax2 = axs[1].imshow(accuracy_of_non_top_8, cmap='Blues', aspect='auto')\n",
    "axs[1].set_title('Set Count of Non-Top 8')\n",
    "\n",
    "# Annotating values in the cells for non-top 8\n",
    "for i in range(accuracy_of_non_top_8.shape[0]):\n",
    "    for j in range(accuracy_of_non_top_8.shape[1]):\n",
    "        axs[1].text(j, i, f'{accuracy_of_non_top_8[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "# Set labels and ticks for both heatmaps\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Max Updates to Rating')  # This is correct for the y-axis\n",
    "    ax.set_ylabel('Rating Difference')  # This should be the x-axis label\n",
    "    ax.set_xticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_yticks(np.arange(0, 10))  # These ticks are fine\n",
    "    ax.set_xticklabels(np.arange(0, 50, 5))  # Matches your `updates` range\n",
    "    ax.set_yticklabels(np.arange(0, 100, 10))  # Matches your `rating_difference` range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Ranked Player Wins Tournament\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_8_tournament_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournaments_with_top_8_df = tournament_info_df[tournament_info_df['key'].isin(top_8_tournament_keys)]\n",
    "print(tournaments_with_top_8_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tournaments_with_top_8_df['placings'].iloc[4]))\n",
    "tournaments_with_top_8_df['placings'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tournaments_with_top_8_df['placings'].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract the top 3 player IDs from the 'placings' list, handling None values\n",
    "def extract_top_3(placings):\n",
    "    # Check if placings is None or an empty list\n",
    "    if placings is None or len(placings) == 0:\n",
    "        return pd.Series([None, None, None], index=['1', '2', '3'])\n",
    "    \n",
    "    # Filter out invalid entries (ensure they are lists of length 2 with valid player_id and rank)\n",
    "    valid_placings = [p for p in placings if isinstance(p, list) and len(p) == 2 and isinstance(p[1], int)]\n",
    "    \n",
    "    # Sort the valid placings based on the rank (second element in each sublist)\n",
    "    sorted_placings = sorted(valid_placings, key=lambda x: x[1])\n",
    "    \n",
    "    # Extract the player IDs of the top 3 (if available)\n",
    "    top_3 = [p[0] for p in sorted_placings[:3]]\n",
    "    \n",
    "    # If there are less than 3 players, fill the remaining spots with None\n",
    "    while len(top_3) < 3:\n",
    "        top_3.append(None)\n",
    "    \n",
    "    return pd.Series(top_3, index=['1', '2', '3'])\n",
    "\n",
    "# Apply the function to extract top 3 players to the 'placings' column\n",
    "top_3_df = tournaments_with_top_8_df[['key', 'placings']].copy()\n",
    "top_3_df[['1', '2', '3']] = top_3_df['placings'].apply(extract_top_3)\n",
    "\n",
    "# Drop the 'placings' column, as we only need the 'key' and top 3 player IDs\n",
    "top_3_df = top_3_df.drop(columns=['placings'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "top_3_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8_sets_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_8_locations = [\n",
    "        ['WSF', 'Winners Semis', 'Winners Semi-Final'],\n",
    "        ['LQF', 'Losers Quarters', 'Losers Quarter-Final'],\n",
    "        ['LSF', 'Losers Semis', 'Losers Semi-Final'],\n",
    "        ['WF', 'Winners Final', 'Winners Final'],\n",
    "        ['LF', 'Losers Final', 'Losers Final'],\n",
    "        ['GF', 'Grand Final', 'Grand Final'],\n",
    "        ['GFR', 'GF Reset', 'Grand Final Reset']\n",
    "    ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = sets_df[sets_df['tournament_key'] == 's@sh7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df.shape)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "losers_1_player_df = temp_df[temp_df['p1_id'] == 'lain']\n",
    "losers_2_player_df = temp_df[temp_df['p2_id'] == 'lain']\n",
    "losers_player_df = pd.concat([losers_1_player_df,losers_2_player_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losers_player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['location_names'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
