{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "from glicko2 import Player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SQLite Database into Pandas DataFrames\n",
    "\n",
    "The following code connects to an SQLite database (`melee_player_database.db`) and converts each table within the database into a pandas DataFrame. The DataFrames will be stored in a dictionary, where each key corresponds to the table name with `_df` appended, and the values are the respective DataFrames.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Database Connection**: We use the `sqlite3` library to connect to the SQLite database file.\n",
    "2. **Retrieve Table Names**: A query retrieves all the table names in the database.\n",
    "3. **Convert Tables to DataFrames**: For each table:\n",
    "   - The table is loaded into a pandas DataFrame using `pd.read_sql()`.\n",
    "   - We check each column to see if any data is JSON-formatted (lists or dictionaries). If so, we convert these columns from strings into their corresponding Python objects using `json.loads()`.\n",
    "4. **Store DataFrames**: The DataFrames are stored in a dictionary, where the key is the table name with a `_df` suffix, and the value is the DataFrame.\n",
    "5. **Database Connection Closed**: Once all tables are loaded into DataFrames, the database connection is closed.\n",
    "\n",
    "### Example:\n",
    "If the database contains a table named `players`, the corresponding DataFrame will be stored in the dictionary with the key `players_df`, and can be accessed as:\n",
    "\n",
    "```python\n",
    "players_df = dfs['players_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = \"../data/melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we adjust the data types of the dataframes so that they are the correct type. (This will be updated as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sets_df']['best_of'] = dfs['sets_df']['best_of'].fillna(0).astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we make dataframes that we will use and print the head.\n",
    "\n",
    "The integers in 'characters' count the number of games the player has played that character. (We verify this for Zain below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs['players_df']\n",
    "players_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = dfs['ranking_df']\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "ranking_seasons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_df = dfs['sets_df']\n",
    "print(f'{sets_df[sets_df['game_data'].apply(lambda x: len(x) > 0)].shape[0] / sets_df.shape[0]:0.01%} percent of sets have some game data')\n",
    "sets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_info_df = dfs['tournament_info_df']\n",
    "tournament_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tournament(tournament_key, player_ratings_df, tournament_info_df, sets_df):\n",
    "    \"\"\"\n",
    "    Process a tournament to update player ratings.\n",
    "    \"\"\"\n",
    "    # Get the sets for this tournament\n",
    "    tournament_sets_df = sets_df[sets_df['tournament_key'] == tournament_key]\n",
    "    \n",
    "    # Extract the unique player IDs from the sets\n",
    "    tournament_players = pd.unique(tournament_sets_df[['p1_id', 'p2_id']].values.ravel())\n",
    "    \n",
    "    # Add any new players to the player_ratings_df\n",
    "    new_players = [player for player in tournament_players if player not in player_ratings_df.index]\n",
    "    if new_players:\n",
    "        new_player_df = pd.DataFrame({\n",
    "            'dates': [[] for _ in new_players],\n",
    "            'rating_history': [[] for _ in new_players],\n",
    "            'rd_history': [[] for _ in new_players],\n",
    "            'glicko2': [Player() for _ in new_players]\n",
    "        }, index=new_players)\n",
    "        player_ratings_df = pd.concat([player_ratings_df, new_player_df], ignore_index=False)\n",
    "    \n",
    "    # Ensure the index name is set to 'player_id'\n",
    "    player_ratings_df.index.name = 'player_id'\n",
    "    \n",
    "    # Create a mapping from player_id to their Glicko2 player object\n",
    "    player_map = player_ratings_df['glicko2'].to_dict()\n",
    "    \n",
    "    # Create a snapshot of ratings before the tournament\n",
    "    ratings_snapshot = player_ratings_df[['glicko2']].copy()\n",
    "    ratings_snapshot['rating'] = ratings_snapshot['glicko2'].apply(lambda x: x.getRating())\n",
    "    ratings_snapshot['rd'] = ratings_snapshot['glicko2'].apply(lambda x: x.getRd())\n",
    "    # Add 'opponent_id' column from the index\n",
    "    ratings_snapshot.reset_index(inplace=True)\n",
    "    ratings_snapshot.rename(columns={'player_id': 'opponent_id'}, inplace=True)\n",
    "    ratings_snapshot = ratings_snapshot[['opponent_id', 'rating', 'rd']]\n",
    "    \n",
    "    # Prepare player matches DataFrame\n",
    "    df_p1 = tournament_sets_df[['p1_id', 'p2_id', 'winner_id']].copy()\n",
    "    df_p1.rename(columns={'p1_id': 'player_id', 'p2_id': 'opponent_id'}, inplace=True)\n",
    "    df_p1['outcome'] = (df_p1['winner_id'] == df_p1['player_id']).astype(int)\n",
    "    df_p1 = df_p1[['player_id', 'opponent_id', 'outcome']]\n",
    "    \n",
    "    df_p2 = tournament_sets_df[['p2_id', 'p1_id', 'winner_id']].copy()\n",
    "    df_p2.rename(columns={'p2_id': 'player_id', 'p1_id': 'opponent_id'}, inplace=True)\n",
    "    df_p2['outcome'] = (df_p2['winner_id'] == df_p2['player_id']).astype(int)\n",
    "    df_p2 = df_p2[['player_id', 'opponent_id', 'outcome']]\n",
    "    \n",
    "    player_matches = pd.concat([df_p1, df_p2], ignore_index=True)\n",
    "    \n",
    "    # Merge to get opponent ratings and RDs\n",
    "    player_matches = player_matches.merge(\n",
    "        ratings_snapshot,\n",
    "        on='opponent_id', how='left'\n",
    "    )\n",
    "    player_matches.rename(columns={'rating': 'opponent_rating', 'rd': 'opponent_rd'}, inplace=True)\n",
    "    \n",
    "    # Group by player_id to aggregate opponent data\n",
    "    grouped = player_matches.groupby('player_id').agg({\n",
    "        'opponent_rating': list,\n",
    "        'opponent_rd': list,\n",
    "        'outcome': list\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get the tournament end date\n",
    "    end_date = tournament_info_df.loc[tournament_info_df['key'] == tournament_key, 'end'].values[0]\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    # Process each player\n",
    "    for idx, row in grouped.iterrows():\n",
    "        player_id = row['player_id']\n",
    "        rating_list = row['opponent_rating']\n",
    "        rd_list = row['opponent_rd']\n",
    "        outcome_list = row['outcome']\n",
    "        \n",
    "        # Update Glicko rating for the player\n",
    "        player_glicko = player_map[player_id]\n",
    "        if rating_list:  # Ensure the player has matches to process\n",
    "            player_glicko.update_player(rating_list, rd_list, outcome_list)\n",
    "        \n",
    "        # Update the player's history\n",
    "        player_ratings_df.at[player_id, 'dates'].append(end_date)\n",
    "        player_ratings_df.at[player_id, 'rating_history'].append(player_glicko.getRating())\n",
    "        player_ratings_df.at[player_id, 'rd_history'].append(player_glicko.getRd())\n",
    "    \n",
    "    return player_ratings_df  # Return the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tournament_info_df = tournament_info_df.sort_values('end').reset_index(drop=True)\n",
    "sorted_tournament_info_df.shape[0]\n",
    "\n",
    "# Initialize player ratings DataFrame\n",
    "player_ratings_df = pd.DataFrame(columns=[\n",
    "     'dates', 'rating_history', 'rd_history', 'glicko2'\n",
    "])\n",
    "\n",
    "# Loop over tournaments\n",
    "for idx, tournament in tqdm.tqdm(sorted_tournament_info_df.iterrows(), total=sorted_tournament_info_df.shape[0]):\n",
    "    player_ratings_df = process_tournament(tournament['key'], player_ratings_df, tournament_info_df, sets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = player_ratings_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays in the specified columns\n",
    "for col in ['dates', 'rating_history', 'rd_history']:\n",
    "    print(col)\n",
    "    player_ratings_df[col] = player_ratings_df[col].apply(np.array)\n",
    "# Save the DataFrame to a pickle file\n",
    "player_ratings_df.to_pickle('../data/overall_players_ranking.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame to verify\n",
    "loaded_df = pd.read_pickle('../data/overall_players_ranking.pkl')\n",
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rating = 0\n",
    "\n",
    "for index, row in loaded_df.iterrows():\n",
    "    index_max_rating = np.argmax(row['rating_history'].astype(int))  # Correcting the typo to `astype`\n",
    "    if row['rating_history'][index_max_rating] > max_rating:\n",
    "        best_row = row\n",
    "        best_index = index\n",
    "        max_rating = row['rating_history'][index_max_rating]\n",
    "        print(players_df[players_df['player_id'] == index]['tag'], max_rating)\n",
    "        # print(max_rating)\n",
    "\n",
    "\n",
    "        \n",
    "print(max_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df[players_df['player_id'] == best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_2024_melee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
