{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import sqlite3\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading database\n",
    "\n",
    "Due to Jaspar's code for loading the database and handling data types being a bit more robust than mine, I have decided to start this second file for data exploration from scratch, copying over the database loading code. Currently, it is used for generating a heatmap of character vs character win percentages, but might be used for more exploration later.\n",
    "\n",
    "Next couple cells are originally mostly Jaspar's - see his data exploration file for some more comments on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the table names\n",
    "def get_table_names(conn):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    return pd.read_sql(query, conn)['name'].tolist()\n",
    "\n",
    "# Function to load tables into DataFrames\n",
    "def load_tables_to_dfs(conn):\n",
    "    table_names = get_table_names(conn)\n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in table_names:\n",
    "        # Load table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table}\", conn)\n",
    "        \n",
    "        # Detect and convert JSON formatted columns (if any)\n",
    "        for col in df.columns:\n",
    "            # Check if any entry in the column is a valid JSON (list or dictionary)\n",
    "            if df[col].apply(lambda x: isinstance(x, str)).all():\n",
    "                try:\n",
    "                    # Try parsing the column as JSON\n",
    "                    df[col] = df[col].apply(lambda x: json.loads(x) if pd.notnull(x) else x)\n",
    "                except (json.JSONDecodeError, TypeError):\n",
    "                    # If it fails, skip the column\n",
    "                    pass\n",
    "        \n",
    "        # Store the DataFrame with table name + '_df'\n",
    "        dataframes[f\"{table}_df\"] = df\n",
    "        \n",
    "    return dataframes\n",
    "\n",
    "# Check if the flag variable exists in the global scope so that this code does not run twice\n",
    "if 'cell_has_run' not in globals():\n",
    "    path = \"../data/melee_player_database.db\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(path)\n",
    "\n",
    "    # Convert each table into a DataFrame\n",
    "    dfs = load_tables_to_dfs(conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "    # Now, you have a dictionary 'dfs' where each key is the table name with '_df' suffix and value is the corresponding DataFrame.\n",
    "    # For example, to access the DataFrame for a table called 'players':\n",
    "    # players_df = dfs['players_df']\n",
    "\n",
    "    dfs['tournament_info_df']['start'] = pd.to_datetime(dfs['tournament_info_df']['start'], unit='s')\n",
    "    dfs['tournament_info_df']['end'] = pd.to_datetime(dfs['tournament_info_df']['end'], unit='s')\n",
    "\n",
    "    \n",
    "    # Set the flag to indicate that the cell has been run\n",
    "    cell_has_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sets_df']['best_of'] = dfs['sets_df']['best_of'].fillna(0).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = dfs['players_df']\n",
    "ranking_df = dfs['ranking_df']\n",
    "ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "sets_df = dfs['sets_df']\n",
    "tournament_info_df = dfs['tournament_info_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the character win rates\n",
    "\n",
    "Ideally, for each individual player, we would have statistics of how well they perform playing a certain character, with their opponent also playing another given character. However, we might not have enough data for that in general, and so it might be necessary to use the global character vs. character win rates. Here, we compute those rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might not be best practice, but seems reasonably fast\n",
    "game_data = []\n",
    "\n",
    "for data in sets_df['game_data']:\n",
    "    game_data += data\n",
    "    \n",
    "game_data_df = pd.DataFrame(game_data)\n",
    "\n",
    "# melee/character -> character\n",
    "# Dunno why these aren't formatted as strings by default. I'll look into that later.\n",
    "game_data_df['loser_char'] = game_data_df['loser_char'].apply(lambda x: str(x).replace('melee/', ''))\n",
    "game_data_df['winner_char'] = game_data_df['winner_char'].apply(lambda x: str(x).replace('melee/', ''))\n",
    "\n",
    "# Data cleanup. Not 100% sure from where, but 'None' (as a string) shows up as a character sometimes.\n",
    "# Let's just remove it here.\n",
    "num_invalid = len(game_data_df[(game_data_df['loser_char'] == 'None') & (game_data_df['winner_char'] == 'None')].index)\n",
    "num_total = len(game_data_df.index)\n",
    "print(\"About {0:.2f}% of the data is invalid. Removing it.\".format(100.0 * num_invalid / num_total))\n",
    "\n",
    "game_data_df = game_data_df[(game_data_df['loser_char'] != 'None') & (game_data_df['winner_char'] != 'None')]\n",
    "\n",
    "game_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also slightly janky. Compute total character vs character wins.\n",
    "# Need a dummy column in there initially (winner_id) to get the .count() to work properly\n",
    "char_vs_char_totals_df = game_data_df[['winner_char', 'loser_char', 'winner_id']].groupby(by=['winner_char', 'loser_char']).count().unstack()\n",
    "\n",
    "# Remove that leftover winner_id, which is the top level column after the .unstack()\n",
    "char_vs_char_totals_df.columns = char_vs_char_totals_df.columns.droplevel()\n",
    "\n",
    "# Rows and columns seem to be ordered alphabetically by default\n",
    "# We can order by number of wins with that character instead\n",
    "# (should be roughly equivalent to character popularity)\n",
    "wins_df = char_vs_char_totals_df.sum(axis=1)\n",
    "wins_df = wins_df.sort_values(ascending=False)\n",
    "\n",
    "# Reorder rows and columns, respectively\n",
    "char_vs_char_totals_df = char_vs_char_totals_df.reindex(wins_df.index)\n",
    "char_vs_char_totals_df = char_vs_char_totals_df[wins_df.index]\n",
    "\n",
    "# Compute win percentages\n",
    "# Convert to float prematurely so we don't get errors about setting incompatible data types\n",
    "char_vs_char_rates_df = char_vs_char_totals_df.copy().astype(float)\n",
    "characters = list(char_vs_char_rates_df.index)\n",
    "\n",
    "for char_1 in characters:\n",
    "    for char_2 in characters:\n",
    "        wins   = char_vs_char_totals_df.loc[char_1, char_2]\n",
    "        losses = char_vs_char_totals_df.loc[char_2, char_1]\n",
    "\n",
    "        char_vs_char_rates_df.loc[char_1, char_2] = 100 * wins / (wins + losses)\n",
    "\n",
    "# For display purposes only, remove the absurd amount of decimals\n",
    "char_vs_char_rates_df.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a heatmap\n",
    "\n",
    "Here, we create a heatmap instead of just a table of numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can limit ourselves to the n most popular characters, to avoid having it be too massive\n",
    "max_chars = 30\n",
    "\n",
    "limited_df = char_vs_char_rates_df.iloc[:max_chars][char_vs_char_rates_df.columns[:max_chars]]\n",
    "limited_df\n",
    "\n",
    "sns.heatmap(limited_df, cmap='RdYlGn', center=50, xticklabels=True, yticklabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, duplicates exist for some reason or another\n",
    "players_df[players_df['tag'] == 'Hungrybox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of the day, we will have to choose mappings for duplicate ids\n",
    "# They will be stored here.\n",
    "id_mapping = {}\n",
    "\n",
    "def merge_one_tag_groupby(data):\n",
    "    # Let's slowly deal with one column at a time.\n",
    "    # game, player_id, tag, all_tags, prefixes, social, country, state, region, c_country, c_state, c_region, placings, characters, alias\n",
    "\n",
    "    # Let's make this generalizable to games other than melee\n",
    "    game = data.iloc[0]['game']\n",
    "\n",
    "    # Pick one id to be the definitive one.\n",
    "    # To keep things \"canonical\", if an ID is not numeric, pick that one.\n",
    "    # Otherwise, pick the one with the smallest numeric value.\n",
    "    #\n",
    "    # We have to keep track of mapping the rest later.\n",
    "    # Might as well map the definitive one to itself as well\n",
    "\n",
    "    player_id = None\n",
    "\n",
    "    # Search for a non-numeric ID\n",
    "    for id in data['player_id']:\n",
    "        if re.fullmatch(r'\\d+', id) is None:\n",
    "            player_id = id\n",
    "            break    \n",
    "    # All ids are numeric\n",
    "    if player_id is None:\n",
    "        ids = [int(x) for x in data['player_id']]\n",
    "        ids.sort()\n",
    "        player_id = str(ids[0])\n",
    "    # Mapping old ids -> new id\n",
    "    for id in data['player_id']:\n",
    "        id_mapping[id] = player_id\n",
    "\n",
    "    # These should all be the same anyways, if we grouped by tag\n",
    "    tag = data.iloc[0]['tag']\n",
    "\n",
    "    # We will actually repeatedly call this same function again\n",
    "    # on later dataframes that actually do have multiple tags.\n",
    "    # Hence, we will need to remember all of them.\n",
    "    all_tags = []\n",
    "    for tag_list in data['all_tags']:\n",
    "        all_tags += tag_list\n",
    "    all_tags = list(set(all_tags))\n",
    "\n",
    "    # Might as well take all unique prefixes\n",
    "    prefixes = []\n",
    "    for prefix_list in data['prefixes']:\n",
    "        prefixes += prefix_list\n",
    "    prefixes = list(set(prefixes))\n",
    "\n",
    "    # Again combine all socials into one, handling duplicates\n",
    "    # Would rather throw away a blank entry than one with info\n",
    "    social = {}\n",
    "    # TODO: Maybe actually combine lists together instead of throwing info away?\n",
    "    for social_list in data['social']:\n",
    "        for key in social_list:\n",
    "            if (key in social and social[key] == []) or key not in social:\n",
    "                social[key] = social_list[key]\n",
    "    \n",
    "    # These entries might be correlated and we can't pick the first \"non-None\" entry for each\n",
    "    # as those might correspond to different rows\n",
    "    country   = data.iloc[0]['country']\n",
    "    state     = data.iloc[0]['state']\n",
    "    region    = data.iloc[0]['region']\n",
    "    c_country = data.iloc[0]['c_country']\n",
    "    c_state   = data.iloc[0]['c_state']\n",
    "    c_region  = data.iloc[0]['c_region']\n",
    "\n",
    "    # I'm gonna assume there are no duplicates among placings for duplicate tags\n",
    "    placings = []\n",
    "    for placing_list in data['placings']:\n",
    "        placings += placing_list\n",
    "\n",
    "    # There actually might be duplicates among the character list though\n",
    "    # and we will need to compute totals among all of them\n",
    "    characters = {}\n",
    "    for character_dict in data['characters']:\n",
    "        for key in character_dict:\n",
    "            if key in characters:\n",
    "                characters[key] += character_dict[key]\n",
    "            else:\n",
    "                characters[key] = character_dict[key]\n",
    "\n",
    "    aliases = [x for x in data['alias'] if x is not None and x != 'None']\n",
    "    alias = aliases[0] if len(aliases) > 0 else None\n",
    "\n",
    "    final_dict = {'game': game,\n",
    "                  'player_id': player_id,\n",
    "                  'tag': tag,\n",
    "                  'all_tags': all_tags,\n",
    "                  'prefixes': prefixes,\n",
    "                  'social': social,\n",
    "                  'country': country,\n",
    "                  'state': state,\n",
    "                  'region': region,\n",
    "                  'c_country': c_country,\n",
    "                  'c_state': c_state,\n",
    "                  'c_region': c_region,\n",
    "                  'placings': placings,\n",
    "                  'characters': characters,\n",
    "                  'alias': alias}\n",
    "    \n",
    "    return pd.Series(final_dict)\n",
    "\n",
    "# Note that the new index is the tag, and is not numeric anymore.\n",
    "# Let's revert it back to numeric.\n",
    "# TODO: Figure out this include_groups=False nonsense\n",
    "merged_df = players_df.groupby('tag').apply(merge_one_tag_groupby)\n",
    "merged_df = merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comparison takes a few minutes. You can skip it here if you want\n",
    "PERFORM_COMMON_SETS_COMPARISON = True\n",
    "\n",
    "# Avoiding so many string comparisons speeds things up DRAMATICALLY\n",
    "def str_checksum(s):\n",
    "    return (int(hashlib.sha256(s.encode('utf-8')).hexdigest(), 16) % 9223372036854775807)\n",
    "\n",
    "def find_common_sets():\n",
    "    # As a sanity check, let's verify that the \"duplicates\" we lumped together\n",
    "    # really never played against each other\n",
    "    print(\"Hashing player ids...\")\n",
    "    p1_id_series = sets_df['p1_id'].apply(str_checksum)\n",
    "    p2_id_series = sets_df['p2_id'].apply(str_checksum)\n",
    "\n",
    "    def have_played(id1, id2):\n",
    "        result = True in ((p1_id_series == id1) & (p2_id_series == id2)).values or True in ((p1_id_series == id2) & (p2_id_series == id1)).values\n",
    "        return result\n",
    "\n",
    "    print(\"Performing comparisons...\")\n",
    "\n",
    "    total_common = 0\n",
    "\n",
    "    for i,key in enumerate(id_mapping):\n",
    "        if key == id_mapping[key]:\n",
    "            continue\n",
    "\n",
    "        if have_played(str_checksum(key), str_checksum(id_mapping[key])):\n",
    "            total_common += 1\n",
    "            print(\"Total of {0} at i={1}\".format(total_common, i))\n",
    "        \n",
    "        # print(i)\n",
    "\n",
    "    print(\"Total of {0}\".format(total_common))\n",
    "\n",
    "if PERFORM_COMMON_SETS_COMPARISON:\n",
    "    find_common_sets()\n",
    "\n",
    "#players_df = dfs['players_df']\n",
    "#ranking_df = dfs['ranking_df']\n",
    "#ranking_seasons_df = dfs['ranking_seasons_df']\n",
    "#sets_df = dfs['sets_df']\n",
    "#tournament_info_df = dfs['tournament_info_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sus_values = [1802, 16601, 24232, 40731, 44471, 51213, 78252, 88475]\n",
    "keys = list(id_mapping.keys())\n",
    "\n",
    "for value in sus_values:\n",
    "    old_id = keys[value]\n",
    "    new_id = id_mapping[old_id]\n",
    "    \n",
    "    print(old_id, new_id, players_df[players_df['player_id'] == new_id].iloc[0]['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(players_df[players_df['tag'] == 'Hungrybox']['player_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
